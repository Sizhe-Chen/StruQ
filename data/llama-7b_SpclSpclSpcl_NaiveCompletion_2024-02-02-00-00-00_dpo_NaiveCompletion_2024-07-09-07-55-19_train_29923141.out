WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1504: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1504: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1504: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1504: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1830: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead 
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1830: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead 
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1830: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead 
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1830: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead 
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/private/home/sizhechen/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/private/home/sizhechen/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/private/home/sizhechen/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/private/home/sizhechen/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:00,  5.75it/s]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:00,  3.70it/s]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:00,  2.97it/s]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:00<00:00,  5.87it/s]Loading checkpoint shards:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:00,  3.06it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.09it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.01it/s]
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:00<00:00,  3.57it/s]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:00<00:00,  3.12it/s]Loading checkpoint shards:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:00<00:00,  3.17it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.89it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.73it/s]
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.57it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.49it/s]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.62it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.46it/s]
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
trainable params: 33,554,432 || all params: 6,772,019,200 || trainable%: 0.4954863683788729
models/llama-7b_SpclSpclSpcl_NaiveCompletion_2024-02-02-00-00-00_dpo_NaiveCompletion_2024-07-09-07-55-19 



Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
trainable params: 33,554,432 || all params: 6,772,019,200 || trainable%: 0.4954863683788729
models/llama-7b_SpclSpclSpcl_NaiveCompletion_2024-02-02-00-00-00_dpo_NaiveCompletion_2024-07-09-07-55-19 



trainable params: 33,554,432 || all params: 6,772,019,200 || trainable%: 0.4954863683788729
models/llama-7b_SpclSpclSpcl_NaiveCompletion_2024-02-02-00-00-00_dpo_NaiveCompletion_2024-07-09-07-55-19 



trainable params: 33,554,432 || all params: 6,772,019,200 || trainable%: 0.4954863683788729
models/llama-7b_SpclSpclSpcl_NaiveCompletion_2024-02-02-00-00-00_dpo_NaiveCompletion_2024-07-09-07-55-19 



/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:300: UserWarning: `max_length` is not set in the DPOTrainer's init it will default to `512` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:307: UserWarning: `max_prompt_length` is not set in the DPOTrainer's init it will default to `128` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:332: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:300: UserWarning: `max_length` is not set in the DPOTrainer's init it will default to `512` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:307: UserWarning: `max_prompt_length` is not set in the DPOTrainer's init it will default to `128` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:332: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:300: UserWarning: `max_length` is not set in the DPOTrainer's init it will default to `512` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:307: UserWarning: `max_prompt_length` is not set in the DPOTrainer's init it will default to `128` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:332: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:300: UserWarning: `max_length` is not set in the DPOTrainer's init it will default to `512` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:307: UserWarning: `max_prompt_length` is not set in the DPOTrainer's init it will default to `128` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:332: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: Currently logged in as: sizhe-chen. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /private/home/sizhechen/SecAlign/wandb/run-20240709_080614-f6lja4l6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run models/llama-7b_SpclSpclSpcl_NaiveCompletion_2024-02-02-00-00-00_dpo_NaiveCompletion_2024-07-09-07-55-19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/sizhe-chen/huggingface
wandb: üöÄ View run at https://wandb.ai/sizhe-chen/huggingface/runs/f6lja4l6
  0%|          | 0/222 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
  0%|          | 1/222 [00:37<2:17:15, 37.26s/it]                                                 {'loss': 0.6931, 'grad_norm': 0.2098594307899475, 'learning_rate': 0.00015999198974133992, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -142.1671142578125, 'logps/chosen': -50.49531555175781, 'logits/rejected': -1.2795745134353638, 'logits/chosen': -1.4242749214172363, 'epoch': 0.01}
  0%|          | 1/222 [00:37<2:17:15, 37.26s/it]  1%|          | 2/222 [01:13<2:13:23, 36.38s/it]                                                 {'loss': 0.6482, 'grad_norm': 0.2278129607439041, 'learning_rate': 0.00015996796056946575, 'rewards/chosen': 0.0004252611834090203, 'rewards/rejected': -0.08634085953235626, 'rewards/accuracies': 0.984375, 'rewards/margins': 0.08676611632108688, 'logps/rejected': -128.57752990722656, 'logps/chosen': -59.304603576660156, 'logits/rejected': -1.3593974113464355, 'logits/chosen': -1.4522954225540161, 'epoch': 0.03}
  1%|          | 2/222 [01:13<2:13:23, 36.38s/it]  1%|‚ñè         | 3/222 [01:48<2:11:22, 35.99s/it]                                                 {'loss': 0.5929, 'grad_norm': 0.3002699017524719, 'learning_rate': 0.00015992791729637455, 'rewards/chosen': 0.003156075021252036, 'rewards/rejected': -0.20834633708000183, 'rewards/accuracies': 1.0, 'rewards/margins': 0.21150240302085876, 'logps/rejected': -137.80381774902344, 'logps/chosen': -62.993228912353516, 'logits/rejected': -1.335157871246338, 'logits/chosen': -1.4239583015441895, 'epoch': 0.04}
  1%|‚ñè         | 3/222 [01:48<2:11:22, 35.99s/it]  2%|‚ñè         | 4/222 [02:24<2:10:06, 35.81s/it]                                                 {'loss': 0.5259, 'grad_norm': 0.3637787699699402, 'learning_rate': 0.00015987186794099066, 'rewards/chosen': -0.0008256020955741405, 'rewards/rejected': -0.37622860074043274, 'rewards/accuracies': 1.0, 'rewards/margins': 0.3754030168056488, 'logps/rejected': -138.18199157714844, 'logps/chosen': -57.573150634765625, 'logits/rejected': -1.357870101928711, 'logits/chosen': -1.4010511636734009, 'epoch': 0.05}
  2%|‚ñè         | 4/222 [02:24<2:10:06, 35.81s/it]  2%|‚ñè         | 5/222 [02:59<2:09:06, 35.70s/it]                                                 {'loss': 0.4749, 'grad_norm': 0.3634837567806244, 'learning_rate': 0.00015979982372756, 'rewards/chosen': -0.005372295156121254, 'rewards/rejected': -0.6525846719741821, 'rewards/accuracies': 0.984375, 'rewards/margins': 0.6472123861312866, 'logps/rejected': -149.7458953857422, 'logps/chosen': -54.98509979248047, 'logits/rejected': -1.338276743888855, 'logits/chosen': -1.4193975925445557, 'epoch': 0.07}
  2%|‚ñè         | 5/222 [02:59<2:09:06, 35.70s/it]  3%|‚ñé         | 6/222 [03:35<2:08:49, 35.78s/it]                                                 {'loss': 0.3707, 'grad_norm': 0.41131362318992615, 'learning_rate': 0.00015971179908340214, 'rewards/chosen': -0.009156612679362297, 'rewards/rejected': -0.9072535037994385, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8980969190597534, 'logps/rejected': -157.378173828125, 'logps/chosen': -58.95924758911133, 'logits/rejected': -1.4144129753112793, 'logits/chosen': -1.4063605070114136, 'epoch': 0.08}
  3%|‚ñé         | 6/222 [03:35<2:08:49, 35.78s/it]  3%|‚ñé         | 7/222 [04:11<2:08:15, 35.79s/it]                                                 {'loss': 0.3237, 'grad_norm': 0.35437318682670593, 'learning_rate': 0.00015960781163602128, 'rewards/chosen': -0.004604905843734741, 'rewards/rejected': -1.2397894859313965, 'rewards/accuracies': 1.0, 'rewards/margins': 1.235184669494629, 'logps/rejected': -151.50157165527344, 'logps/chosen': -52.84943389892578, 'logits/rejected': -1.3053839206695557, 'logits/chosen': -1.3615894317626953, 'epoch': 0.09}
  3%|‚ñé         | 7/222 [04:11<2:08:15, 35.79s/it]  4%|‚ñé         | 8/222 [04:46<2:07:06, 35.64s/it]                                                 {'loss': 0.2421, 'grad_norm': 0.31381502747535706, 'learning_rate': 0.00015948788220957627, 'rewards/chosen': -0.008031681180000305, 'rewards/rejected': -1.6263995170593262, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6183679103851318, 'logps/rejected': -162.21543884277344, 'logps/chosen': -52.792625427246094, 'logits/rejected': -1.337110161781311, 'logits/chosen': -1.4053547382354736, 'epoch': 0.11}
  4%|‚ñé         | 8/222 [04:46<2:07:06, 35.64s/it]  4%|‚ñç         | 9/222 [05:22<2:06:23, 35.60s/it]                                                 {'loss': 0.2121, 'grad_norm': 0.24290111660957336, 'learning_rate': 0.00015935203482071015, 'rewards/chosen': -0.055083662271499634, 'rewards/rejected': -1.9898014068603516, 'rewards/accuracies': 0.984375, 'rewards/margins': 1.9347177743911743, 'logps/rejected': -162.90570068359375, 'logps/chosen': -65.10617065429688, 'logits/rejected': -1.3710851669311523, 'logits/chosen': -1.385819435119629, 'epoch': 0.12}
  4%|‚ñç         | 9/222 [05:22<2:06:23, 35.60s/it]  5%|‚ñç         | 10/222 [05:57<2:05:40, 35.57s/it]                                                  {'loss': 0.1675, 'grad_norm': 0.20243284106254578, 'learning_rate': 0.0001592002966737411, 'rewards/chosen': -0.029065053910017014, 'rewards/rejected': -2.8510777950286865, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8220126628875732, 'logps/rejected': -170.28016662597656, 'logps/chosen': -63.759971618652344, 'logits/rejected': -1.3777135610580444, 'logits/chosen': -1.3550690412521362, 'epoch': 0.13}
  5%|‚ñç         | 10/222 [05:57<2:05:40, 35.57s/it]  5%|‚ñç         | 11/222 [06:33<2:05:26, 35.67s/it]                                                  {'loss': 0.1298, 'grad_norm': 0.14462552964687347, 'learning_rate': 0.00015903269815521425, 'rewards/chosen': -0.04614982008934021, 'rewards/rejected': -3.273421287536621, 'rewards/accuracies': 1.0, 'rewards/margins': 3.22727108001709, 'logps/rejected': -162.4764404296875, 'logps/chosen': -56.68583297729492, 'logits/rejected': -1.3547428846359253, 'logits/chosen': -1.4016902446746826, 'epoch': 0.15}
  5%|‚ñç         | 11/222 [06:33<2:05:26, 35.67s/it]  5%|‚ñå         | 12/222 [07:10<2:05:41, 35.91s/it]                                                  {'loss': 0.0906, 'grad_norm': 0.10682551562786102, 'learning_rate': 0.00015884927282781668, 'rewards/chosen': -0.040632251650094986, 'rewards/rejected': -3.7840092182159424, 'rewards/accuracies': 1.0, 'rewards/margins': 3.7433769702911377, 'logps/rejected': -172.67918395996094, 'logps/chosen': -46.20371627807617, 'logits/rejected': -1.366041898727417, 'logits/chosen': -1.3914289474487305, 'epoch': 0.16}
  5%|‚ñå         | 12/222 [07:10<2:05:41, 35.91s/it]  6%|‚ñå         | 13/222 [07:46<2:05:20, 35.98s/it]                                                  {'loss': 0.0784, 'grad_norm': 0.08621222525835037, 'learning_rate': 0.00015865005742365636, 'rewards/chosen': -0.08777210116386414, 'rewards/rejected': -5.764595985412598, 'rewards/accuracies': 1.0, 'rewards/margins': 5.676824569702148, 'logps/rejected': -197.43882751464844, 'logps/chosen': -55.125675201416016, 'logits/rejected': -1.3116016387939453, 'logits/chosen': -1.3565062284469604, 'epoch': 0.17}
  6%|‚ñå         | 13/222 [07:46<2:05:20, 35.98s/it]  6%|‚ñã         | 14/222 [08:21<2:04:09, 35.81s/it]                                                  {'loss': 0.064, 'grad_norm': 0.06471320241689682, 'learning_rate': 0.00015843509183690615, 'rewards/chosen': -0.11618900299072266, 'rewards/rejected': -7.234486103057861, 'rewards/accuracies': 0.984375, 'rewards/margins': 7.118297100067139, 'logps/rejected': -213.66297912597656, 'logps/chosen': -56.7733039855957, 'logits/rejected': -1.3429663181304932, 'logits/chosen': -1.3469942808151245, 'epoch': 0.19}
  6%|‚ñã         | 14/222 [08:21<2:04:09, 35.81s/it]  7%|‚ñã         | 15/222 [08:57<2:03:16, 35.73s/it]                                                  {'loss': 0.0751, 'grad_norm': 0.07055473327636719, 'learning_rate': 0.00015820441911581492, 'rewards/chosen': -0.13961182534694672, 'rewards/rejected': -7.059961318969727, 'rewards/accuracies': 1.0, 'rewards/margins': 6.920350074768066, 'logps/rejected': -196.42098999023438, 'logps/chosen': -58.6778564453125, 'logits/rejected': -1.3458267450332642, 'logits/chosen': -1.3216009140014648, 'epoch': 0.2}
  7%|‚ñã         | 15/222 [08:57<2:03:16, 35.73s/it]  7%|‚ñã         | 16/222 [09:32<2:02:35, 35.71s/it]                                                  {'loss': 0.0496, 'grad_norm': 0.05171437934041023, 'learning_rate': 0.00015795808545408666, 'rewards/chosen': -0.22160397469997406, 'rewards/rejected': -8.855661392211914, 'rewards/accuracies': 1.0, 'rewards/margins': 8.634057998657227, 'logps/rejected': -214.9084930419922, 'logps/chosen': -59.662837982177734, 'logits/rejected': -1.3200860023498535, 'logits/chosen': -1.3369247913360596, 'epoch': 0.21}
  7%|‚ñã         | 16/222 [09:32<2:02:35, 35.71s/it]  8%|‚ñä         | 17/222 [10:08<2:01:56, 35.69s/it]                                                  {'loss': 0.0457, 'grad_norm': 0.04425019025802612, 'learning_rate': 0.00015769614018163011, 'rewards/chosen': -0.375292032957077, 'rewards/rejected': -10.935647010803223, 'rewards/accuracies': 1.0, 'rewards/margins': 10.560355186462402, 'logps/rejected': -252.52890014648438, 'logps/chosen': -69.8377685546875, 'logits/rejected': -1.3050963878631592, 'logits/chosen': -1.2553207874298096, 'epoch': 0.23}
  8%|‚ñä         | 17/222 [10:08<2:01:56, 35.69s/it]  8%|‚ñä         | 18/222 [10:44<2:01:35, 35.76s/it]                                                  {'loss': 0.0858, 'grad_norm': 0.12894539535045624, 'learning_rate': 0.00015741863575467993, 'rewards/chosen': -0.35983192920684814, 'rewards/rejected': -12.163354873657227, 'rewards/accuracies': 1.0, 'rewards/margins': 11.803524017333984, 'logps/rejected': -264.2782897949219, 'logps/chosen': -62.324806213378906, 'logits/rejected': -1.294466495513916, 'logits/chosen': -1.276965856552124, 'epoch': 0.24}
  8%|‚ñä         | 18/222 [10:44<2:01:35, 35.76s/it]  9%|‚ñä         | 19/222 [11:19<2:00:39, 35.66s/it]                                                  {'loss': 0.0342, 'grad_norm': 0.06014547869563103, 'learning_rate': 0.00015712562774529207, 'rewards/chosen': -0.42861443758010864, 'rewards/rejected': -17.508878707885742, 'rewards/accuracies': 0.984375, 'rewards/margins': 17.080263137817383, 'logps/rejected': -325.0218200683594, 'logps/chosen': -61.409080505371094, 'logits/rejected': -1.2439370155334473, 'logits/chosen': -1.2099329233169556, 'epoch': 0.25}
  9%|‚ñä         | 19/222 [11:19<2:00:39, 35.66s/it]  9%|‚ñâ         | 20/222 [11:55<1:59:40, 35.55s/it]                                                  {'loss': 0.0207, 'grad_norm': 0.03034704178571701, 'learning_rate': 0.00015681717483021515, 'rewards/chosen': -0.45370936393737793, 'rewards/rejected': -14.925650596618652, 'rewards/accuracies': 1.0, 'rewards/margins': 14.471940994262695, 'logps/rejected': -281.0283508300781, 'logps/chosen': -63.15081024169922, 'logits/rejected': -1.237678050994873, 'logits/chosen': -1.2244889736175537, 'epoch': 0.27}
  9%|‚ñâ         | 20/222 [11:55<1:59:40, 35.55s/it]  9%|‚ñâ         | 21/222 [12:30<1:58:45, 35.45s/it]                                                  {'loss': 0.0375, 'grad_norm': 0.0906587690114975, 'learning_rate': 0.00015649333877914008, 'rewards/chosen': -0.35364073514938354, 'rewards/rejected': -21.890792846679688, 'rewards/accuracies': 0.96875, 'rewards/margins': 21.53714942932129, 'logps/rejected': -355.88409423828125, 'logps/chosen': -52.81645202636719, 'logits/rejected': -1.2202390432357788, 'logits/chosen': -1.2123544216156006, 'epoch': 0.28}
  9%|‚ñâ         | 21/222 [12:30<1:58:45, 35.45s/it] 10%|‚ñâ         | 22/222 [13:05<1:58:22, 35.51s/it]                                                  {'loss': 0.0437, 'grad_norm': 0.08252212405204773, 'learning_rate': 0.00015615418444233013, 'rewards/chosen': -0.3763658106327057, 'rewards/rejected': -19.075679779052734, 'rewards/accuracies': 0.984375, 'rewards/margins': 18.69931411743164, 'logps/rejected': -320.8191833496094, 'logps/chosen': -55.25431442260742, 'logits/rejected': -1.2240148782730103, 'logits/chosen': -1.2121270895004272, 'epoch': 0.29}
 10%|‚ñâ         | 22/222 [13:05<1:58:22, 35.51s/it] 10%|‚ñà         | 23/222 [13:41<1:58:00, 35.58s/it]                                                  {'loss': 0.0551, 'grad_norm': 0.10365848988294601, 'learning_rate': 0.00015579977973763438, 'rewards/chosen': -0.5920518040657043, 'rewards/rejected': -23.217655181884766, 'rewards/accuracies': 0.984375, 'rewards/margins': 22.625600814819336, 'logps/rejected': -371.5499572753906, 'logps/chosen': -71.02284240722656, 'logits/rejected': -1.2015501260757446, 'logits/chosen': -1.2180171012878418, 'epoch': 0.31}
 10%|‚ñà         | 23/222 [13:41<1:58:00, 35.58s/it] 11%|‚ñà         | 24/222 [14:17<1:57:52, 35.72s/it]                                                  {'loss': 0.0099, 'grad_norm': 0.014666477218270302, 'learning_rate': 0.00015543019563688676, 'rewards/chosen': -0.31290972232818604, 'rewards/rejected': -30.28054428100586, 'rewards/accuracies': 1.0, 'rewards/margins': 29.96763038635254, 'logps/rejected': -453.2279968261719, 'logps/chosen': -48.9261360168457, 'logits/rejected': -1.1369116306304932, 'logits/chosen': -1.134824275970459, 'epoch': 0.32}
 11%|‚ñà         | 24/222 [14:17<1:57:52, 35.72s/it] 11%|‚ñà‚ñè        | 25/222 [14:53<1:57:40, 35.84s/it]                                                  {'loss': 0.0474, 'grad_norm': 0.07422350347042084, 'learning_rate': 0.0001550455061516933, 'rewards/chosen': -0.5663600564002991, 'rewards/rejected': -33.16869354248047, 'rewards/accuracies': 0.984375, 'rewards/margins': 32.602333068847656, 'logps/rejected': -474.1405944824219, 'logps/chosen': -56.634986877441406, 'logits/rejected': -1.1295055150985718, 'logits/chosen': -1.142034888267517, 'epoch': 0.33}
 11%|‚ñà‚ñè        | 25/222 [14:53<1:57:40, 35.84s/it] 12%|‚ñà‚ñè        | 26/222 [15:29<1:56:58, 35.81s/it]                                                  {'loss': 0.0263, 'grad_norm': 0.0659552812576294, 'learning_rate': 0.00015464578831861099, 'rewards/chosen': -0.48173290491104126, 'rewards/rejected': -25.912500381469727, 'rewards/accuracies': 1.0, 'rewards/margins': 25.430767059326172, 'logps/rejected': -399.5009765625, 'logps/chosen': -65.97462463378906, 'logits/rejected': -1.1541250944137573, 'logits/chosen': -1.155200719833374, 'epoch': 0.35}
 12%|‚ñà‚ñè        | 26/222 [15:29<1:56:58, 35.81s/it] 12%|‚ñà‚ñè        | 27/222 [16:05<1:56:09, 35.74s/it]                                                  {'loss': 0.0119, 'grad_norm': 0.02051837556064129, 'learning_rate': 0.00015423112218372078, 'rewards/chosen': -0.5402272343635559, 'rewards/rejected': -34.05204772949219, 'rewards/accuracies': 1.0, 'rewards/margins': 33.51182174682617, 'logps/rejected': -487.0782775878906, 'logps/chosen': -59.761253356933594, 'logits/rejected': -1.1887434720993042, 'logits/chosen': -1.1187399625778198, 'epoch': 0.36}
 12%|‚ñà‚ñè        | 27/222 [16:05<1:56:09, 35.74s/it] 13%|‚ñà‚ñé        | 28/222 [16:41<1:55:54, 35.85s/it]                                                  {'loss': 0.0413, 'grad_norm': 0.10619432479143143, 'learning_rate': 0.0001538015907865975, 'rewards/chosen': -0.5715413093566895, 'rewards/rejected': -26.087156295776367, 'rewards/accuracies': 1.0, 'rewards/margins': 25.515615463256836, 'logps/rejected': -402.9366760253906, 'logps/chosen': -61.08209991455078, 'logits/rejected': -1.1836291551589966, 'logits/chosen': -1.1420797109603882, 'epoch': 0.37}
 13%|‚ñà‚ñé        | 28/222 [16:41<1:55:54, 35.85s/it] 13%|‚ñà‚ñé        | 29/222 [17:16<1:54:43, 35.67s/it]                                                  {'loss': 0.0196, 'grad_norm': 0.049395568668842316, 'learning_rate': 0.00015335728014368108, 'rewards/chosen': -0.6030153632164001, 'rewards/rejected': -30.0350399017334, 'rewards/accuracies': 1.0, 'rewards/margins': 29.432029724121094, 'logps/rejected': -443.2774963378906, 'logps/chosen': -71.81669616699219, 'logits/rejected': -1.1074914932250977, 'logits/chosen': -1.1446141004562378, 'epoch': 0.39}
 13%|‚ñà‚ñé        | 29/222 [17:16<1:54:43, 35.67s/it] 14%|‚ñà‚ñé        | 30/222 [17:52<1:54:03, 35.64s/it]                                                  {'loss': 0.0313, 'grad_norm': 0.060286764055490494, 'learning_rate': 0.00015289827923105088, 'rewards/chosen': -0.570277750492096, 'rewards/rejected': -30.617263793945312, 'rewards/accuracies': 1.0, 'rewards/margins': 30.04698371887207, 'logps/rejected': -443.4093933105469, 'logps/chosen': -71.24530792236328, 'logits/rejected': -1.1928585767745972, 'logits/chosen': -1.1996359825134277, 'epoch': 0.4}
 14%|‚ñà‚ñé        | 30/222 [17:52<1:54:03, 35.64s/it] 14%|‚ñà‚ñç        | 31/222 [18:28<1:53:47, 35.74s/it]                                                  {'loss': 0.0093, 'grad_norm': 0.01887945644557476, 'learning_rate': 0.00015242467996660775, 'rewards/chosen': -0.6022220253944397, 'rewards/rejected': -28.834598541259766, 'rewards/accuracies': 1.0, 'rewards/margins': 28.232378005981445, 'logps/rejected': -407.25311279296875, 'logps/chosen': -69.50444030761719, 'logits/rejected': -1.1059412956237793, 'logits/chosen': -1.1126036643981934, 'epoch': 0.41}
 14%|‚ñà‚ñç        | 31/222 [18:28<1:53:47, 35.74s/it] 14%|‚ñà‚ñç        | 32/222 [19:03<1:52:49, 35.63s/it]                                                  {'loss': 0.0088, 'grad_norm': 0.014745122753083706, 'learning_rate': 0.00015193657719166694, 'rewards/chosen': -0.503637969493866, 'rewards/rejected': -29.558631896972656, 'rewards/accuracies': 1.0, 'rewards/margins': 29.054996490478516, 'logps/rejected': -433.59503173828125, 'logps/chosen': -60.65422821044922, 'logits/rejected': -1.075236201286316, 'logits/chosen': -1.117515206336975, 'epoch': 0.43}
 14%|‚ñà‚ñç        | 32/222 [19:03<1:52:49, 35.63s/it] 15%|‚ñà‚ñç        | 33/222 [19:39<1:52:20, 35.67s/it]                                                  {'loss': 0.0108, 'grad_norm': 0.027173319831490517, 'learning_rate': 0.0001514340686519655, 'rewards/chosen': -0.3835902512073517, 'rewards/rejected': -32.29703140258789, 'rewards/accuracies': 1.0, 'rewards/margins': 31.913442611694336, 'logps/rejected': -475.8833312988281, 'logps/chosen': -52.95809555053711, 'logits/rejected': -1.150606632232666, 'logits/chosen': -1.1213960647583008, 'epoch': 0.44}
 15%|‚ñà‚ñç        | 33/222 [19:39<1:52:20, 35.67s/it] 15%|‚ñà‚ñå        | 34/222 [20:15<1:52:04, 35.77s/it]                                                  {'loss': 0.0362, 'grad_norm': 0.07171735167503357, 'learning_rate': 0.00015091725497808788, 'rewards/chosen': -0.5604330897331238, 'rewards/rejected': -30.36138153076172, 'rewards/accuracies': 1.0, 'rewards/margins': 29.800947189331055, 'logps/rejected': -441.294677734375, 'logps/chosen': -77.11768341064453, 'logits/rejected': -1.1125913858413696, 'logits/chosen': -1.1373745203018188, 'epoch': 0.45}
 15%|‚ñà‚ñå        | 34/222 [20:15<1:52:04, 35.77s/it] 16%|‚ñà‚ñå        | 35/222 [20:50<1:50:54, 35.59s/it]                                                  {'loss': 0.0208, 'grad_norm': 0.0522255003452301, 'learning_rate': 0.00015038623966531436, 'rewards/chosen': -0.5097283124923706, 'rewards/rejected': -28.165409088134766, 'rewards/accuracies': 1.0, 'rewards/margins': 27.655677795410156, 'logps/rejected': -422.14697265625, 'logps/chosen': -66.28816223144531, 'logits/rejected': -1.1226744651794434, 'logits/chosen': -1.1321579217910767, 'epoch': 0.47}
 16%|‚ñà‚ñå        | 35/222 [20:50<1:50:54, 35.59s/it] 16%|‚ñà‚ñå        | 36/222 [21:26<1:50:21, 35.60s/it]                                                  {'loss': 0.0111, 'grad_norm': 0.031707435846328735, 'learning_rate': 0.00014984112905289506, 'rewards/chosen': -0.5154611468315125, 'rewards/rejected': -29.122426986694336, 'rewards/accuracies': 1.0, 'rewards/margins': 28.60696792602539, 'logps/rejected': -439.1177673339844, 'logps/chosen': -69.98479461669922, 'logits/rejected': -1.0970079898834229, 'logits/chosen': -1.0377527475357056, 'epoch': 0.48}
 16%|‚ñà‚ñå        | 36/222 [21:26<1:50:21, 35.60s/it] 17%|‚ñà‚ñã        | 37/222 [22:02<1:50:18, 35.78s/it]                                                  {'loss': 0.0093, 'grad_norm': 0.02019585855305195, 'learning_rate': 0.00014928203230275513, 'rewards/chosen': -0.3528567850589752, 'rewards/rejected': -30.752344131469727, 'rewards/accuracies': 1.0, 'rewards/margins': 30.39948844909668, 'logps/rejected': -453.6016845703125, 'logps/chosen': -58.797950744628906, 'logits/rejected': -1.1105650663375854, 'logits/chosen': -1.1113405227661133, 'epoch': 0.49}
 17%|‚ñà‚ñã        | 37/222 [22:02<1:50:18, 35.78s/it] 17%|‚ñà‚ñã        | 38/222 [22:37<1:49:37, 35.75s/it]                                                  {'loss': 0.0164, 'grad_norm': 0.11703947931528091, 'learning_rate': 0.0001487090613776341, 'rewards/chosen': -0.41637134552001953, 'rewards/rejected': -25.49399185180664, 'rewards/accuracies': 0.984375, 'rewards/margins': 25.077621459960938, 'logps/rejected': -387.59619140625, 'logps/chosen': -53.7513427734375, 'logits/rejected': -1.1323862075805664, 'logits/chosen': -1.087904691696167, 'epoch': 0.51}
 17%|‚ñà‚ñã        | 38/222 [22:37<1:49:37, 35.75s/it] 18%|‚ñà‚ñä        | 39/222 [23:13<1:48:54, 35.71s/it]                                                  {'loss': 0.0139, 'grad_norm': 0.021718451753258705, 'learning_rate': 0.00014812233101866491, 'rewards/chosen': -0.3319026231765747, 'rewards/rejected': -39.757545471191406, 'rewards/accuracies': 1.0, 'rewards/margins': 39.4256477355957, 'logps/rejected': -535.6683959960938, 'logps/chosen': -64.07312774658203, 'logits/rejected': -1.090867042541504, 'logits/chosen': -1.1105575561523438, 'epoch': 0.52}
 18%|‚ñà‚ñä        | 39/222 [23:13<1:48:54, 35.71s/it] 18%|‚ñà‚ñä        | 40/222 [23:49<1:48:27, 35.76s/it]                                                  {'loss': 0.0081, 'grad_norm': 0.0205036960542202, 'learning_rate': 0.00014752195872239605, 'rewards/chosen': -0.4791416823863983, 'rewards/rejected': -30.00102996826172, 'rewards/accuracies': 1.0, 'rewards/margins': 29.521888732910156, 'logps/rejected': -450.9710998535156, 'logps/chosen': -65.02367401123047, 'logits/rejected': -1.1714521646499634, 'logits/chosen': -1.1507341861724854, 'epoch': 0.53}
 18%|‚ñà‚ñä        | 40/222 [23:49<1:48:27, 35.76s/it] 18%|‚ñà‚ñä        | 41/222 [24:25<1:47:49, 35.74s/it]                                                  {'loss': 0.0056, 'grad_norm': 0.006338851526379585, 'learning_rate': 0.0001469080647172621, 'rewards/chosen': -0.40346193313598633, 'rewards/rejected': -29.131200790405273, 'rewards/accuracies': 1.0, 'rewards/margins': 28.727741241455078, 'logps/rejected': -438.44061279296875, 'logps/chosen': -67.86923217773438, 'logits/rejected': -1.0989325046539307, 'logits/chosen': -1.1393437385559082, 'epoch': 0.55}
 18%|‚ñà‚ñä        | 41/222 [24:25<1:47:49, 35.74s/it] 19%|‚ñà‚ñâ        | 42/222 [25:00<1:47:14, 35.75s/it]                                                  {'loss': 0.0083, 'grad_norm': 0.02404678612947464, 'learning_rate': 0.0001462807719395074, 'rewards/chosen': -0.3951088786125183, 'rewards/rejected': -30.743026733398438, 'rewards/accuracies': 1.0, 'rewards/margins': 30.347917556762695, 'logps/rejected': -456.05535888671875, 'logps/chosen': -57.295433044433594, 'logits/rejected': -1.150367259979248, 'logits/chosen': -1.1097817420959473, 'epoch': 0.56}
 19%|‚ñà‚ñâ        | 42/222 [25:00<1:47:14, 35.75s/it] 19%|‚ñà‚ñâ        | 43/222 [25:36<1:46:26, 35.68s/it]                                                  {'loss': 0.0083, 'grad_norm': 0.016567202284932137, 'learning_rate': 0.00014564020600856703, 'rewards/chosen': -0.3425103724002838, 'rewards/rejected': -27.18992805480957, 'rewards/accuracies': 1.0, 'rewards/margins': 26.8474178314209, 'logps/rejected': -410.415283203125, 'logps/chosen': -52.155433654785156, 'logits/rejected': -1.1598504781723022, 'logits/chosen': -1.1201075315475464, 'epoch': 0.57}
 19%|‚ñà‚ñâ        | 43/222 [25:36<1:46:26, 35.68s/it] 20%|‚ñà‚ñâ        | 44/222 [26:12<1:45:53, 35.69s/it]                                                  {'loss': 0.0085, 'grad_norm': 0.027162650600075722, 'learning_rate': 0.0001449864952019109, 'rewards/chosen': -0.36186879873275757, 'rewards/rejected': -31.343358993530273, 'rewards/accuracies': 1.0, 'rewards/margins': 30.981491088867188, 'logps/rejected': -469.04229736328125, 'logps/chosen': -62.787445068359375, 'logits/rejected': -1.111057996749878, 'logits/chosen': -1.1434152126312256, 'epoch': 0.59}
 20%|‚ñà‚ñâ        | 44/222 [26:12<1:45:53, 35.69s/it] 20%|‚ñà‚ñà        | 45/222 [26:47<1:45:03, 35.62s/it]                                                  {'loss': 0.013, 'grad_norm': 0.016663437709212303, 'learning_rate': 0.00014431977042935525, 'rewards/chosen': -0.32918715476989746, 'rewards/rejected': -36.14898681640625, 'rewards/accuracies': 0.984375, 'rewards/margins': 35.819801330566406, 'logps/rejected': -513.2569580078125, 'logps/chosen': -62.513694763183594, 'logits/rejected': -1.1550333499908447, 'logits/chosen': -1.1574382781982422, 'epoch': 0.6}
 20%|‚ñà‚ñà        | 45/222 [26:47<1:45:03, 35.62s/it] 21%|‚ñà‚ñà        | 46/222 [27:23<1:44:31, 35.64s/it]                                                  {'loss': 0.0184, 'grad_norm': 0.020250985398888588, 'learning_rate': 0.0001436401652068472, 'rewards/chosen': -0.3385128676891327, 'rewards/rejected': -31.924055099487305, 'rewards/accuracies': 0.984375, 'rewards/margins': 31.585540771484375, 'logps/rejected': -466.7576904296875, 'logps/chosen': -53.703857421875, 'logits/rejected': -1.1191209554672241, 'logits/chosen': -1.1172785758972168, 'epoch': 0.61}
 21%|‚ñà‚ñà        | 46/222 [27:23<1:44:31, 35.64s/it] 21%|‚ñà‚ñà        | 47/222 [27:58<1:44:00, 35.66s/it]                                                  {'loss': 0.0073, 'grad_norm': 0.013719446025788784, 'learning_rate': 0.0001429478156297272, 'rewards/chosen': -0.3426976799964905, 'rewards/rejected': -25.671653747558594, 'rewards/accuracies': 1.0, 'rewards/margins': 25.328954696655273, 'logps/rejected': -391.28680419921875, 'logps/chosen': -73.48038482666016, 'logits/rejected': -1.1702604293823242, 'logits/chosen': -1.1484907865524292, 'epoch': 0.63}
 21%|‚ñà‚ñà        | 47/222 [27:58<1:44:00, 35.66s/it] 22%|‚ñà‚ñà‚ñè       | 48/222 [28:34<1:43:31, 35.70s/it]                                                  {'loss': 0.0205, 'grad_norm': 0.12571577727794647, 'learning_rate': 0.00014224286034547517, 'rewards/chosen': -0.4314282238483429, 'rewards/rejected': -26.486974716186523, 'rewards/accuracies': 0.984375, 'rewards/margins': 26.055545806884766, 'logps/rejected': -405.9002380371094, 'logps/chosen': -76.27012634277344, 'logits/rejected': -1.1000041961669922, 'logits/chosen': -1.1175342798233032, 'epoch': 0.64}
 22%|‚ñà‚ñà‚ñè       | 48/222 [28:34<1:43:31, 35.70s/it] 22%|‚ñà‚ñà‚ñè       | 49/222 [29:10<1:42:37, 35.59s/it]                                                  {'loss': 0.0127, 'grad_norm': 0.8204783201217651, 'learning_rate': 0.00014152544052594535, 'rewards/chosen': -0.39144444465637207, 'rewards/rejected': -36.42287063598633, 'rewards/accuracies': 0.984375, 'rewards/margins': 36.031429290771484, 'logps/rejected': -497.8869323730469, 'logps/chosen': -55.40882873535156, 'logits/rejected': -1.103742241859436, 'logits/chosen': -1.1426750421524048, 'epoch': 0.65}
 22%|‚ñà‚ñà‚ñè       | 49/222 [29:10<1:42:37, 35.59s/it] 23%|‚ñà‚ñà‚ñé       | 50/222 [29:45<1:41:43, 35.49s/it]                                                  {'loss': 0.015, 'grad_norm': 0.0338473841547966, 'learning_rate': 0.0001407956998390958, 'rewards/chosen': -0.3142240643501282, 'rewards/rejected': -32.031742095947266, 'rewards/accuracies': 1.0, 'rewards/margins': 31.71751594543457, 'logps/rejected': -454.9756774902344, 'logps/chosen': -62.96193313598633, 'logits/rejected': -1.0798641443252563, 'logits/chosen': -1.0705089569091797, 'epoch': 0.67}
 23%|‚ñà‚ñà‚ñé       | 50/222 [29:45<1:41:43, 35.49s/it] 23%|‚ñà‚ñà‚ñé       | 51/222 [30:20<1:41:06, 35.48s/it]                                                  {'loss': 0.0378, 'grad_norm': 0.06189609318971634, 'learning_rate': 0.00014005378442021794, 'rewards/chosen': -0.29978206753730774, 'rewards/rejected': -28.202865600585938, 'rewards/accuracies': 0.984375, 'rewards/margins': 27.903085708618164, 'logps/rejected': -438.18853759765625, 'logps/chosen': -65.27064514160156, 'logits/rejected': -1.1529879570007324, 'logits/chosen': -1.1007709503173828, 'epoch': 0.68}
 23%|‚ñà‚ñà‚ñé       | 51/222 [30:20<1:41:06, 35.48s/it] 23%|‚ñà‚ñà‚ñé       | 52/222 [30:56<1:40:50, 35.59s/it]                                                  {'loss': 0.0093, 'grad_norm': 0.014592461287975311, 'learning_rate': 0.00013929984284267205, 'rewards/chosen': -0.28628063201904297, 'rewards/rejected': -25.58356285095215, 'rewards/accuracies': 1.0, 'rewards/margins': 25.297279357910156, 'logps/rejected': -403.5307312011719, 'logps/chosen': -60.70703887939453, 'logits/rejected': -1.107155680656433, 'logits/chosen': -1.1618775129318237, 'epoch': 0.69}
 23%|‚ñà‚ñà‚ñé       | 52/222 [30:56<1:40:50, 35.59s/it] 24%|‚ñà‚ñà‚ñç       | 53/222 [31:32<1:40:53, 35.82s/it]                                                  {'loss': 0.0074, 'grad_norm': 0.015586663968861103, 'learning_rate': 0.00013853402608813426, 'rewards/chosen': -0.251406192779541, 'rewards/rejected': -25.421144485473633, 'rewards/accuracies': 1.0, 'rewards/margins': 25.169740676879883, 'logps/rejected': -387.24493408203125, 'logps/chosen': -64.2925033569336, 'logits/rejected': -1.048089861869812, 'logits/chosen': -1.0848972797393799, 'epoch': 0.71}
 24%|‚ñà‚ñà‚ñç       | 53/222 [31:32<1:40:53, 35.82s/it] 24%|‚ñà‚ñà‚ñç       | 54/222 [32:08<1:39:58, 35.70s/it]                                                  {'loss': 0.0282, 'grad_norm': 0.0462055504322052, 'learning_rate': 0.00013775648751636197, 'rewards/chosen': -0.27562931180000305, 'rewards/rejected': -22.736875534057617, 'rewards/accuracies': 1.0, 'rewards/margins': 22.461244583129883, 'logps/rejected': -374.60223388671875, 'logps/chosen': -66.27726745605469, 'logits/rejected': -1.1904228925704956, 'logits/chosen': -1.136018991470337, 'epoch': 0.72}
 24%|‚ñà‚ñà‚ñç       | 54/222 [32:08<1:39:58, 35.70s/it] 25%|‚ñà‚ñà‚ñç       | 55/222 [32:43<1:39:07, 35.61s/it]                                                  {'loss': 0.027, 'grad_norm': 0.03402811661362648, 'learning_rate': 0.00013696738283448207, 'rewards/chosen': -0.18613773584365845, 'rewards/rejected': -26.039583206176758, 'rewards/accuracies': 1.0, 'rewards/margins': 25.853445053100586, 'logps/rejected': -403.9501953125, 'logps/chosen': -54.27252960205078, 'logits/rejected': -1.1204839944839478, 'logits/chosen': -1.0954605340957642, 'epoch': 0.73}
 25%|‚ñà‚ñà‚ñç       | 55/222 [32:43<1:39:07, 35.61s/it] 25%|‚ñà‚ñà‚ñå       | 56/222 [33:20<1:39:07, 35.83s/it]                                                  {'loss': 0.0062, 'grad_norm': 0.01296242419630289, 'learning_rate': 0.00013616687006580983, 'rewards/chosen': -0.18850991129875183, 'rewards/rejected': -24.544143676757812, 'rewards/accuracies': 1.0, 'rewards/margins': 24.355632781982422, 'logps/rejected': -401.1854248046875, 'logps/chosen': -55.61115646362305, 'logits/rejected': -1.1458189487457275, 'logits/chosen': -1.1210359334945679, 'epoch': 0.75}
 25%|‚ñà‚ñà‚ñå       | 56/222 [33:20<1:39:07, 35.83s/it] 26%|‚ñà‚ñà‚ñå       | 57/222 [33:55<1:38:12, 35.71s/it]                                                  {'loss': 0.0049, 'grad_norm': 0.010207274928689003, 'learning_rate': 0.0001353551095182037, 'rewards/chosen': -0.21295419335365295, 'rewards/rejected': -24.404714584350586, 'rewards/accuracies': 1.0, 'rewards/margins': 24.191761016845703, 'logps/rejected': -389.047119140625, 'logps/chosen': -59.12997055053711, 'logits/rejected': -1.1350339651107788, 'logits/chosen': -1.0770524740219116, 'epoch': 0.76}
 26%|‚ñà‚ñà‚ñå       | 57/222 [33:55<1:38:12, 35.71s/it] 26%|‚ñà‚ñà‚ñå       | 58/222 [34:30<1:37:19, 35.61s/it]                                                  {'loss': 0.0209, 'grad_norm': 0.039001695811748505, 'learning_rate': 0.00013453226375196263, 'rewards/chosen': -0.2573595941066742, 'rewards/rejected': -22.5928955078125, 'rewards/accuracies': 1.0, 'rewards/margins': 22.33553695678711, 'logps/rejected': -364.99658203125, 'logps/chosen': -63.28144073486328, 'logits/rejected': -1.1467854976654053, 'logits/chosen': -1.1474618911743164, 'epoch': 0.77}
 26%|‚ñà‚ñà‚ñå       | 58/222 [34:30<1:37:19, 35.61s/it] 27%|‚ñà‚ñà‚ñã       | 59/222 [35:06<1:36:48, 35.64s/it]                                                  {'loss': 0.0388, 'grad_norm': 0.06597664952278137, 'learning_rate': 0.00013369849754727226, 'rewards/chosen': -0.4226137697696686, 'rewards/rejected': -19.921913146972656, 'rewards/accuracies': 0.984375, 'rewards/margins': 19.499300003051758, 'logps/rejected': -333.4665222167969, 'logps/chosen': -62.89298629760742, 'logits/rejected': -1.1631265878677368, 'logits/chosen': -1.121201992034912, 'epoch': 0.79}
 27%|‚ñà‚ñà‚ñã       | 59/222 [35:06<1:36:48, 35.64s/it] 27%|‚ñà‚ñà‚ñã       | 60/222 [35:42<1:36:30, 35.74s/it]                                                  {'loss': 0.0165, 'grad_norm': 0.017065558582544327, 'learning_rate': 0.00013285397787120653, 'rewards/chosen': -0.260836660861969, 'rewards/rejected': -21.71430206298828, 'rewards/accuracies': 1.0, 'rewards/margins': 21.453466415405273, 'logps/rejected': -377.3814697265625, 'logps/chosen': -66.73656463623047, 'logits/rejected': -1.1939125061035156, 'logits/chosen': -1.1067843437194824, 'epoch': 0.8}
 27%|‚ñà‚ñà‚ñã       | 60/222 [35:42<1:36:30, 35.74s/it] 27%|‚ñà‚ñà‚ñã       | 61/222 [36:18<1:35:59, 35.78s/it]                                                  {'loss': 0.0114, 'grad_norm': 0.02100585214793682, 'learning_rate': 0.00013199887384429175, 'rewards/chosen': -0.1036609634757042, 'rewards/rejected': -22.075969696044922, 'rewards/accuracies': 1.0, 'rewards/margins': 21.972307205200195, 'logps/rejected': -360.19891357421875, 'logps/chosen': -44.95494079589844, 'logits/rejected': -1.1784337759017944, 'logits/chosen': -1.1488287448883057, 'epoch': 0.81}
 27%|‚ñà‚ñà‚ñã       | 61/222 [36:18<1:35:59, 35.78s/it] 28%|‚ñà‚ñà‚ñä       | 62/222 [36:54<1:35:31, 35.82s/it]                                                  {'loss': 0.023, 'grad_norm': 0.03860519453883171, 'learning_rate': 0.0001311333567066388, 'rewards/chosen': -0.27868086099624634, 'rewards/rejected': -17.566640853881836, 'rewards/accuracies': 0.96875, 'rewards/margins': 17.287960052490234, 'logps/rejected': -298.6879577636719, 'logps/chosen': -69.55318450927734, 'logits/rejected': -1.1172515153884888, 'logits/chosen': -1.1354522705078125, 'epoch': 0.83}
 28%|‚ñà‚ñà‚ñä       | 62/222 [36:54<1:35:31, 35.82s/it] 28%|‚ñà‚ñà‚ñä       | 63/222 [37:30<1:34:48, 35.78s/it]                                                  {'loss': 0.0148, 'grad_norm': 0.03582023084163666, 'learning_rate': 0.0001302575997836514, 'rewards/chosen': -0.3181520700454712, 'rewards/rejected': -20.64763641357422, 'rewards/accuracies': 1.0, 'rewards/margins': 20.329484939575195, 'logps/rejected': -336.8237609863281, 'logps/chosen': -71.06507110595703, 'logits/rejected': -1.14314866065979, 'logits/chosen': -1.2040852308273315, 'epoch': 0.84}
 28%|‚ñà‚ñà‚ñä       | 63/222 [37:30<1:34:48, 35.78s/it] 29%|‚ñà‚ñà‚ñâ       | 64/222 [38:06<1:34:23, 35.84s/it]                                                  {'loss': 0.0167, 'grad_norm': 0.027864323928952217, 'learning_rate': 0.00012937177845131643, 'rewards/chosen': -0.17827051877975464, 'rewards/rejected': -22.297714233398438, 'rewards/accuracies': 1.0, 'rewards/margins': 22.119441986083984, 'logps/rejected': -360.0203857421875, 'logps/chosen': -66.21854400634766, 'logits/rejected': -1.1481928825378418, 'logits/chosen': -1.1767936944961548, 'epoch': 0.85}
 29%|‚ñà‚ñà‚ñâ       | 64/222 [38:06<1:34:23, 35.84s/it] 29%|‚ñà‚ñà‚ñâ       | 65/222 [38:42<1:34:00, 35.93s/it]                                                  {'loss': 0.0098, 'grad_norm': 0.014403676614165306, 'learning_rate': 0.00012847607010108385, 'rewards/chosen': -0.248765766620636, 'rewards/rejected': -20.68027114868164, 'rewards/accuracies': 1.0, 'rewards/margins': 20.431503295898438, 'logps/rejected': -325.27545166015625, 'logps/chosen': -68.42678833007812, 'logits/rejected': -1.1187037229537964, 'logits/chosen': -1.2012115716934204, 'epoch': 0.87}
 29%|‚ñà‚ñà‚ñâ       | 65/222 [38:42<1:34:00, 35.93s/it] 30%|‚ñà‚ñà‚ñâ       | 66/222 [39:17<1:32:58, 35.76s/it]                                                  {'loss': 0.0085, 'grad_norm': 0.017767636105418205, 'learning_rate': 0.00012757065410434296, 'rewards/chosen': -0.1966005265712738, 'rewards/rejected': -25.725873947143555, 'rewards/accuracies': 1.0, 'rewards/margins': 25.529273986816406, 'logps/rejected': -398.3998718261719, 'logps/chosen': -59.087398529052734, 'logits/rejected': -1.1521847248077393, 'logits/chosen': -1.1616296768188477, 'epoch': 0.88}
 30%|‚ñà‚ñà‚ñâ       | 66/222 [39:17<1:32:58, 35.76s/it] 30%|‚ñà‚ñà‚ñà       | 67/222 [39:53<1:32:20, 35.74s/it]                                                  {'loss': 0.0088, 'grad_norm': 0.01644316129386425, 'learning_rate': 0.00012665571177650187, 'rewards/chosen': -0.15250691771507263, 'rewards/rejected': -20.620948791503906, 'rewards/accuracies': 1.0, 'rewards/margins': 20.46844482421875, 'logps/rejected': -346.0568542480469, 'logps/chosen': -60.0598258972168, 'logits/rejected': -1.1438405513763428, 'logits/chosen': -1.1625277996063232, 'epoch': 0.89}
 30%|‚ñà‚ñà‚ñà       | 67/222 [39:53<1:32:20, 35.74s/it] 31%|‚ñà‚ñà‚ñà       | 68/222 [40:28<1:31:35, 35.69s/it]                                                  {'loss': 0.0081, 'grad_norm': 0.022187339141964912, 'learning_rate': 0.0001257314263406783, 'rewards/chosen': -0.2656541168689728, 'rewards/rejected': -22.26276397705078, 'rewards/accuracies': 1.0, 'rewards/margins': 21.99711036682129, 'logps/rejected': -359.939208984375, 'logps/chosen': -73.67818450927734, 'logits/rejected': -1.1692606210708618, 'logits/chosen': -1.1729412078857422, 'epoch': 0.91}
 31%|‚ñà‚ñà‚ñà       | 68/222 [40:28<1:31:35, 35.69s/it] 31%|‚ñà‚ñà‚ñà       | 69/222 [41:04<1:31:12, 35.77s/it]                                                  {'loss': 0.0169, 'grad_norm': 0.02324127033352852, 'learning_rate': 0.00012479798289100766, 'rewards/chosen': -0.19533012807369232, 'rewards/rejected': -21.5450439453125, 'rewards/accuracies': 0.984375, 'rewards/margins': 21.349714279174805, 'logps/rejected': -342.49334716796875, 'logps/chosen': -62.427330017089844, 'logits/rejected': -1.1235477924346924, 'logits/chosen': -1.1413347721099854, 'epoch': 0.92}
 31%|‚ñà‚ñà‚ñà       | 69/222 [41:04<1:31:12, 35.77s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 70/222 [41:40<1:30:31, 35.74s/it]                                                  {'loss': 0.0096, 'grad_norm': 0.016602344810962677, 'learning_rate': 0.0001238555683555768, 'rewards/chosen': -0.1625838726758957, 'rewards/rejected': -23.331945419311523, 'rewards/accuracies': 1.0, 'rewards/margins': 23.169361114501953, 'logps/rejected': -366.82513427734375, 'logps/chosen': -58.904388427734375, 'logits/rejected': -1.1081736087799072, 'logits/chosen': -1.1342921257019043, 'epoch': 0.93}
 32%|‚ñà‚ñà‚ñà‚ñè      | 70/222 [41:40<1:30:31, 35.74s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 71/222 [42:15<1:29:46, 35.67s/it]                                                  {'loss': 0.0038, 'grad_norm': 0.009253637865185738, 'learning_rate': 0.0001229043714589906, 'rewards/chosen': -0.224777951836586, 'rewards/rejected': -20.13818359375, 'rewards/accuracies': 1.0, 'rewards/margins': 19.913406372070312, 'logps/rejected': -342.69232177734375, 'logps/chosen': -66.32896423339844, 'logits/rejected': -1.1246533393859863, 'logits/chosen': -1.1298096179962158, 'epoch': 0.95}
 32%|‚ñà‚ñà‚ñà‚ñè      | 71/222 [42:15<1:29:46, 35.67s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 72/222 [42:51<1:29:16, 35.71s/it]                                                  {'loss': 0.0108, 'grad_norm': 0.019609658047556877, 'learning_rate': 0.00012194458268457855, 'rewards/chosen': -0.181799054145813, 'rewards/rejected': -18.59964370727539, 'rewards/accuracies': 1.0, 'rewards/margins': 18.417842864990234, 'logps/rejected': -323.8599548339844, 'logps/chosen': -60.40412902832031, 'logits/rejected': -1.125908374786377, 'logits/chosen': -1.115405559539795, 'epoch': 0.96}
 32%|‚ñà‚ñà‚ñà‚ñè      | 72/222 [42:51<1:29:16, 35.71s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 73/222 [43:27<1:28:38, 35.69s/it]                                                  {'loss': 0.0062, 'grad_norm': 0.009247000329196453, 'learning_rate': 0.00012097639423624914, 'rewards/chosen': -0.1566898226737976, 'rewards/rejected': -21.365816116333008, 'rewards/accuracies': 1.0, 'rewards/margins': 21.209125518798828, 'logps/rejected': -358.7237548828125, 'logps/chosen': -48.479042053222656, 'logits/rejected': -1.207119107246399, 'logits/chosen': -1.0464868545532227, 'epoch': 0.97}
 33%|‚ñà‚ñà‚ñà‚ñé      | 73/222 [43:27<1:28:38, 35.69s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 74/222 [44:03<1:28:09, 35.74s/it]                                                  {'loss': 0.0093, 'grad_norm': 0.018810328096151352, 'learning_rate': 0.00012000000000000002, 'rewards/chosen': -0.25393134355545044, 'rewards/rejected': -27.673120498657227, 'rewards/accuracies': 1.0, 'rewards/margins': 27.419189453125, 'logps/rejected': -423.0556335449219, 'logps/chosen': -54.63783264160156, 'logits/rejected': -1.1218104362487793, 'logits/chosen': -1.1601402759552002, 'epoch': 0.99}
 33%|‚ñà‚ñà‚ñà‚ñé      | 74/222 [44:03<1:28:09, 35.74s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 75/222 [44:38<1:27:21, 35.66s/it]                                                  {'loss': 0.0059, 'grad_norm': 0.008486960083246231, 'learning_rate': 0.00011901559550509078, 'rewards/chosen': -0.21998733282089233, 'rewards/rejected': -23.67982292175293, 'rewards/accuracies': 1.0, 'rewards/margins': 23.459835052490234, 'logps/rejected': -386.19586181640625, 'logps/chosen': -60.217926025390625, 'logits/rejected': -1.1524995565414429, 'logits/chosen': -1.1676712036132812, 'epoch': 1.0}
 34%|‚ñà‚ñà‚ñà‚ñç      | 75/222 [44:38<1:27:21, 35.66s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 76/222 [45:14<1:26:41, 35.63s/it]                                                  {'loss': 0.01, 'grad_norm': 0.011203226633369923, 'learning_rate': 0.0001180233778848872, 'rewards/chosen': -0.22685736417770386, 'rewards/rejected': -22.208770751953125, 'rewards/accuracies': 1.0, 'rewards/margins': 21.981914520263672, 'logps/rejected': -370.2242431640625, 'logps/chosen': -56.960323333740234, 'logits/rejected': -1.1868197917938232, 'logits/chosen': -1.1310760974884033, 'epoch': 1.02}
 34%|‚ñà‚ñà‚ñà‚ñç      | 76/222 [45:14<1:26:41, 35.63s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 77/222 [45:50<1:26:18, 35.71s/it]                                                  {'loss': 0.0132, 'grad_norm': 0.030479421839118004, 'learning_rate': 0.00011702354583738394, 'rewards/chosen': -0.3088582754135132, 'rewards/rejected': -20.270679473876953, 'rewards/accuracies': 1.0, 'rewards/margins': 19.961820602416992, 'logps/rejected': -348.8751525878906, 'logps/chosen': -54.97516632080078, 'logits/rejected': -1.1162426471710205, 'logits/chosen': -1.1039048433303833, 'epoch': 1.03}
 35%|‚ñà‚ñà‚ñà‚ñç      | 77/222 [45:50<1:26:18, 35.71s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 78/222 [46:26<1:26:07, 35.89s/it]                                                  {'loss': 0.0032, 'grad_norm': 0.005866858176887035, 'learning_rate': 0.00011601629958541387, 'rewards/chosen': -0.23730656504631042, 'rewards/rejected': -26.29054832458496, 'rewards/accuracies': 1.0, 'rewards/margins': 26.053241729736328, 'logps/rejected': -405.2159729003906, 'logps/chosen': -57.85590362548828, 'logits/rejected': -1.1551111936569214, 'logits/chosen': -1.1394857168197632, 'epoch': 1.04}
 35%|‚ñà‚ñà‚ñà‚ñå      | 78/222 [46:26<1:26:07, 35.89s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 79/222 [47:01<1:25:13, 35.76s/it]                                                  {'loss': 0.0119, 'grad_norm': 0.01857152208685875, 'learning_rate': 0.00011500184083655235, 'rewards/chosen': -0.18323597311973572, 'rewards/rejected': -20.838769912719727, 'rewards/accuracies': 1.0, 'rewards/margins': 20.655534744262695, 'logps/rejected': -335.02191162109375, 'logps/chosen': -59.4388313293457, 'logits/rejected': -1.1419546604156494, 'logits/chosen': -1.1890769004821777, 'epoch': 1.06}
 36%|‚ñà‚ñà‚ñà‚ñå      | 79/222 [47:01<1:25:13, 35.76s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 80/222 [47:37<1:24:37, 35.75s/it]                                                  {'loss': 0.0133, 'grad_norm': 0.016744909808039665, 'learning_rate': 0.00011398037274272384, 'rewards/chosen': -0.22531910240650177, 'rewards/rejected': -25.854957580566406, 'rewards/accuracies': 1.0, 'rewards/margins': 25.629636764526367, 'logps/rejected': -388.5540771484375, 'logps/chosen': -53.35989761352539, 'logits/rejected': -1.090915560722351, 'logits/chosen': -1.083813190460205, 'epoch': 1.07}
 36%|‚ñà‚ñà‚ñà‚ñå      | 80/222 [47:37<1:24:37, 35.75s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 81/222 [48:13<1:23:58, 35.73s/it]                                                  {'loss': 0.0143, 'grad_norm': 0.015663577243685722, 'learning_rate': 0.00011295209985951943, 'rewards/chosen': -0.17411743104457855, 'rewards/rejected': -21.259008407592773, 'rewards/accuracies': 0.984375, 'rewards/margins': 21.08489227294922, 'logps/rejected': -347.009521484375, 'logps/chosen': -55.50395202636719, 'logits/rejected': -1.1167086362838745, 'logits/chosen': -1.081688404083252, 'epoch': 1.08}
 36%|‚ñà‚ñà‚ñà‚ñã      | 81/222 [48:13<1:23:58, 35.73s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 82/222 [48:49<1:23:26, 35.76s/it]                                                  {'loss': 0.0086, 'grad_norm': 0.01385583821684122, 'learning_rate': 0.00011191722810523332, 'rewards/chosen': -0.1628776341676712, 'rewards/rejected': -25.114940643310547, 'rewards/accuracies': 1.0, 'rewards/margins': 24.952062606811523, 'logps/rejected': -402.4394836425781, 'logps/chosen': -75.63922119140625, 'logits/rejected': -1.1695212125778198, 'logits/chosen': -1.1282212734222412, 'epoch': 1.1}
 37%|‚ñà‚ñà‚ñà‚ñã      | 82/222 [48:49<1:23:26, 35.76s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 83/222 [49:24<1:22:38, 35.67s/it]                                                  {'loss': 0.0035, 'grad_norm': 0.006924217566847801, 'learning_rate': 0.00011087596471962631, 'rewards/chosen': -0.18744345009326935, 'rewards/rejected': -24.041711807250977, 'rewards/accuracies': 1.0, 'rewards/margins': 23.854270935058594, 'logps/rejected': -375.2428283691406, 'logps/chosen': -58.22188186645508, 'logits/rejected': -1.1164826154708862, 'logits/chosen': -1.160672664642334, 'epoch': 1.11}
 37%|‚ñà‚ñà‚ñà‚ñã      | 83/222 [49:24<1:22:38, 35.67s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 84/222 [50:00<1:21:58, 35.64s/it]                                                  {'loss': 0.0072, 'grad_norm': 0.009752891026437283, 'learning_rate': 0.00010982851822242471, 'rewards/chosen': -0.28055843710899353, 'rewards/rejected': -24.067838668823242, 'rewards/accuracies': 1.0, 'rewards/margins': 23.787281036376953, 'logps/rejected': -385.41925048828125, 'logps/chosen': -56.689090728759766, 'logits/rejected': -1.1285139322280884, 'logits/chosen': -1.1089231967926025, 'epoch': 1.12}
 38%|‚ñà‚ñà‚ñà‚ñä      | 84/222 [50:00<1:21:58, 35.64s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 85/222 [50:36<1:21:36, 35.74s/it]                                                  {'loss': 0.0031, 'grad_norm': 0.005927493795752525, 'learning_rate': 0.00010877509837156288, 'rewards/chosen': -0.18631432950496674, 'rewards/rejected': -27.071748733520508, 'rewards/accuracies': 1.0, 'rewards/margins': 26.885433197021484, 'logps/rejected': -412.1245422363281, 'logps/chosen': -62.432315826416016, 'logits/rejected': -1.1364983320236206, 'logits/chosen': -1.1455762386322021, 'epoch': 1.14}
 38%|‚ñà‚ñà‚ñà‚ñä      | 85/222 [50:36<1:21:36, 35.74s/it] 39%|‚ñà‚ñà‚ñà‚ñä      | 86/222 [51:11<1:20:41, 35.60s/it]                                                  {'loss': 0.0077, 'grad_norm': 0.02385162003338337, 'learning_rate': 0.00010771591612117791, 'rewards/chosen': -0.25526219606399536, 'rewards/rejected': -26.169477462768555, 'rewards/accuracies': 1.0, 'rewards/margins': 25.914215087890625, 'logps/rejected': -399.66253662109375, 'logps/chosen': -54.71027374267578, 'logits/rejected': -1.1294479370117188, 'logits/chosen': -1.1296160221099854, 'epoch': 1.15}
 39%|‚ñà‚ñà‚ñà‚ñä      | 86/222 [51:11<1:20:41, 35.60s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 87/222 [51:47<1:20:14, 35.67s/it]                                                  {'loss': 0.0092, 'grad_norm': 0.022683197632431984, 'learning_rate': 0.00010665118357936462, 'rewards/chosen': -0.2736610174179077, 'rewards/rejected': -27.505603790283203, 'rewards/accuracies': 0.984375, 'rewards/margins': 27.23194122314453, 'logps/rejected': -415.1038818359375, 'logps/chosen': -54.05243682861328, 'logits/rejected': -1.1177934408187866, 'logits/chosen': -1.0738708972930908, 'epoch': 1.16}
 39%|‚ñà‚ñà‚ñà‚ñâ      | 87/222 [51:47<1:20:14, 35.67s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 88/222 [52:23<1:19:42, 35.69s/it]                                                  {'loss': 0.0105, 'grad_norm': 0.025998691096901894, 'learning_rate': 0.00010558111396569963, 'rewards/chosen': -0.20636685192584991, 'rewards/rejected': -24.688962936401367, 'rewards/accuracies': 1.0, 'rewards/margins': 24.482595443725586, 'logps/rejected': -397.95269775390625, 'logps/chosen': -53.01585006713867, 'logits/rejected': -1.0834988355636597, 'logits/chosen': -1.058520793914795, 'epoch': 1.18}
 40%|‚ñà‚ñà‚ñà‚ñâ      | 88/222 [52:23<1:19:42, 35.69s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 89/222 [52:58<1:19:08, 35.70s/it]                                                  {'loss': 0.013, 'grad_norm': 0.024749744683504105, 'learning_rate': 0.0001045059215685427, 'rewards/chosen': -0.29858511686325073, 'rewards/rejected': -24.745994567871094, 'rewards/accuracies': 0.984375, 'rewards/margins': 24.447406768798828, 'logps/rejected': -393.8704528808594, 'logps/chosen': -57.86048126220703, 'logits/rejected': -1.154858112335205, 'logits/chosen': -1.0725270509719849, 'epoch': 1.19}
 40%|‚ñà‚ñà‚ñà‚ñà      | 89/222 [52:58<1:19:08, 35.70s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 90/222 [53:34<1:18:21, 35.62s/it]                                                  {'loss': 0.0127, 'grad_norm': 0.04464340582489967, 'learning_rate': 0.00010342582170212403, 'rewards/chosen': -0.39606189727783203, 'rewards/rejected': -24.986644744873047, 'rewards/accuracies': 0.984375, 'rewards/margins': 24.590585708618164, 'logps/rejected': -398.69354248046875, 'logps/chosen': -73.69964599609375, 'logits/rejected': -1.1527645587921143, 'logits/chosen': -1.198272705078125, 'epoch': 1.2}
 41%|‚ñà‚ñà‚ñà‚ñà      | 90/222 [53:34<1:18:21, 35.62s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 91/222 [54:09<1:17:51, 35.66s/it]                                                  {'loss': 0.0045, 'grad_norm': 0.011711256578564644, 'learning_rate': 0.00010234103066342642, 'rewards/chosen': -0.2744241952896118, 'rewards/rejected': -26.51021957397461, 'rewards/accuracies': 1.0, 'rewards/margins': 26.235794067382812, 'logps/rejected': -406.5242004394531, 'logps/chosen': -53.142967224121094, 'logits/rejected': -1.157395362854004, 'logits/chosen': -1.1348758935928345, 'epoch': 1.22}
 41%|‚ñà‚ñà‚ñà‚ñà      | 91/222 [54:09<1:17:51, 35.66s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 92/222 [54:45<1:16:54, 35.50s/it]                                                  {'loss': 0.0109, 'grad_norm': 0.016897156834602356, 'learning_rate': 0.0001012517656888701, 'rewards/chosen': -0.22697670757770538, 'rewards/rejected': -29.766508102416992, 'rewards/accuracies': 1.0, 'rewards/margins': 29.539527893066406, 'logps/rejected': -441.3838195800781, 'logps/chosen': -75.78905487060547, 'logits/rejected': -1.1113754510879517, 'logits/chosen': -1.163798213005066, 'epoch': 1.23}
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 92/222 [54:45<1:16:54, 35.50s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 93/222 [55:20<1:16:31, 35.59s/it]                                                  {'loss': 0.0093, 'grad_norm': 0.023907726630568504, 'learning_rate': 0.00010015824491081003, 'rewards/chosen': -0.27987876534461975, 'rewards/rejected': -26.081161499023438, 'rewards/accuracies': 1.0, 'rewards/margins': 25.801280975341797, 'logps/rejected': -408.3018798828125, 'logps/chosen': -71.59782409667969, 'logits/rejected': -1.070641279220581, 'logits/chosen': -1.0523192882537842, 'epoch': 1.24}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 93/222 [55:20<1:16:31, 35.59s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 94/222 [55:56<1:16:04, 35.66s/it]                                                  {'loss': 0.0073, 'grad_norm': 0.01738474704325199, 'learning_rate': 9.90606873138532e-05, 'rewards/chosen': -0.2129051685333252, 'rewards/rejected': -27.325756072998047, 'rewards/accuracies': 1.0, 'rewards/margins': 27.112850189208984, 'logps/rejected': -409.1883544921875, 'logps/chosen': -60.779449462890625, 'logits/rejected': -1.1052476167678833, 'logits/chosen': -1.0963526964187622, 'epoch': 1.26}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 94/222 [55:56<1:16:04, 35.66s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 95/222 [56:31<1:15:08, 35.50s/it]                                                  {'loss': 0.0023, 'grad_norm': 0.004715597722679377, 'learning_rate': 9.795931269100581e-05, 'rewards/chosen': -0.25163352489471436, 'rewards/rejected': -25.816009521484375, 'rewards/accuracies': 1.0, 'rewards/margins': 25.564374923706055, 'logps/rejected': -391.4686279296875, 'logps/chosen': -51.85352325439453, 'logits/rejected': -1.077921986579895, 'logits/chosen': -1.073878526687622, 'epoch': 1.27}
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 95/222 [56:31<1:15:08, 35.50s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 96/222 [57:07<1:14:41, 35.56s/it]                                                  {'loss': 0.0048, 'grad_norm': 0.009595274925231934, 'learning_rate': 9.685434159965811e-05, 'rewards/chosen': -0.24062664806842804, 'rewards/rejected': -32.58517837524414, 'rewards/accuracies': 1.0, 'rewards/margins': 32.34455871582031, 'logps/rejected': -451.11749267578125, 'logps/chosen': -49.887367248535156, 'logits/rejected': -1.1250104904174805, 'logits/chosen': -1.1299488544464111, 'epoch': 1.28}
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 96/222 [57:07<1:14:41, 35.56s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 97/222 [57:42<1:13:58, 35.51s/it]                                                  {'loss': 0.0137, 'grad_norm': 0.029093515127897263, 'learning_rate': 9.574599531741644e-05, 'rewards/chosen': -0.29503101110458374, 'rewards/rejected': -27.06468391418457, 'rewards/accuracies': 0.984375, 'rewards/margins': 26.769649505615234, 'logps/rejected': -410.44586181640625, 'logps/chosen': -54.799964904785156, 'logits/rejected': -1.1412571668624878, 'logits/chosen': -1.0838629007339478, 'epoch': 1.3}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 97/222 [57:42<1:13:58, 35.51s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 98/222 [58:18<1:13:32, 35.58s/it]                                                  {'loss': 0.0093, 'grad_norm': 0.019623149186372757, 'learning_rate': 9.463449579779094e-05, 'rewards/chosen': -0.2708362340927124, 'rewards/rejected': -31.298782348632812, 'rewards/accuracies': 0.984375, 'rewards/margins': 31.02794647216797, 'logps/rejected': -469.90057373046875, 'logps/chosen': -57.84168243408203, 'logits/rejected': -1.099589467048645, 'logits/chosen': -1.0800907611846924, 'epoch': 1.31}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 98/222 [58:18<1:13:32, 35.58s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 99/222 [58:54<1:13:00, 35.61s/it]                                                  {'loss': 0.0044, 'grad_norm': 0.011807052418589592, 'learning_rate': 9.352006562574794e-05, 'rewards/chosen': -0.2620151937007904, 'rewards/rejected': -40.357208251953125, 'rewards/accuracies': 1.0, 'rewards/margins': 40.095191955566406, 'logps/rejected': -577.5444946289062, 'logps/chosen': -52.21000671386719, 'logits/rejected': -1.0977741479873657, 'logits/chosen': -1.0885788202285767, 'epoch': 1.32}
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 99/222 [58:54<1:13:00, 35.61s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 100/222 [59:30<1:12:36, 35.71s/it]                                                   {'loss': 0.0064, 'grad_norm': 0.014092665165662766, 'learning_rate': 9.240292797313583e-05, 'rewards/chosen': -0.3246862292289734, 'rewards/rejected': -28.034908294677734, 'rewards/accuracies': 1.0, 'rewards/margins': 27.710224151611328, 'logps/rejected': -406.53546142578125, 'logps/chosen': -64.42753601074219, 'logits/rejected': -1.0332119464874268, 'logits/chosen': -1.0873286724090576, 'epoch': 1.34}
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 100/222 [59:30<1:12:36, 35.71s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 101/222 [1:00:06<1:12:02, 35.72s/it]                                                     {'loss': 0.0134, 'grad_norm': 0.021509284153580666, 'learning_rate': 9.128330655399355e-05, 'rewards/chosen': -0.2610313892364502, 'rewards/rejected': -30.554664611816406, 'rewards/accuracies': 1.0, 'rewards/margins': 30.29363250732422, 'logps/rejected': -452.530517578125, 'logps/chosen': -56.62855529785156, 'logits/rejected': -1.1217889785766602, 'logits/chosen': -1.0399689674377441, 'epoch': 1.35}
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 101/222 [1:00:06<1:12:02, 35.72s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 102/222 [1:00:42<1:11:46, 35.89s/it]                                                     {'loss': 0.0104, 'grad_norm': 0.021463239565491676, 'learning_rate': 9.016142557975031e-05, 'rewards/chosen': -0.28452304005622864, 'rewards/rejected': -32.45124816894531, 'rewards/accuracies': 1.0, 'rewards/margins': 32.16672897338867, 'logps/rejected': -476.3714599609375, 'logps/chosen': -59.40573501586914, 'logits/rejected': -1.1578902006149292, 'logits/chosen': -1.0626667737960815, 'epoch': 1.36}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 102/222 [1:00:42<1:11:46, 35.89s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 103/222 [1:01:18<1:11:17, 35.95s/it]                                                     {'loss': 0.0027, 'grad_norm': 0.005352845881134272, 'learning_rate': 8.903750971432584e-05, 'rewards/chosen': -0.32217317819595337, 'rewards/rejected': -33.633819580078125, 'rewards/accuracies': 1.0, 'rewards/margins': 33.3116455078125, 'logps/rejected': -473.1109619140625, 'logps/chosen': -57.803672790527344, 'logits/rejected': -1.0812008380889893, 'logits/chosen': -1.0791430473327637, 'epoch': 1.38}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 103/222 [1:01:18<1:11:17, 35.95s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 104/222 [1:01:53<1:10:19, 35.76s/it]                                                     {'loss': 0.0085, 'grad_norm': 0.01687065325677395, 'learning_rate': 8.791178402914e-05, 'rewards/chosen': -0.17844517529010773, 'rewards/rejected': -30.736589431762695, 'rewards/accuracies': 1.0, 'rewards/margins': 30.55814552307129, 'logps/rejected': -442.36993408203125, 'logps/chosen': -48.9918098449707, 'logits/rejected': -1.0615949630737305, 'logits/chosen': -1.0622234344482422, 'epoch': 1.39}
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 104/222 [1:01:53<1:10:19, 35.76s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 105/222 [1:02:29<1:09:39, 35.72s/it]                                                     {'loss': 0.0025, 'grad_norm': 0.00473009143024683, 'learning_rate': 8.678447395804074e-05, 'rewards/chosen': -0.27892032265663147, 'rewards/rejected': -33.373985290527344, 'rewards/accuracies': 1.0, 'rewards/margins': 33.095062255859375, 'logps/rejected': -457.89959716796875, 'logps/chosen': -60.588653564453125, 'logits/rejected': -1.030390739440918, 'logits/chosen': -1.093238115310669, 'epoch': 1.4}
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 105/222 [1:02:29<1:09:39, 35.72s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 106/222 [1:03:05<1:09:08, 35.77s/it]                                                     {'loss': 0.0041, 'grad_norm': 0.010155826807022095, 'learning_rate': 8.565580525215957e-05, 'rewards/chosen': -0.2507269084453583, 'rewards/rejected': -29.065019607543945, 'rewards/accuracies': 1.0, 'rewards/margins': 28.814294815063477, 'logps/rejected': -427.9975280761719, 'logps/chosen': -65.67411041259766, 'logits/rejected': -1.0574580430984497, 'logits/chosen': -1.0712640285491943, 'epoch': 1.42}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 106/222 [1:03:05<1:09:08, 35.77s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/222 [1:03:40<1:08:29, 35.74s/it]                                                     {'loss': 0.0094, 'grad_norm': 0.011545712128281593, 'learning_rate': 8.45260039347034e-05, 'rewards/chosen': -0.20846661925315857, 'rewards/rejected': -40.636619567871094, 'rewards/accuracies': 0.984375, 'rewards/margins': 40.428157806396484, 'logps/rejected': -555.33154296875, 'logps/chosen': -51.83462142944336, 'logits/rejected': -1.0727847814559937, 'logits/chosen': -1.048734188079834, 'epoch': 1.43}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/222 [1:03:40<1:08:29, 35.74s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 108/222 [1:04:16<1:07:51, 35.72s/it]                                                     {'loss': 0.0091, 'grad_norm': 0.032467592507600784, 'learning_rate': 8.339529625569188e-05, 'rewards/chosen': -0.20906054973602295, 'rewards/rejected': -32.89852523803711, 'rewards/accuracies': 1.0, 'rewards/margins': 32.68946075439453, 'logps/rejected': -462.83306884765625, 'logps/chosen': -51.93350601196289, 'logits/rejected': -1.0413658618927002, 'logits/chosen': -1.062371015548706, 'epoch': 1.44}
 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 108/222 [1:04:16<1:07:51, 35.72s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 109/222 [1:04:52<1:07:20, 35.76s/it]                                                     {'loss': 0.0072, 'grad_norm': 0.011116330511868, 'learning_rate': 8.226390864664947e-05, 'rewards/chosen': -0.30431628227233887, 'rewards/rejected': -29.762554168701172, 'rewards/accuracies': 1.0, 'rewards/margins': 29.45823860168457, 'logps/rejected': -443.3160095214844, 'logps/chosen': -58.41864776611328, 'logits/rejected': -1.0658444166183472, 'logits/chosen': -1.1010339260101318, 'epoch': 1.46}
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 109/222 [1:04:52<1:07:20, 35.76s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 110/222 [1:05:28<1:06:49, 35.80s/it]                                                     {'loss': 0.0118, 'grad_norm': 0.04487544298171997, 'learning_rate': 8.113206767526098e-05, 'rewards/chosen': -0.3386058211326599, 'rewards/rejected': -30.733150482177734, 'rewards/accuracies': 1.0, 'rewards/margins': 30.394542694091797, 'logps/rejected': -450.47515869140625, 'logps/chosen': -58.007083892822266, 'logits/rejected': -1.0711345672607422, 'logits/chosen': -1.0130535364151, 'epoch': 1.47}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 110/222 [1:05:28<1:06:49, 35.80s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 111/222 [1:06:04<1:06:10, 35.77s/it]                                                     {'loss': 0.0084, 'grad_norm': 0.014563034288585186, 'learning_rate': 8e-05, 'rewards/chosen': -0.27595779299736023, 'rewards/rejected': -28.33348274230957, 'rewards/accuracies': 1.0, 'rewards/margins': 28.057525634765625, 'logps/rejected': -410.3034362792969, 'logps/chosen': -71.74530029296875, 'logits/rejected': -1.05735182762146, 'logits/chosen': -1.12613844871521, 'epoch': 1.48}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 111/222 [1:06:04<1:06:10, 35.77s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 112/222 [1:06:39<1:05:41, 35.83s/it]                                                     {'loss': 0.0091, 'grad_norm': 0.011228430084884167, 'learning_rate': 7.886793232473906e-05, 'rewards/chosen': -0.3433169722557068, 'rewards/rejected': -33.167198181152344, 'rewards/accuracies': 0.984375, 'rewards/margins': 32.823883056640625, 'logps/rejected': -480.0567626953125, 'logps/chosen': -59.62034606933594, 'logits/rejected': -1.1409937143325806, 'logits/chosen': -1.0753469467163086, 'epoch': 1.5}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 112/222 [1:06:39<1:05:41, 35.83s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/222 [1:07:15<1:05:01, 35.79s/it]                                                     {'loss': 0.0055, 'grad_norm': 0.01169698778539896, 'learning_rate': 7.773609135335056e-05, 'rewards/chosen': -0.23355817794799805, 'rewards/rejected': -35.91472244262695, 'rewards/accuracies': 1.0, 'rewards/margins': 35.6811637878418, 'logps/rejected': -509.9748229980469, 'logps/chosen': -63.39928436279297, 'logits/rejected': -1.1263422966003418, 'logits/chosen': -1.106747031211853, 'epoch': 1.51}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/222 [1:07:15<1:05:01, 35.79s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 114/222 [1:07:51<1:04:13, 35.68s/it]                                                     {'loss': 0.0028, 'grad_norm': 0.006178066600114107, 'learning_rate': 7.660470374430816e-05, 'rewards/chosen': -0.2700876295566559, 'rewards/rejected': -31.68533706665039, 'rewards/accuracies': 1.0, 'rewards/margins': 31.415252685546875, 'logps/rejected': -465.972412109375, 'logps/chosen': -58.1732177734375, 'logits/rejected': -1.1051456928253174, 'logits/chosen': -1.0994975566864014, 'epoch': 1.52}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 114/222 [1:07:51<1:04:13, 35.68s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 115/222 [1:08:27<1:03:46, 35.76s/it]                                                     {'loss': 0.003, 'grad_norm': 0.006488678511232138, 'learning_rate': 7.547399606529661e-05, 'rewards/chosen': -0.31637758016586304, 'rewards/rejected': -31.914459228515625, 'rewards/accuracies': 1.0, 'rewards/margins': 31.59808349609375, 'logps/rejected': -467.437255859375, 'logps/chosen': -70.91627502441406, 'logits/rejected': -1.1264722347259521, 'logits/chosen': -1.135387659072876, 'epoch': 1.54}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 115/222 [1:08:27<1:03:46, 35.76s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 116/222 [1:09:02<1:02:59, 35.66s/it]                                                     {'loss': 0.0046, 'grad_norm': 0.010475472547113895, 'learning_rate': 7.434419474784044e-05, 'rewards/chosen': -0.3441462516784668, 'rewards/rejected': -28.25568199157715, 'rewards/accuracies': 1.0, 'rewards/margins': 27.911535263061523, 'logps/rejected': -416.47222900390625, 'logps/chosen': -67.93988037109375, 'logits/rejected': -1.0932800769805908, 'logits/chosen': -1.1036076545715332, 'epoch': 1.55}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 116/222 [1:09:02<1:02:59, 35.66s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 117/222 [1:09:38<1:02:39, 35.81s/it]                                                     {'loss': 0.0038, 'grad_norm': 0.008697195909917355, 'learning_rate': 7.32155260419593e-05, 'rewards/chosen': -0.2997327744960785, 'rewards/rejected': -29.882431030273438, 'rewards/accuracies': 1.0, 'rewards/margins': 29.582691192626953, 'logps/rejected': -433.43536376953125, 'logps/chosen': -70.29502868652344, 'logits/rejected': -1.018217921257019, 'logits/chosen': -1.0506194829940796, 'epoch': 1.56}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 117/222 [1:09:38<1:02:39, 35.81s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 118/222 [1:10:14<1:02:04, 35.81s/it]                                                     {'loss': 0.0059, 'grad_norm': 0.012740976177155972, 'learning_rate': 7.208821597086003e-05, 'rewards/chosen': -0.23211058974266052, 'rewards/rejected': -35.69202423095703, 'rewards/accuracies': 1.0, 'rewards/margins': 35.45991134643555, 'logps/rejected': -493.3572998046875, 'logps/chosen': -57.1745719909668, 'logits/rejected': -1.0555344820022583, 'logits/chosen': -1.0398736000061035, 'epoch': 1.58}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 118/222 [1:10:14<1:02:04, 35.81s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 119/222 [1:10:50<1:01:20, 35.74s/it]                                                     {'loss': 0.0015, 'grad_norm': 0.003980325069278479, 'learning_rate': 7.096249028567419e-05, 'rewards/chosen': -0.24592892825603485, 'rewards/rejected': -34.39198303222656, 'rewards/accuracies': 1.0, 'rewards/margins': 34.146053314208984, 'logps/rejected': -480.0052795410156, 'logps/chosen': -57.65284729003906, 'logits/rejected': -1.02101731300354, 'logits/chosen': -1.0653616189956665, 'epoch': 1.59}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 119/222 [1:10:50<1:01:20, 35.74s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 120/222 [1:11:25<1:00:40, 35.69s/it]                                                     {'loss': 0.0052, 'grad_norm': 0.011618549935519695, 'learning_rate': 6.98385744202497e-05, 'rewards/chosen': -0.35530683398246765, 'rewards/rejected': -28.75580596923828, 'rewards/accuracies': 1.0, 'rewards/margins': 28.400495529174805, 'logps/rejected': -427.77325439453125, 'logps/chosen': -69.25321197509766, 'logits/rejected': -1.0883331298828125, 'logits/chosen': -1.0392532348632812, 'epoch': 1.6}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 120/222 [1:11:25<1:00:40, 35.69s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 121/222 [1:12:00<59:41, 35.46s/it]                                                     {'loss': 0.0062, 'grad_norm': 0.009196660481393337, 'learning_rate': 6.871669344600648e-05, 'rewards/chosen': -0.22238172590732574, 'rewards/rejected': -36.14326858520508, 'rewards/accuracies': 1.0, 'rewards/margins': 35.9208869934082, 'logps/rejected': -506.36328125, 'logps/chosen': -57.41395568847656, 'logits/rejected': -1.1154032945632935, 'logits/chosen': -1.0802539587020874, 'epoch': 1.62}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 121/222 [1:12:00<59:41, 35.46s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 122/222 [1:12:36<59:17, 35.57s/it]                                                   {'loss': 0.0166, 'grad_norm': 0.040882885456085205, 'learning_rate': 6.759707202686418e-05, 'rewards/chosen': -0.3884444236755371, 'rewards/rejected': -35.51288604736328, 'rewards/accuracies': 1.0, 'rewards/margins': 35.124446868896484, 'logps/rejected': -483.28912353515625, 'logps/chosen': -63.568267822265625, 'logits/rejected': -1.008193850517273, 'logits/chosen': -1.0728431940078735, 'epoch': 1.63}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 122/222 [1:12:36<59:17, 35.57s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 123/222 [1:13:12<58:47, 35.63s/it]                                                   {'loss': 0.0024, 'grad_norm': 0.005658815614879131, 'learning_rate': 6.64799343742521e-05, 'rewards/chosen': -0.3394196331501007, 'rewards/rejected': -41.96503829956055, 'rewards/accuracies': 1.0, 'rewards/margins': 41.625614166259766, 'logps/rejected': -559.632080078125, 'logps/chosen': -54.17317199707031, 'logits/rejected': -1.0696022510528564, 'logits/chosen': -1.0226634740829468, 'epoch': 1.64}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 123/222 [1:13:12<58:47, 35.63s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 124/222 [1:13:47<58:15, 35.67s/it]                                                   {'loss': 0.0132, 'grad_norm': 0.016029750928282738, 'learning_rate': 6.536550420220907e-05, 'rewards/chosen': -0.3429744839668274, 'rewards/rejected': -36.13720703125, 'rewards/accuracies': 1.0, 'rewards/margins': 35.79423141479492, 'logps/rejected': -500.46673583984375, 'logps/chosen': -74.7947769165039, 'logits/rejected': -1.101157307624817, 'logits/chosen': -1.1000316143035889, 'epoch': 1.66}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 124/222 [1:13:47<58:15, 35.67s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 125/222 [1:14:23<57:38, 35.66s/it]                                                   {'loss': 0.003, 'grad_norm': 0.011603135615587234, 'learning_rate': 6.425400468258358e-05, 'rewards/chosen': -0.2838220000267029, 'rewards/rejected': -40.45542907714844, 'rewards/accuracies': 1.0, 'rewards/margins': 40.171607971191406, 'logps/rejected': -534.0653686523438, 'logps/chosen': -68.11167907714844, 'logits/rejected': -0.9679962396621704, 'logits/chosen': -1.086499810218811, 'epoch': 1.67}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 125/222 [1:14:23<57:38, 35.66s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 126/222 [1:14:59<57:11, 35.75s/it]                                                   {'loss': 0.0098, 'grad_norm': 0.019556807354092598, 'learning_rate': 6.314565840034192e-05, 'rewards/chosen': -0.24193789064884186, 'rewards/rejected': -38.25096130371094, 'rewards/accuracies': 0.984375, 'rewards/margins': 38.00902557373047, 'logps/rejected': -520.749267578125, 'logps/chosen': -57.05142593383789, 'logits/rejected': -1.0482655763626099, 'logits/chosen': -0.9954992532730103, 'epoch': 1.68}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 126/222 [1:14:59<57:11, 35.75s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 127/222 [1:15:35<56:49, 35.89s/it]                                                   {'loss': 0.0038, 'grad_norm': 0.00750519847497344, 'learning_rate': 6.204068730899419e-05, 'rewards/chosen': -0.2779392898082733, 'rewards/rejected': -29.95285415649414, 'rewards/accuracies': 1.0, 'rewards/margins': 29.674917221069336, 'logps/rejected': -421.8115234375, 'logps/chosen': -58.46326446533203, 'logits/rejected': -1.0107808113098145, 'logits/chosen': -1.0810643434524536, 'epoch': 1.7}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 127/222 [1:15:35<56:49, 35.89s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 128/222 [1:16:11<56:10, 35.86s/it]                                                   {'loss': 0.0027, 'grad_norm': 0.00785757228732109, 'learning_rate': 6.093931268614682e-05, 'rewards/chosen': -0.29804757237434387, 'rewards/rejected': -30.638051986694336, 'rewards/accuracies': 1.0, 'rewards/margins': 30.340002059936523, 'logps/rejected': -429.598876953125, 'logps/chosen': -72.72965240478516, 'logits/rejected': -0.9852582216262817, 'logits/chosen': -1.0356054306030273, 'epoch': 1.71}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 128/222 [1:16:11<56:10, 35.86s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 129/222 [1:16:47<55:30, 35.81s/it]                                                   {'loss': 0.0132, 'grad_norm': 0.01986558549106121, 'learning_rate': 5.9841755089190005e-05, 'rewards/chosen': -0.2925354540348053, 'rewards/rejected': -36.54935073852539, 'rewards/accuracies': 1.0, 'rewards/margins': 36.256813049316406, 'logps/rejected': -512.5971069335938, 'logps/chosen': -57.322364807128906, 'logits/rejected': -1.025001049041748, 'logits/chosen': -1.069669246673584, 'epoch': 1.72}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 129/222 [1:16:47<55:30, 35.81s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 130/222 [1:17:22<54:40, 35.66s/it]                                                   {'loss': 0.0033, 'grad_norm': 0.0077026840299367905, 'learning_rate': 5.8748234311129914e-05, 'rewards/chosen': -0.31637129187583923, 'rewards/rejected': -32.68990707397461, 'rewards/accuracies': 1.0, 'rewards/margins': 32.37353515625, 'logps/rejected': -464.11541748046875, 'logps/chosen': -60.53367614746094, 'logits/rejected': -1.0351450443267822, 'logits/chosen': -1.0051944255828857, 'epoch': 1.74}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 130/222 [1:17:22<54:40, 35.66s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 131/222 [1:17:58<54:14, 35.77s/it]                                                   {'loss': 0.002, 'grad_norm': 0.005849676672369242, 'learning_rate': 5.76589693365736e-05, 'rewards/chosen': -0.3065953254699707, 'rewards/rejected': -35.801918029785156, 'rewards/accuracies': 1.0, 'rewards/margins': 35.49531936645508, 'logps/rejected': -503.4083557128906, 'logps/chosen': -50.11384201049805, 'logits/rejected': -1.061745285987854, 'logits/chosen': -1.0064852237701416, 'epoch': 1.75}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 131/222 [1:17:58<54:14, 35.77s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 132/222 [1:18:34<53:36, 35.74s/it]                                                   {'loss': 0.0049, 'grad_norm': 0.009133197367191315, 'learning_rate': 5.657417829787598e-05, 'rewards/chosen': -0.26557037234306335, 'rewards/rejected': -30.519893646240234, 'rewards/accuracies': 1.0, 'rewards/margins': 30.254322052001953, 'logps/rejected': -462.5104675292969, 'logps/chosen': -64.95034790039062, 'logits/rejected': -1.022756814956665, 'logits/chosen': -1.0522871017456055, 'epoch': 1.76}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 132/222 [1:18:34<53:36, 35.74s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 133/222 [1:19:09<52:47, 35.59s/it]                                                   {'loss': 0.0078, 'grad_norm': 0.013165955431759357, 'learning_rate': 5.5494078431457334e-05, 'rewards/chosen': -0.28093841671943665, 'rewards/rejected': -37.691429138183594, 'rewards/accuracies': 1.0, 'rewards/margins': 37.410491943359375, 'logps/rejected': -511.89141845703125, 'logps/chosen': -53.39306640625, 'logits/rejected': -1.0430680513381958, 'logits/chosen': -1.0136082172393799, 'epoch': 1.78}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 133/222 [1:19:09<52:47, 35.59s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 134/222 [1:19:45<52:26, 35.75s/it]                                                   {'loss': 0.0028, 'grad_norm': 0.011051255278289318, 'learning_rate': 5.4418886034300386e-05, 'rewards/chosen': -0.2733364701271057, 'rewards/rejected': -37.921142578125, 'rewards/accuracies': 1.0, 'rewards/margins': 37.647804260253906, 'logps/rejected': -530.5694580078125, 'logps/chosen': -66.83952331542969, 'logits/rejected': -1.0441269874572754, 'logits/chosen': -1.0540887117385864, 'epoch': 1.79}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 134/222 [1:19:45<52:26, 35.75s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 135/222 [1:20:21<51:45, 35.69s/it]                                                   {'loss': 0.0101, 'grad_norm': 0.01775745116174221, 'learning_rate': 5.33488164206354e-05, 'rewards/chosen': -0.2565554082393646, 'rewards/rejected': -42.6790771484375, 'rewards/accuracies': 1.0, 'rewards/margins': 42.422523498535156, 'logps/rejected': -562.8384399414062, 'logps/chosen': -56.80677032470703, 'logits/rejected': -1.0023705959320068, 'logits/chosen': -1.020351767539978, 'epoch': 1.8}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 135/222 [1:20:21<51:45, 35.69s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 136/222 [1:20:56<51:13, 35.74s/it]                                                   {'loss': 0.0043, 'grad_norm': 0.010293244384229183, 'learning_rate': 5.228408387882214e-05, 'rewards/chosen': -0.3265444040298462, 'rewards/rejected': -32.9387092590332, 'rewards/accuracies': 1.0, 'rewards/margins': 32.612159729003906, 'logps/rejected': -465.824462890625, 'logps/chosen': -73.1569595336914, 'logits/rejected': -1.1063504219055176, 'logits/chosen': -1.0585957765579224, 'epoch': 1.82}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 136/222 [1:20:56<51:13, 35.74s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 137/222 [1:21:32<50:41, 35.78s/it]                                                   {'loss': 0.0015, 'grad_norm': 0.006746910512447357, 'learning_rate': 5.122490162843714e-05, 'rewards/chosen': -0.314037024974823, 'rewards/rejected': -34.292030334472656, 'rewards/accuracies': 1.0, 'rewards/margins': 33.977996826171875, 'logps/rejected': -456.0357360839844, 'logps/chosen': -66.1550521850586, 'logits/rejected': -1.0466389656066895, 'logits/chosen': -1.1062575578689575, 'epoch': 1.83}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 137/222 [1:21:32<50:41, 35.78s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 138/222 [1:22:08<50:00, 35.72s/it]                                                   {'loss': 0.0014, 'grad_norm': 0.0033847568556666374, 'learning_rate': 5.0171481777575324e-05, 'rewards/chosen': -0.40582218766212463, 'rewards/rejected': -43.217437744140625, 'rewards/accuracies': 1.0, 'rewards/margins': 42.811614990234375, 'logps/rejected': -564.924560546875, 'logps/chosen': -64.70529174804688, 'logits/rejected': -1.0038995742797852, 'logits/chosen': -1.1051623821258545, 'epoch': 1.84}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 138/222 [1:22:08<50:00, 35.72s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 139/222 [1:22:44<49:27, 35.75s/it]                                                   {'loss': 0.0082, 'grad_norm': 0.015933014452457428, 'learning_rate': 4.9124035280373694e-05, 'rewards/chosen': -0.4440581202507019, 'rewards/rejected': -33.444541931152344, 'rewards/accuracies': 1.0, 'rewards/margins': 33.00048828125, 'logps/rejected': -465.19842529296875, 'logps/chosen': -63.26249694824219, 'logits/rejected': -1.056601643562317, 'logits/chosen': -1.1056464910507202, 'epoch': 1.86}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 139/222 [1:22:44<49:27, 35.75s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 140/222 [1:23:20<48:58, 35.83s/it]                                                   {'loss': 0.0011, 'grad_norm': 0.003514218609780073, 'learning_rate': 4.80827718947667e-05, 'rewards/chosen': -0.2823904752731323, 'rewards/rejected': -46.514976501464844, 'rewards/accuracies': 1.0, 'rewards/margins': 46.23258590698242, 'logps/rejected': -624.0299072265625, 'logps/chosen': -54.253929138183594, 'logits/rejected': -1.063913106918335, 'logits/chosen': -1.0130620002746582, 'epoch': 1.87}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 140/222 [1:23:20<48:58, 35.83s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 141/222 [1:23:55<48:09, 35.68s/it]                                                   {'loss': 0.0016, 'grad_norm': 0.0042855944484472275, 'learning_rate': 4.70479001404806e-05, 'rewards/chosen': -0.2896544635295868, 'rewards/rejected': -39.358272552490234, 'rewards/accuracies': 1.0, 'rewards/margins': 39.06862258911133, 'logps/rejected': -544.076171875, 'logps/chosen': -63.78218078613281, 'logits/rejected': -1.0774672031402588, 'logits/chosen': -1.0897698402404785, 'epoch': 1.88}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 141/222 [1:23:55<48:09, 35.68s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 142/222 [1:24:31<47:31, 35.64s/it]                                                   {'loss': 0.0078, 'grad_norm': 0.012906479649245739, 'learning_rate': 4.601962725727617e-05, 'rewards/chosen': -0.5238576531410217, 'rewards/rejected': -37.421363830566406, 'rewards/accuracies': 0.984375, 'rewards/margins': 36.89750671386719, 'logps/rejected': -511.9256286621094, 'logps/chosen': -66.84728240966797, 'logits/rejected': -0.9491955041885376, 'logits/chosen': -1.0369722843170166, 'epoch': 1.9}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 142/222 [1:24:31<47:31, 35.64s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 143/222 [1:25:07<47:06, 35.78s/it]                                                   {'loss': 0.0077, 'grad_norm': 0.01810436323285103, 'learning_rate': 4.499815916344769e-05, 'rewards/chosen': -0.27719733119010925, 'rewards/rejected': -36.94181823730469, 'rewards/accuracies': 1.0, 'rewards/margins': 36.66461944580078, 'logps/rejected': -508.5854797363281, 'logps/chosen': -78.90086364746094, 'logits/rejected': -0.9946848154067993, 'logits/chosen': -1.0834401845932007, 'epoch': 1.91}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 143/222 [1:25:07<47:06, 35.78s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 144/222 [1:25:43<46:35, 35.84s/it]                                                   {'loss': 0.0025, 'grad_norm': 0.005002138204872608, 'learning_rate': 4.398370041458613e-05, 'rewards/chosen': -0.2482491284608841, 'rewards/rejected': -43.12896728515625, 'rewards/accuracies': 1.0, 'rewards/margins': 42.88071823120117, 'logps/rejected': -551.698974609375, 'logps/chosen': -54.682395935058594, 'logits/rejected': -0.966455340385437, 'logits/chosen': -1.045654296875, 'epoch': 1.92}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 144/222 [1:25:43<46:35, 35.84s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 145/222 [1:26:19<45:59, 35.84s/it]                                                   {'loss': 0.0104, 'grad_norm': 0.05519209802150726, 'learning_rate': 4.297645416261611e-05, 'rewards/chosen': -0.4441068172454834, 'rewards/rejected': -44.22601318359375, 'rewards/accuracies': 0.984375, 'rewards/margins': 43.78190994262695, 'logps/rejected': -593.34228515625, 'logps/chosen': -73.65911102294922, 'logits/rejected': -1.0666730403900146, 'logits/chosen': -1.0321238040924072, 'epoch': 1.94}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 145/222 [1:26:19<45:59, 35.84s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 146/222 [1:26:54<45:07, 35.63s/it]                                                   {'loss': 0.002, 'grad_norm': 0.0047002858482301235, 'learning_rate': 4.1976622115112795e-05, 'rewards/chosen': -0.3605444133281708, 'rewards/rejected': -38.25959014892578, 'rewards/accuracies': 1.0, 'rewards/margins': 37.8990478515625, 'logps/rejected': -519.0711669921875, 'logps/chosen': -74.60247802734375, 'logits/rejected': -1.0593138933181763, 'logits/chosen': -1.1066313982009888, 'epoch': 1.95}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 146/222 [1:26:54<45:07, 35.63s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 147/222 [1:27:30<44:40, 35.74s/it]                                                   {'loss': 0.0012, 'grad_norm': 0.004194289445877075, 'learning_rate': 4.098440449490926e-05, 'rewards/chosen': -0.31544286012649536, 'rewards/rejected': -45.341617584228516, 'rewards/accuracies': 1.0, 'rewards/margins': 45.02617645263672, 'logps/rejected': -606.2128295898438, 'logps/chosen': -65.47200012207031, 'logits/rejected': -1.0198607444763184, 'logits/chosen': -1.0954251289367676, 'epoch': 1.96}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 147/222 [1:27:30<44:40, 35.74s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 148/222 [1:28:05<44:06, 35.76s/it]                                                   {'loss': 0.0116, 'grad_norm': 0.018775489181280136, 'learning_rate': 4.0000000000000024e-05, 'rewards/chosen': -0.3306203782558441, 'rewards/rejected': -41.85881042480469, 'rewards/accuracies': 1.0, 'rewards/margins': 41.52819061279297, 'logps/rejected': -562.2210083007812, 'logps/chosen': -56.75264358520508, 'logits/rejected': -1.0393906831741333, 'logits/chosen': -1.0107301473617554, 'epoch': 1.98}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 148/222 [1:28:05<44:06, 35.76s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 149/222 [1:28:41<43:35, 35.83s/it]                                                   {'loss': 0.0093, 'grad_norm': 0.015207192860543728, 'learning_rate': 3.9023605763750876e-05, 'rewards/chosen': -0.2592739164829254, 'rewards/rejected': -42.02553176879883, 'rewards/accuracies': 1.0, 'rewards/margins': 41.76625442504883, 'logps/rejected': -539.086669921875, 'logps/chosen': -63.434303283691406, 'logits/rejected': -0.9575031399726868, 'logits/chosen': -0.9925500750541687, 'epoch': 1.99}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 149/222 [1:28:41<43:35, 35.83s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 150/222 [1:29:17<42:59, 35.83s/it]                                                   {'loss': 0.0017, 'grad_norm': 0.005270081106573343, 'learning_rate': 3.805541731542148e-05, 'rewards/chosen': -0.34082794189453125, 'rewards/rejected': -43.015960693359375, 'rewards/accuracies': 1.0, 'rewards/margins': 42.67512893676758, 'logps/rejected': -555.386962890625, 'logps/chosen': -61.119911193847656, 'logits/rejected': -1.0314968824386597, 'logits/chosen': -1.0560823678970337, 'epoch': 2.0}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 150/222 [1:29:17<42:59, 35.83s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 151/222 [1:29:52<42:08, 35.61s/it]                                                   {'loss': 0.0084, 'grad_norm': 0.024157226085662842, 'learning_rate': 3.709562854100941e-05, 'rewards/chosen': -0.29500168561935425, 'rewards/rejected': -39.121124267578125, 'rewards/accuracies': 1.0, 'rewards/margins': 38.82612228393555, 'logps/rejected': -517.0643920898438, 'logps/chosen': -48.08407211303711, 'logits/rejected': -1.0573198795318604, 'logits/chosen': -1.0191184282302856, 'epoch': 2.02}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 151/222 [1:29:52<42:08, 35.61s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 152/222 [1:30:28<41:33, 35.62s/it]                                                   {'loss': 0.0013, 'grad_norm': 0.0033743055537343025, 'learning_rate': 3.6144431644423226e-05, 'rewards/chosen': -0.20999817550182343, 'rewards/rejected': -48.992576599121094, 'rewards/accuracies': 1.0, 'rewards/margins': 48.78258514404297, 'logps/rejected': -619.1749877929688, 'logps/chosen': -63.19668960571289, 'logits/rejected': -0.9706370234489441, 'logits/chosen': -1.0503240823745728, 'epoch': 2.03}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 152/222 [1:30:28<41:33, 35.62s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 153/222 [1:31:04<41:00, 35.66s/it]                                                   {'loss': 0.0013, 'grad_norm': 0.0037581096403300762, 'learning_rate': 3.520201710899238e-05, 'rewards/chosen': -0.37584927678108215, 'rewards/rejected': -32.51664352416992, 'rewards/accuracies': 1.0, 'rewards/margins': 32.14079284667969, 'logps/rejected': -442.3968505859375, 'logps/chosen': -61.558902740478516, 'logits/rejected': -1.0031239986419678, 'logits/chosen': -1.0488207340240479, 'epoch': 2.04}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 153/222 [1:31:04<41:00, 35.66s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 154/222 [1:31:40<40:26, 35.68s/it]                                                   {'loss': 0.0149, 'grad_norm': 0.033518001437187195, 'learning_rate': 3.426857365932171e-05, 'rewards/chosen': -0.31033095717430115, 'rewards/rejected': -44.25395202636719, 'rewards/accuracies': 0.96875, 'rewards/margins': 43.94361877441406, 'logps/rejected': -584.1033325195312, 'logps/chosen': -74.67217254638672, 'logits/rejected': -1.0786899328231812, 'logits/chosen': -1.073948860168457, 'epoch': 2.06}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 154/222 [1:31:40<40:26, 35.68s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 155/222 [1:32:15<39:43, 35.58s/it]                                                   {'loss': 0.0074, 'grad_norm': 0.012139114551246166, 'learning_rate': 3.334428822349813e-05, 'rewards/chosen': -0.29213255643844604, 'rewards/rejected': -39.99098587036133, 'rewards/accuracies': 1.0, 'rewards/margins': 39.6988525390625, 'logps/rejected': -529.1625366210938, 'logps/chosen': -56.46006774902344, 'logits/rejected': -1.0609962940216064, 'logits/chosen': -1.0536555051803589, 'epoch': 2.07}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 155/222 [1:32:15<39:43, 35.58s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 156/222 [1:32:51<39:16, 35.70s/it]                                                   {'loss': 0.0023, 'grad_norm': 0.005976577755063772, 'learning_rate': 3.242934589565708e-05, 'rewards/chosen': -0.2849633991718292, 'rewards/rejected': -48.871803283691406, 'rewards/accuracies': 1.0, 'rewards/margins': 48.58683776855469, 'logps/rejected': -630.1680908203125, 'logps/chosen': -56.097999572753906, 'logits/rejected': -0.959178626537323, 'logits/chosen': -1.0012699365615845, 'epoch': 2.08}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 156/222 [1:32:51<39:16, 35.70s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 157/222 [1:33:27<38:41, 35.71s/it]                                                   {'loss': 0.0013, 'grad_norm': 0.003985080402344465, 'learning_rate': 3.152392989891615e-05, 'rewards/chosen': -0.3372972011566162, 'rewards/rejected': -36.84459686279297, 'rewards/accuracies': 1.0, 'rewards/margins': 36.507301330566406, 'logps/rejected': -496.4091796875, 'logps/chosen': -55.366981506347656, 'logits/rejected': -1.0334041118621826, 'logits/chosen': -1.0593304634094238, 'epoch': 2.1}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 157/222 [1:33:27<38:41, 35.71s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 158/222 [1:34:02<37:59, 35.62s/it]                                                   {'loss': 0.0027, 'grad_norm': 0.006622431334108114, 'learning_rate': 3.0628221548683606e-05, 'rewards/chosen': -0.3562203049659729, 'rewards/rejected': -43.68764877319336, 'rewards/accuracies': 1.0, 'rewards/margins': 43.33142852783203, 'logps/rejected': -571.8992919921875, 'logps/chosen': -66.13133239746094, 'logits/rejected': -1.0205097198486328, 'logits/chosen': -1.0649898052215576, 'epoch': 2.11}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 158/222 [1:34:02<37:59, 35.62s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 159/222 [1:34:38<37:33, 35.77s/it]                                                   {'loss': 0.0038, 'grad_norm': 0.008598949760198593, 'learning_rate': 2.974240021634861e-05, 'rewards/chosen': -0.34168267250061035, 'rewards/rejected': -34.301734924316406, 'rewards/accuracies': 1.0, 'rewards/margins': 33.96004867553711, 'logps/rejected': -473.88226318359375, 'logps/chosen': -61.77387237548828, 'logits/rejected': -1.0507725477218628, 'logits/chosen': -1.0161584615707397, 'epoch': 2.12}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 159/222 [1:34:38<37:33, 35.77s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 160/222 [1:35:14<36:55, 35.73s/it]                                                   {'loss': 0.0021, 'grad_norm': 0.005433923564851284, 'learning_rate': 2.886664329336123e-05, 'rewards/chosen': -0.3169720470905304, 'rewards/rejected': -49.47916030883789, 'rewards/accuracies': 1.0, 'rewards/margins': 49.16218566894531, 'logps/rejected': -640.352294921875, 'logps/chosen': -48.774658203125, 'logits/rejected': -1.0154013633728027, 'logits/chosen': -1.0114927291870117, 'epoch': 2.14}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 160/222 [1:35:14<36:55, 35.73s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 161/222 [1:35:49<36:15, 35.66s/it]                                                   {'loss': 0.0077, 'grad_norm': 0.011854221113026142, 'learning_rate': 2.800112615570826e-05, 'rewards/chosen': -0.2835979461669922, 'rewards/rejected': -42.35220718383789, 'rewards/accuracies': 1.0, 'rewards/margins': 42.068607330322266, 'logps/rejected': -555.314697265625, 'logps/chosen': -63.000282287597656, 'logits/rejected': -1.0686687231063843, 'logits/chosen': -1.0700273513793945, 'epoch': 2.15}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 161/222 [1:35:49<36:15, 35.66s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 162/222 [1:36:25<35:41, 35.68s/it]                                                   {'loss': 0.0038, 'grad_norm': 0.012397189624607563, 'learning_rate': 2.7146022128793502e-05, 'rewards/chosen': -0.2981412410736084, 'rewards/rejected': -53.400901794433594, 'rewards/accuracies': 1.0, 'rewards/margins': 53.102760314941406, 'logps/rejected': -696.2915649414062, 'logps/chosen': -51.913570404052734, 'logits/rejected': -1.0196902751922607, 'logits/chosen': -1.0075161457061768, 'epoch': 2.16}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 162/222 [1:36:25<35:41, 35.68s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 163/222 [1:37:00<34:59, 35.59s/it]                                                   {'loss': 0.0014, 'grad_norm': 0.0038899248465895653, 'learning_rate': 2.630150245272777e-05, 'rewards/chosen': -0.4068514406681061, 'rewards/rejected': -49.74258041381836, 'rewards/accuracies': 1.0, 'rewards/margins': 49.33572769165039, 'logps/rejected': -648.9168090820312, 'logps/chosen': -73.17730712890625, 'logits/rejected': -1.0658646821975708, 'logits/chosen': -1.0560327768325806, 'epoch': 2.18}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 163/222 [1:37:00<34:59, 35.59s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 164/222 [1:37:36<34:30, 35.70s/it]                                                   {'loss': 0.0029, 'grad_norm': 0.006432278547435999, 'learning_rate': 2.546773624803739e-05, 'rewards/chosen': -0.26693618297576904, 'rewards/rejected': -41.921329498291016, 'rewards/accuracies': 1.0, 'rewards/margins': 41.65439224243164, 'logps/rejected': -560.0857543945312, 'logps/chosen': -64.86576843261719, 'logits/rejected': -1.0125608444213867, 'logits/chosen': -1.1032915115356445, 'epoch': 2.19}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 164/222 [1:37:36<34:30, 35.70s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 165/222 [1:38:12<33:51, 35.64s/it]                                                   {'loss': 0.005, 'grad_norm': 0.009437108412384987, 'learning_rate': 2.4644890481796316e-05, 'rewards/chosen': -0.31473276019096375, 'rewards/rejected': -43.844730377197266, 'rewards/accuracies': 1.0, 'rewards/margins': 43.529998779296875, 'logps/rejected': -580.164794921875, 'logps/chosen': -56.67629623413086, 'logits/rejected': -1.074127197265625, 'logits/chosen': -1.0540990829467773, 'epoch': 2.2}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 165/222 [1:38:12<33:51, 35.64s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 166/222 [1:38:47<33:16, 35.65s/it]                                                   {'loss': 0.0074, 'grad_norm': 0.015156740322709084, 'learning_rate': 2.38331299341902e-05, 'rewards/chosen': -0.2386144995689392, 'rewards/rejected': -41.74319839477539, 'rewards/accuracies': 0.984375, 'rewards/margins': 41.50458526611328, 'logps/rejected': -548.9461669921875, 'logps/chosen': -62.58234786987305, 'logits/rejected': -0.9997109770774841, 'logits/chosen': -1.08780837059021, 'epoch': 2.22}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 166/222 [1:38:48<33:16, 35.65s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 167/222 [1:39:24<32:47, 35.78s/it]                                                   {'loss': 0.0056, 'grad_norm': 0.016314655542373657, 'learning_rate': 2.3032617165517966e-05, 'rewards/chosen': -0.3706187605857849, 'rewards/rejected': -47.59782409667969, 'rewards/accuracies': 0.984375, 'rewards/margins': 47.227210998535156, 'logps/rejected': -613.8400268554688, 'logps/chosen': -65.41380310058594, 'logits/rejected': -1.0504966974258423, 'logits/chosen': -1.0215067863464355, 'epoch': 2.23}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 167/222 [1:39:24<32:47, 35.78s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 168/222 [1:39:59<32:13, 35.80s/it]                                                   {'loss': 0.0093, 'grad_norm': 0.012126949615776539, 'learning_rate': 2.2243512483638046e-05, 'rewards/chosen': -0.38785696029663086, 'rewards/rejected': -40.8856315612793, 'rewards/accuracies': 0.984375, 'rewards/margins': 40.49777603149414, 'logps/rejected': -544.717529296875, 'logps/chosen': -73.32683563232422, 'logits/rejected': -1.027469515800476, 'logits/chosen': -1.1243666410446167, 'epoch': 2.24}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 168/222 [1:39:59<32:13, 35.80s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 169/222 [1:40:35<31:30, 35.67s/it]                                                   {'loss': 0.0061, 'grad_norm': 0.013757963664829731, 'learning_rate': 2.1465973911865737e-05, 'rewards/chosen': -0.5142646431922913, 'rewards/rejected': -43.574867248535156, 'rewards/accuracies': 1.0, 'rewards/margins': 43.06060028076172, 'logps/rejected': -578.3513793945312, 'logps/chosen': -71.55127716064453, 'logits/rejected': -0.9925701022148132, 'logits/chosen': -1.0661882162094116, 'epoch': 2.26}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 169/222 [1:40:35<31:30, 35.67s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 170/222 [1:41:10<30:50, 35.60s/it]                                                   {'loss': 0.003, 'grad_norm': 0.008489860221743584, 'learning_rate': 2.070015715732801e-05, 'rewards/chosen': -0.3495262861251831, 'rewards/rejected': -44.64318084716797, 'rewards/accuracies': 1.0, 'rewards/margins': 44.29365158081055, 'logps/rejected': -578.0944213867188, 'logps/chosen': -68.00904846191406, 'logits/rejected': -0.9729824662208557, 'logits/chosen': -0.9874386787414551, 'epoch': 2.27}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 170/222 [1:41:10<30:50, 35.60s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 171/222 [1:41:46<30:18, 35.66s/it]                                                   {'loss': 0.0012, 'grad_norm': 0.0032056202180683613, 'learning_rate': 1.9946215579782048e-05, 'rewards/chosen': -0.32819944620132446, 'rewards/rejected': -38.93697738647461, 'rewards/accuracies': 1.0, 'rewards/margins': 38.60877990722656, 'logps/rejected': -525.99853515625, 'logps/chosen': -59.33768844604492, 'logits/rejected': -1.058579444885254, 'logits/chosen': -0.9782246947288513, 'epoch': 2.28}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 171/222 [1:41:46<30:18, 35.66s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 172/222 [1:42:22<29:47, 35.75s/it]                                                   {'loss': 0.0078, 'grad_norm': 0.015598434023559093, 'learning_rate': 1.920430016090422e-05, 'rewards/chosen': -0.44864359498023987, 'rewards/rejected': -47.94049835205078, 'rewards/accuracies': 1.0, 'rewards/margins': 47.491859436035156, 'logps/rejected': -625.797607421875, 'logps/chosen': -70.67420959472656, 'logits/rejected': -1.0300414562225342, 'logits/chosen': -1.0448423624038696, 'epoch': 2.3}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 172/222 [1:42:22<29:47, 35.75s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 173/222 [1:42:58<29:09, 35.70s/it]                                                   {'loss': 0.009, 'grad_norm': 0.01555976364761591, 'learning_rate': 1.8474559474054653e-05, 'rewards/chosen': -0.3544744551181793, 'rewards/rejected': -33.450157165527344, 'rewards/accuracies': 0.984375, 'rewards/margins': 33.09568786621094, 'logps/rejected': -461.3877868652344, 'logps/chosen': -63.829322814941406, 'logits/rejected': -1.0331361293792725, 'logits/chosen': -1.0963984727859497, 'epoch': 2.31}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 173/222 [1:42:58<29:09, 35.70s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 174/222 [1:43:33<28:31, 35.65s/it]                                                   {'loss': 0.0039, 'grad_norm': 0.011770324781537056, 'learning_rate': 1.775713965452486e-05, 'rewards/chosen': -0.3101619482040405, 'rewards/rejected': -37.14759063720703, 'rewards/accuracies': 0.984375, 'rewards/margins': 36.837425231933594, 'logps/rejected': -512.6937866210938, 'logps/chosen': -61.38876724243164, 'logits/rejected': -1.0308928489685059, 'logits/chosen': -1.0717437267303467, 'epoch': 2.32}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 174/222 [1:43:33<28:31, 35.65s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 175/222 [1:44:09<28:01, 35.78s/it]                                                   {'loss': 0.0032, 'grad_norm': 0.012017006985843182, 'learning_rate': 1.7052184370272788e-05, 'rewards/chosen': -0.36053359508514404, 'rewards/rejected': -34.50450134277344, 'rewards/accuracies': 1.0, 'rewards/margins': 34.14396667480469, 'logps/rejected': -472.95465087890625, 'logps/chosen': -62.55946731567383, 'logits/rejected': -1.0031133890151978, 'logits/chosen': -1.0649644136428833, 'epoch': 2.34}
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 175/222 [1:44:09<28:01, 35.78s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 176/222 [1:44:44<27:18, 35.63s/it]                                                   {'loss': 0.0019, 'grad_norm': 0.008418475277721882, 'learning_rate': 1.635983479315282e-05, 'rewards/chosen': -0.2727818191051483, 'rewards/rejected': -44.69806671142578, 'rewards/accuracies': 1.0, 'rewards/margins': 44.42528533935547, 'logps/rejected': -585.1328125, 'logps/chosen': -52.61171340942383, 'logits/rejected': -1.0417063236236572, 'logits/chosen': -1.0579687356948853, 'epoch': 2.35}
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 176/222 [1:44:44<27:18, 35.63s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 177/222 [1:45:20<26:45, 35.67s/it]                                                   {'loss': 0.0088, 'grad_norm': 0.015160057693719864, 'learning_rate': 1.5680229570644767e-05, 'rewards/chosen': -0.4138847887516022, 'rewards/rejected': -37.7886962890625, 'rewards/accuracies': 0.984375, 'rewards/margins': 37.374813079833984, 'logps/rejected': -513.096923828125, 'logps/chosen': -69.93682861328125, 'logits/rejected': -0.9834797382354736, 'logits/chosen': -1.0643372535705566, 'epoch': 2.36}
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 177/222 [1:45:20<26:45, 35.67s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 178/222 [1:45:56<26:09, 35.67s/it]                                                   {'loss': 0.0022, 'grad_norm': 0.00953206792473793, 'learning_rate': 1.501350479808914e-05, 'rewards/chosen': -0.2734541893005371, 'rewards/rejected': -43.83619689941406, 'rewards/accuracies': 1.0, 'rewards/margins': 43.562744140625, 'logps/rejected': -576.4429321289062, 'logps/chosen': -60.68421936035156, 'logits/rejected': -1.0117603540420532, 'logits/chosen': -1.0458530187606812, 'epoch': 2.38}
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 178/222 [1:45:56<26:09, 35.67s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 179/222 [1:46:31<25:31, 35.62s/it]                                                   {'loss': 0.0018, 'grad_norm': 0.00510015431791544, 'learning_rate': 1.4359793991433005e-05, 'rewards/chosen': -0.3381993770599365, 'rewards/rejected': -53.116554260253906, 'rewards/accuracies': 1.0, 'rewards/margins': 52.778358459472656, 'logps/rejected': -666.4118041992188, 'logps/chosen': -60.19757843017578, 'logits/rejected': -1.0234193801879883, 'logits/chosen': -0.9988107681274414, 'epoch': 2.39}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 179/222 [1:46:31<25:31, 35.62s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 180/222 [1:47:06<24:49, 35.46s/it]                                                   {'loss': 0.0017, 'grad_norm': 0.004191298969089985, 'learning_rate': 1.3719228060492636e-05, 'rewards/chosen': -0.4062020778656006, 'rewards/rejected': -40.86587905883789, 'rewards/accuracies': 1.0, 'rewards/margins': 40.459678649902344, 'logps/rejected': -537.2124633789062, 'logps/chosen': -67.34146881103516, 'logits/rejected': -1.0328353643417358, 'logits/chosen': -1.0705903768539429, 'epoch': 2.4}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 180/222 [1:47:06<24:49, 35.46s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 181/222 [1:47:42<24:15, 35.50s/it]                                                   {'loss': 0.0009, 'grad_norm': 0.002002360764890909, 'learning_rate': 1.3091935282737915e-05, 'rewards/chosen': -0.35460177063941956, 'rewards/rejected': -42.44107437133789, 'rewards/accuracies': 1.0, 'rewards/margins': 42.08647155761719, 'logps/rejected': -562.5910034179688, 'logps/chosen': -68.11119842529297, 'logits/rejected': -1.0135884284973145, 'logits/chosen': -1.0345655679702759, 'epoch': 2.42}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 181/222 [1:47:42<24:15, 35.50s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 182/222 [1:48:17<23:35, 35.38s/it]                                                   {'loss': 0.0171, 'grad_norm': 0.03816799819469452, 'learning_rate': 1.2478041277603975e-05, 'rewards/chosen': -0.308123916387558, 'rewards/rejected': -43.37052917480469, 'rewards/accuracies': 1.0, 'rewards/margins': 43.06240463256836, 'logps/rejected': -579.3252563476562, 'logps/chosen': -62.59718704223633, 'logits/rejected': -1.0117863416671753, 'logits/chosen': -1.0628777742385864, 'epoch': 2.43}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 182/222 [1:48:17<23:35, 35.38s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 183/222 [1:48:53<23:04, 35.50s/it]                                                   {'loss': 0.0016, 'grad_norm': 0.003794616786763072, 'learning_rate': 1.1877668981335097e-05, 'rewards/chosen': -0.2926434874534607, 'rewards/rejected': -43.02805709838867, 'rewards/accuracies': 1.0, 'rewards/margins': 42.735416412353516, 'logps/rejected': -567.8076171875, 'logps/chosen': -64.70804595947266, 'logits/rejected': -0.9359560012817383, 'logits/chosen': -1.0717179775238037, 'epoch': 2.44}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 183/222 [1:48:53<23:04, 35.50s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 184/222 [1:49:29<22:35, 35.67s/it]                                                   {'loss': 0.0049, 'grad_norm': 0.014568675309419632, 'learning_rate': 1.1290938622365916e-05, 'rewards/chosen': -0.4284319579601288, 'rewards/rejected': -48.33433151245117, 'rewards/accuracies': 1.0, 'rewards/margins': 47.9058952331543, 'logps/rejected': -636.11376953125, 'logps/chosen': -55.88724899291992, 'logits/rejected': -0.9956700801849365, 'logits/chosen': -1.0486397743225098, 'epoch': 2.46}
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 184/222 [1:49:29<22:35, 35.67s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 185/222 [1:50:05<22:01, 35.71s/it]                                                   {'loss': 0.0044, 'grad_norm': 0.007850196212530136, 'learning_rate': 1.0717967697244904e-05, 'rewards/chosen': -0.30027642846107483, 'rewards/rejected': -42.03726577758789, 'rewards/accuracies': 1.0, 'rewards/margins': 41.73699188232422, 'logps/rejected': -558.2635498046875, 'logps/chosen': -54.792083740234375, 'logits/rejected': -0.9951565265655518, 'logits/chosen': -1.0265028476715088, 'epoch': 2.47}
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 185/222 [1:50:05<22:01, 35.71s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 186/222 [1:50:40<21:24, 35.68s/it]                                                   {'loss': 0.0029, 'grad_norm': 0.006820064038038254, 'learning_rate': 1.0158870947104948e-05, 'rewards/chosen': -0.45561063289642334, 'rewards/rejected': -47.31330490112305, 'rewards/accuracies': 1.0, 'rewards/margins': 46.857688903808594, 'logps/rejected': -614.6802368164062, 'logps/chosen': -50.96333312988281, 'logits/rejected': -1.008115530014038, 'logits/chosen': -0.9844223260879517, 'epoch': 2.48}
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 186/222 [1:50:40<21:24, 35.68s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 187/222 [1:51:16<20:51, 35.76s/it]                                                   {'loss': 0.0056, 'grad_norm': 0.016801029443740845, 'learning_rate': 9.613760334685662e-06, 'rewards/chosen': -0.37342777848243713, 'rewards/rejected': -46.573734283447266, 'rewards/accuracies': 1.0, 'rewards/margins': 46.20030975341797, 'logps/rejected': -616.4906005859375, 'logps/chosen': -63.42577362060547, 'logits/rejected': -1.0064201354980469, 'logits/chosen': -0.9521920084953308, 'epoch': 2.5}
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 187/222 [1:51:16<20:51, 35.76s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 188/222 [1:51:52<20:10, 35.59s/it]                                                   {'loss': 0.001, 'grad_norm': 0.002900501945987344, 'learning_rate': 9.0827450219121e-06, 'rewards/chosen': -0.34834471344947815, 'rewards/rejected': -35.720760345458984, 'rewards/accuracies': 1.0, 'rewards/margins': 35.37241744995117, 'logps/rejected': -486.7000732421875, 'logps/chosen': -63.408592224121094, 'logits/rejected': -1.030179738998413, 'logits/chosen': -1.0720824003219604, 'epoch': 2.51}
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 188/222 [1:51:52<20:10, 35.59s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 189/222 [1:52:27<19:31, 35.51s/it]                                                   {'loss': 0.0026, 'grad_norm': 0.015201031230390072, 'learning_rate': 8.56593134803453e-06, 'rewards/chosen': -0.39344799518585205, 'rewards/rejected': -38.58580017089844, 'rewards/accuracies': 1.0, 'rewards/margins': 38.192352294921875, 'logps/rejected': -518.4805908203125, 'logps/chosen': -62.59712219238281, 'logits/rejected': -0.9889026284217834, 'logits/chosen': -1.0358375310897827, 'epoch': 2.52}
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 189/222 [1:52:27<19:31, 35.51s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 190/222 [1:53:02<18:55, 35.48s/it]                                                   {'loss': 0.0079, 'grad_norm': 0.012618708424270153, 'learning_rate': 8.06342280833305e-06, 'rewards/chosen': -0.3424551486968994, 'rewards/rejected': -45.23012161254883, 'rewards/accuracies': 1.0, 'rewards/margins': 44.88766860961914, 'logps/rejected': -600.2045288085938, 'logps/chosen': -58.202178955078125, 'logits/rejected': -1.0110241174697876, 'logits/chosen': -1.0239777565002441, 'epoch': 2.54}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 190/222 [1:53:02<18:55, 35.48s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 191/222 [1:53:38<18:22, 35.56s/it]                                                   {'loss': 0.006, 'grad_norm': 0.009924447163939476, 'learning_rate': 7.5753200333922705e-06, 'rewards/chosen': -0.36232906579971313, 'rewards/rejected': -44.677791595458984, 'rewards/accuracies': 1.0, 'rewards/margins': 44.315460205078125, 'logps/rejected': -586.0711059570312, 'logps/chosen': -51.29945755004883, 'logits/rejected': -1.060503363609314, 'logits/chosen': -0.9974949955940247, 'epoch': 2.55}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 191/222 [1:53:38<18:22, 35.56s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 192/222 [1:54:14<17:46, 35.56s/it]                                                   {'loss': 0.003, 'grad_norm': 0.007563973311334848, 'learning_rate': 7.101720768949136e-06, 'rewards/chosen': -0.2968762516975403, 'rewards/rejected': -50.254215240478516, 'rewards/accuracies': 1.0, 'rewards/margins': 49.95733642578125, 'logps/rejected': -662.88720703125, 'logps/chosen': -56.51744842529297, 'logits/rejected': -0.9860135316848755, 'logits/chosen': -0.9782888889312744, 'epoch': 2.56}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 192/222 [1:54:14<17:46, 35.56s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 193/222 [1:54:49<17:12, 35.60s/it]                                                   {'loss': 0.0043, 'grad_norm': 0.01637781411409378, 'learning_rate': 6.6427198563189375e-06, 'rewards/chosen': -0.30303478240966797, 'rewards/rejected': -44.7838020324707, 'rewards/accuracies': 1.0, 'rewards/margins': 44.480770111083984, 'logps/rejected': -577.332275390625, 'logps/chosen': -73.28382873535156, 'logits/rejected': -1.0339789390563965, 'logits/chosen': -1.0332667827606201, 'epoch': 2.58}
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 193/222 [1:54:49<17:12, 35.60s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 194/222 [1:55:25<16:36, 35.60s/it]                                                   {'loss': 0.0014, 'grad_norm': 0.0035696239210665226, 'learning_rate': 6.198409213402512e-06, 'rewards/chosen': -0.3312503695487976, 'rewards/rejected': -39.713279724121094, 'rewards/accuracies': 1.0, 'rewards/margins': 39.38203430175781, 'logps/rejected': -554.2894287109375, 'logps/chosen': -61.46575927734375, 'logits/rejected': -1.0505571365356445, 'logits/chosen': -1.017160177230835, 'epoch': 2.59}
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 194/222 [1:55:25<16:36, 35.60s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 195/222 [1:56:00<16:01, 35.60s/it]                                                   {'loss': 0.0123, 'grad_norm': 0.016758348792791367, 'learning_rate': 5.768877816279252e-06, 'rewards/chosen': -0.37315478920936584, 'rewards/rejected': -42.325191497802734, 'rewards/accuracies': 0.984375, 'rewards/margins': 41.9520378112793, 'logps/rejected': -548.5322875976562, 'logps/chosen': -60.093685150146484, 'logits/rejected': -1.0073469877243042, 'logits/chosen': -1.0271446704864502, 'epoch': 2.6}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 195/222 [1:56:00<16:01, 35.60s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 196/222 [1:56:36<15:24, 35.56s/it]                                                   {'loss': 0.0158, 'grad_norm': 0.02831648848950863, 'learning_rate': 5.354211681389014e-06, 'rewards/chosen': -0.3957834839820862, 'rewards/rejected': -51.594661712646484, 'rewards/accuracies': 0.984375, 'rewards/margins': 51.19887924194336, 'logps/rejected': -655.6401977539062, 'logps/chosen': -55.738304138183594, 'logits/rejected': -0.9811738729476929, 'logits/chosen': -1.040746808052063, 'epoch': 2.62}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 196/222 [1:56:36<15:24, 35.56s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 197/222 [1:57:12<14:52, 35.69s/it]                                                   {'loss': 0.0042, 'grad_norm': 0.009912117384374142, 'learning_rate': 4.9544938483067296e-06, 'rewards/chosen': -0.34933528304100037, 'rewards/rejected': -51.92066192626953, 'rewards/accuracies': 1.0, 'rewards/margins': 51.571327209472656, 'logps/rejected': -664.3198852539062, 'logps/chosen': -52.698299407958984, 'logits/rejected': -0.972522497177124, 'logits/chosen': -0.9753755331039429, 'epoch': 2.63}
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 197/222 [1:57:12<14:52, 35.69s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 198/222 [1:57:48<14:16, 35.68s/it]                                                   {'loss': 0.0014, 'grad_norm': 0.007592939771711826, 'learning_rate': 4.569804363113264e-06, 'rewards/chosen': -0.2101905792951584, 'rewards/rejected': -43.51005935668945, 'rewards/accuracies': 1.0, 'rewards/margins': 43.299869537353516, 'logps/rejected': -578.41845703125, 'logps/chosen': -56.48158264160156, 'logits/rejected': -1.0275462865829468, 'logits/chosen': -1.0280672311782837, 'epoch': 2.64}
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 198/222 [1:57:48<14:16, 35.68s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 199/222 [1:58:23<13:35, 35.47s/it]                                                   {'loss': 0.0032, 'grad_norm': 0.008064443245530128, 'learning_rate': 4.200220262365626e-06, 'rewards/chosen': -0.33922404050827026, 'rewards/rejected': -55.278053283691406, 'rewards/accuracies': 1.0, 'rewards/margins': 54.93882751464844, 'logps/rejected': -701.6663208007812, 'logps/chosen': -50.85074996948242, 'logits/rejected': -1.0578356981277466, 'logits/chosen': -1.0228620767593384, 'epoch': 2.66}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 199/222 [1:58:23<13:35, 35.47s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 200/222 [1:58:58<13:01, 35.52s/it]                                                   {'loss': 0.0025, 'grad_norm': 0.004615286365151405, 'learning_rate': 3.845815557669879e-06, 'rewards/chosen': -0.33798831701278687, 'rewards/rejected': -41.94095993041992, 'rewards/accuracies': 1.0, 'rewards/margins': 41.602970123291016, 'logps/rejected': -554.787841796875, 'logps/chosen': -61.21940612792969, 'logits/rejected': -1.0276896953582764, 'logits/chosen': -1.108036994934082, 'epoch': 2.67}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 200/222 [1:58:58<13:01, 35.52s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 201/222 [1:59:34<12:27, 35.61s/it]                                                   {'loss': 0.0039, 'grad_norm': 0.008002796210348606, 'learning_rate': 3.5066612208599326e-06, 'rewards/chosen': -0.2271558791399002, 'rewards/rejected': -45.139678955078125, 'rewards/accuracies': 1.0, 'rewards/margins': 44.91252136230469, 'logps/rejected': -588.849365234375, 'logps/chosen': -74.16981506347656, 'logits/rejected': -1.0206506252288818, 'logits/chosen': -0.9783579707145691, 'epoch': 2.68}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 201/222 [1:59:34<12:27, 35.61s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 202/222 [2:00:10<11:54, 35.72s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.0010631560580804944, 'learning_rate': 3.18282516978484e-06, 'rewards/chosen': -0.41165655851364136, 'rewards/rejected': -42.362892150878906, 'rewards/accuracies': 1.0, 'rewards/margins': 41.95124053955078, 'logps/rejected': -557.6784057617188, 'logps/chosen': -67.52101135253906, 'logits/rejected': -0.9908828139305115, 'logits/chosen': -1.016082763671875, 'epoch': 2.7}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 202/222 [2:00:10<11:54, 35.72s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 203/222 [2:00:46<11:19, 35.78s/it]                                                   {'loss': 0.0039, 'grad_norm': 0.010032608173787594, 'learning_rate': 2.8743722547079555e-06, 'rewards/chosen': -0.3965676426887512, 'rewards/rejected': -45.28022766113281, 'rewards/accuracies': 1.0, 'rewards/margins': 44.88365936279297, 'logps/rejected': -592.7021484375, 'logps/chosen': -56.302223205566406, 'logits/rejected': -0.9689077734947205, 'logits/chosen': -1.040857195854187, 'epoch': 2.71}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 203/222 [2:00:46<11:19, 35.78s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 204/222 [2:01:21<10:41, 35.65s/it]                                                   {'loss': 0.0015, 'grad_norm': 0.002808408346027136, 'learning_rate': 2.5813642453200905e-06, 'rewards/chosen': -0.40416383743286133, 'rewards/rejected': -45.691951751708984, 'rewards/accuracies': 1.0, 'rewards/margins': 45.28778839111328, 'logps/rejected': -575.2540893554688, 'logps/chosen': -51.82987976074219, 'logits/rejected': -0.9893808364868164, 'logits/chosen': -1.063218593597412, 'epoch': 2.72}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 204/222 [2:01:21<10:41, 35.65s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 205/222 [2:01:57<10:06, 35.69s/it]                                                   {'loss': 0.0016, 'grad_norm': 0.0048523107543587685, 'learning_rate': 2.3038598183699046e-06, 'rewards/chosen': -0.2908806800842285, 'rewards/rejected': -41.22573471069336, 'rewards/accuracies': 1.0, 'rewards/margins': 40.93485641479492, 'logps/rejected': -547.1017456054688, 'logps/chosen': -72.36981964111328, 'logits/rejected': -1.0178965330123901, 'logits/chosen': -1.08097243309021, 'epoch': 2.74}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 205/222 [2:01:57<10:06, 35.69s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 206/222 [2:02:33<09:33, 35.81s/it]                                                   {'loss': 0.0044, 'grad_norm': 0.010848802514374256, 'learning_rate': 2.0419145459133417e-06, 'rewards/chosen': -0.34787124395370483, 'rewards/rejected': -43.9544677734375, 'rewards/accuracies': 1.0, 'rewards/margins': 43.60660171508789, 'logps/rejected': -575.0292358398438, 'logps/chosen': -56.81843185424805, 'logits/rejected': -1.0390115976333618, 'logits/chosen': -1.041865348815918, 'epoch': 2.75}
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 206/222 [2:02:33<09:33, 35.81s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 207/222 [2:03:09<08:57, 35.80s/it]                                                   {'loss': 0.0022, 'grad_norm': 0.00587766757234931, 'learning_rate': 1.7955808841851086e-06, 'rewards/chosen': -0.26604554057121277, 'rewards/rejected': -48.22750473022461, 'rewards/accuracies': 1.0, 'rewards/margins': 47.961463928222656, 'logps/rejected': -613.7471313476562, 'logps/chosen': -58.04007339477539, 'logits/rejected': -0.9708966612815857, 'logits/chosen': -0.9758986234664917, 'epoch': 2.76}
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 207/222 [2:03:09<08:57, 35.80s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 208/222 [2:03:44<08:17, 35.52s/it]                                                   {'loss': 0.0022, 'grad_norm': 0.0032577638048678637, 'learning_rate': 1.564908163093861e-06, 'rewards/chosen': -0.27024295926094055, 'rewards/rejected': -50.652183532714844, 'rewards/accuracies': 1.0, 'rewards/margins': 50.38193893432617, 'logps/rejected': -658.127685546875, 'logps/chosen': -51.4388542175293, 'logits/rejected': -0.9876884818077087, 'logits/chosen': -1.0387706756591797, 'epoch': 2.78}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 208/222 [2:03:44<08:17, 35.52s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 209/222 [2:04:20<07:43, 35.67s/it]                                                   {'loss': 0.0021, 'grad_norm': 0.00886542908847332, 'learning_rate': 1.3499425763436612e-06, 'rewards/chosen': -0.40007779002189636, 'rewards/rejected': -40.82487487792969, 'rewards/accuracies': 1.0, 'rewards/margins': 40.42479705810547, 'logps/rejected': -546.9638061523438, 'logps/chosen': -61.2850227355957, 'logits/rejected': -1.0591073036193848, 'logits/chosen': -1.0179500579833984, 'epoch': 2.79}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 209/222 [2:04:20<07:43, 35.67s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 210/222 [2:04:55<07:07, 35.65s/it]                                                   {'loss': 0.0014, 'grad_norm': 0.0047474876046180725, 'learning_rate': 1.1507271721833235e-06, 'rewards/chosen': -0.38590437173843384, 'rewards/rejected': -42.87310791015625, 'rewards/accuracies': 1.0, 'rewards/margins': 42.48719787597656, 'logps/rejected': -581.2244262695312, 'logps/chosen': -71.8417739868164, 'logits/rejected': -0.9897916316986084, 'logits/chosen': -0.9621297717094421, 'epoch': 2.8}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 210/222 [2:04:55<07:07, 35.65s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 211/222 [2:05:31<06:31, 35.63s/it]                                                   {'loss': 0.0055, 'grad_norm': 0.020804651081562042, 'learning_rate': 9.67301844785764e-07, 'rewards/chosen': -0.3406752943992615, 'rewards/rejected': -44.5047607421875, 'rewards/accuracies': 1.0, 'rewards/margins': 44.164085388183594, 'logps/rejected': -582.3673706054688, 'logps/chosen': -69.95175170898438, 'logits/rejected': -1.0225157737731934, 'logits/chosen': -1.1076290607452393, 'epoch': 2.82}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 211/222 [2:05:31<06:31, 35.63s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 212/222 [2:06:07<05:58, 35.84s/it]                                                   {'loss': 0.0024, 'grad_norm': 0.008144369348883629, 'learning_rate': 7.997033262588982e-07, 'rewards/chosen': -0.33228859305381775, 'rewards/rejected': -50.1328239440918, 'rewards/accuracies': 1.0, 'rewards/margins': 49.800533294677734, 'logps/rejected': -654.6185913085938, 'logps/chosen': -54.089500427246094, 'logits/rejected': -0.9540634751319885, 'logits/chosen': -0.9811784029006958, 'epoch': 2.83}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 212/222 [2:06:07<05:58, 35.84s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 213/222 [2:06:43<05:22, 35.80s/it]                                                   {'loss': 0.009, 'grad_norm': 0.016716942191123962, 'learning_rate': 6.479651792898534e-07, 'rewards/chosen': -0.3645245134830475, 'rewards/rejected': -39.20952224731445, 'rewards/accuracies': 1.0, 'rewards/margins': 38.84499740600586, 'logps/rejected': -537.5353393554688, 'logps/chosen': -69.61734008789062, 'logits/rejected': -1.0657036304473877, 'logits/chosen': -1.0814385414123535, 'epoch': 2.84}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 213/222 [2:06:43<05:22, 35.80s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 214/222 [2:07:19<04:46, 35.82s/it]                                                   {'loss': 0.0018, 'grad_norm': 0.00693855993449688, 'learning_rate': 5.121177904237673e-07, 'rewards/chosen': -0.24642695486545563, 'rewards/rejected': -42.73411560058594, 'rewards/accuracies': 1.0, 'rewards/margins': 42.48768615722656, 'logps/rejected': -573.0360107421875, 'logps/chosen': -57.57620620727539, 'logits/rejected': -1.0210726261138916, 'logits/chosen': -1.0480854511260986, 'epoch': 2.86}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 214/222 [2:07:19<04:46, 35.82s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 215/222 [2:07:54<04:10, 35.73s/it]                                                   {'loss': 0.0054, 'grad_norm': 0.012874158099293709, 'learning_rate': 3.921883639787183e-07, 'rewards/chosen': -0.3808763921260834, 'rewards/rejected': -43.69670104980469, 'rewards/accuracies': 1.0, 'rewards/margins': 43.31583023071289, 'logps/rejected': -579.8615112304688, 'logps/chosen': -72.75255584716797, 'logits/rejected': -1.0019563436508179, 'logits/chosen': -1.0869946479797363, 'epoch': 2.87}
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 215/222 [2:07:54<04:10, 35.73s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 216/222 [2:08:30<03:34, 35.70s/it]                                                   {'loss': 0.0086, 'grad_norm': 0.015090696513652802, 'learning_rate': 2.882009165978783e-07, 'rewards/chosen': -0.3775922954082489, 'rewards/rejected': -47.62823486328125, 'rewards/accuracies': 1.0, 'rewards/margins': 47.250640869140625, 'logps/rejected': -610.2901000976562, 'logps/chosen': -77.42103576660156, 'logits/rejected': -0.9321775436401367, 'logits/chosen': -1.029217004776001, 'epoch': 2.88}
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 216/222 [2:08:30<03:34, 35.70s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 217/222 [2:09:06<02:58, 35.73s/it]                                                   {'loss': 0.0028, 'grad_norm': 0.012750301510095596, 'learning_rate': 2.001762724400269e-07, 'rewards/chosen': -0.3215327262878418, 'rewards/rejected': -41.46095657348633, 'rewards/accuracies': 1.0, 'rewards/margins': 41.139427185058594, 'logps/rejected': -553.205078125, 'logps/chosen': -61.66606903076172, 'logits/rejected': -0.9892591238021851, 'logits/chosen': -1.0594303607940674, 'epoch': 2.9}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 217/222 [2:09:06<02:58, 35.73s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 218/222 [2:09:42<02:22, 35.75s/it]                                                   {'loss': 0.0015, 'grad_norm': 0.004748527891933918, 'learning_rate': 1.281320590093582e-07, 'rewards/chosen': -0.34694385528564453, 'rewards/rejected': -48.25302505493164, 'rewards/accuracies': 1.0, 'rewards/margins': 47.90608596801758, 'logps/rejected': -629.4126586914062, 'logps/chosen': -58.760826110839844, 'logits/rejected': -1.0053740739822388, 'logits/chosen': -1.0252840518951416, 'epoch': 2.91}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 218/222 [2:09:42<02:22, 35.75s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 219/222 [2:10:17<01:47, 35.70s/it]                                                   {'loss': 0.003, 'grad_norm': 0.004631688352674246, 'learning_rate': 7.208270362548675e-08, 'rewards/chosen': -0.27855318784713745, 'rewards/rejected': -56.20763397216797, 'rewards/accuracies': 1.0, 'rewards/margins': 55.92908477783203, 'logps/rejected': -695.5380859375, 'logps/chosen': -61.75642776489258, 'logits/rejected': -0.9661762714385986, 'logits/chosen': -1.0671863555908203, 'epoch': 2.92}
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 219/222 [2:10:17<01:47, 35.70s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 220/222 [2:10:53<01:11, 35.81s/it]                                                   {'loss': 0.0106, 'grad_norm': 0.023121820762753487, 'learning_rate': 3.203943053427416e-08, 'rewards/chosen': -0.3910875916481018, 'rewards/rejected': -48.20255661010742, 'rewards/accuracies': 1.0, 'rewards/margins': 47.811466217041016, 'logps/rejected': -614.2266235351562, 'logps/chosen': -62.77470779418945, 'logits/rejected': -0.999262809753418, 'logits/chosen': -1.0257103443145752, 'epoch': 2.94}
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 220/222 [2:10:53<01:11, 35.81s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 221/222 [2:11:29<00:35, 35.77s/it]                                                   {'loss': 0.0077, 'grad_norm': 0.011239130049943924, 'learning_rate': 8.01025866008942e-09, 'rewards/chosen': -0.3634660243988037, 'rewards/rejected': -46.20746612548828, 'rewards/accuracies': 1.0, 'rewards/margins': 45.843994140625, 'logps/rejected': -598.0241088867188, 'logps/chosen': -52.95919418334961, 'logits/rejected': -1.0135215520858765, 'logits/chosen': -1.038633108139038, 'epoch': 2.95}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 221/222 [2:11:29<00:35, 35.77s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 222/222 [2:12:05<00:00, 35.79s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.0012775770155712962, 'learning_rate': 0.0, 'rewards/chosen': -0.44307082891464233, 'rewards/rejected': -41.75294494628906, 'rewards/accuracies': 1.0, 'rewards/margins': 41.30987548828125, 'logps/rejected': -541.8709106445312, 'logps/chosen': -72.16439056396484, 'logits/rejected': -1.0057090520858765, 'logits/chosen': -1.1133300065994263, 'epoch': 2.96}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 222/222 [2:12:05<00:00, 35.79s/it]                                                   {'train_runtime': 7928.1743, 'train_samples_per_second': 7.249, 'train_steps_per_second': 0.028, 'train_loss': 0.030241749235502286, 'epoch': 2.96}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 222/222 [2:12:05<00:00, 35.79s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 222/222 [2:12:05<00:00, 35.70s/it]
wandb: - 0.018 MB of 0.018 MB uploadedwandb: \ 0.018 MB of 0.018 MB uploadedwandb: | 0.018 MB of 0.018 MB uploadedwandb: / 0.018 MB of 0.018 MB uploadedwandb: - 0.018 MB of 0.018 MB uploadedwandb: \ 0.018 MB of 0.018 MB uploadedwandb: | 0.055 MB of 0.067 MB uploadedwandb: / 0.055 MB of 0.098 MB uploadedwandb: - 0.098 MB of 0.098 MB uploadedwandb: 
wandb: Run history:
wandb:              train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:        train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:          train/grad_norm ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      train/learning_rate ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      train/logits/chosen ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ
wandb:    train/logits/rejected ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá
wandb:       train/logps/chosen ‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñá‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÇ
wandb:     train/logps/rejected ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb:               train/loss ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: train/rewards/accuracies ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñà‚ñÖ‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:     train/rewards/chosen ‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:    train/rewards/margins ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá
wandb:   train/rewards/rejected ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:               total_flos 0.0
wandb:              train/epoch 2.96494
wandb:        train/global_step 222
wandb:          train/grad_norm 0.00128
wandb:      train/learning_rate 0.0
wandb:      train/logits/chosen -1.11333
wandb:    train/logits/rejected -1.00571
wandb:       train/logps/chosen -72.16439
wandb:     train/logps/rejected -541.87091
wandb:               train/loss 0.0003
wandb: train/rewards/accuracies 1.0
wandb:     train/rewards/chosen -0.44307
wandb:    train/rewards/margins 41.30988
wandb:   train/rewards/rejected -41.75294
wandb:               train_loss 0.03024
wandb:            train_runtime 7928.1743
wandb: train_samples_per_second 7.249
wandb:   train_steps_per_second 0.028
wandb: 
wandb: üöÄ View run models/llama-7b_SpclSpclSpcl_NaiveCompletion_2024-02-02-00-00-00_dpo_NaiveCompletion_2024-07-09-07-55-19 at: https://wandb.ai/sizhe-chen/huggingface/runs/f6lja4l6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/sizhe-chen/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240709_080614-f6lja4l6/logs
