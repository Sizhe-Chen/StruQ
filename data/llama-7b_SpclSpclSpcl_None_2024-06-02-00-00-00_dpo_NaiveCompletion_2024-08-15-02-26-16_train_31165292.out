WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1820: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead 
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1820: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead 
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1820: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead 
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]/private/home/sizhechen/.local/lib/python3.10/site-packages/transformers/training_args.py:1820: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead 
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|â–ˆâ–‹        | 1/6 [00:00<00:00,  9.85it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00,  9.53it/s]Loading checkpoint shards:  17%|â–ˆâ–‹        | 1/6 [00:00<00:00,  8.15it/s]Loading checkpoint shards:  17%|â–ˆâ–‹        | 1/6 [00:00<00:00,  8.00it/s]Loading checkpoint shards:  17%|â–ˆâ–‹        | 1/6 [00:00<00:00,  9.01it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  9.29it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00,  8.67it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00,  8.62it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:00,  9.03it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  9.19it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  8.86it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  8.85it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:00<00:00,  9.05it/s]Loading checkpoint shards:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  9.14it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  8.94it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  8.94it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:00<00:00,  9.06it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.18it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.25it/s]
Loading checkpoint shards:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  8.99it/s]Loading checkpoint shards:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  9.04it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  9.19it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.15it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  8.97it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.25it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.00it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.43it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  9.25it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
trainable params: 33,554,432 || all params: 6,772,019,200 || trainable%: 0.4954863683788729
models/llama-7b_SpclSpclSpcl_None_2024-06-02-00-00-00_dpo_NaiveCompletion_2024-08-15-02-26-16 



trainable params: 33,554,432 || all params: 6,772,019,200 || trainable%: 0.4954863683788729
models/llama-7b_SpclSpclSpcl_None_2024-06-02-00-00-00_dpo_NaiveCompletion_2024-08-15-02-26-16 



trainable params: 33,554,432 || all params: 6,772,019,200 || trainable%: 0.4954863683788729
models/llama-7b_SpclSpclSpcl_None_2024-06-02-00-00-00_dpo_NaiveCompletion_2024-08-15-02-26-16 



trainable params: 33,554,432 || all params: 6,772,019,200 || trainable%: 0.4954863683788729
models/llama-7b_SpclSpclSpcl_None_2024-06-02-00-00-00_dpo_NaiveCompletion_2024-08-15-02-26-16 



/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:300: UserWarning: `max_length` is not set in the DPOTrainer's init it will default to `512` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:300: UserWarning: `max_length` is not set in the DPOTrainer's init it will default to `512` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:307: UserWarning: `max_prompt_length` is not set in the DPOTrainer's init it will default to `128` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:307: UserWarning: `max_prompt_length` is not set in the DPOTrainer's init it will default to `128` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:332: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:332: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:300: UserWarning: `max_length` is not set in the DPOTrainer's init it will default to `512` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:307: UserWarning: `max_prompt_length` is not set in the DPOTrainer's init it will default to `128` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:332: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:300: UserWarning: `max_length` is not set in the DPOTrainer's init it will default to `512` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:307: UserWarning: `max_prompt_length` is not set in the DPOTrainer's init it will default to `128` by default, but you should do it yourself in the future.
  warnings.warn(
/private/home/sizhechen/.local/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:332: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: Currently logged in as: sizhe-chen. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /private/home/sizhechen/SecAlign/wandb/run-20240815_022806-w0h7hpoa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run models/llama-7b_SpclSpclSpcl_None_2024-06-02-00-00-00_dpo_NaiveCompletion_2024-08-15-02-26-16
wandb: â­ï¸ View project at https://wandb.ai/sizhe-chen/huggingface
wandb: ðŸš€ View run at https://wandb.ai/sizhe-chen/huggingface/runs/w0h7hpoa
  0%|          | 0/222 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
  0%|          | 1/222 [00:37<2:16:37, 37.09s/it]                                                 {'loss': 0.6931, 'grad_norm': 0.1877652257680893, 'learning_rate': 0.00029998498076501233, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -104.53721618652344, 'logps/chosen': -58.998634338378906, 'logits/rejected': -1.2981353998184204, 'logits/chosen': -1.3427873849868774, 'epoch': 0.01}
  0%|          | 1/222 [00:37<2:16:37, 37.09s/it]  1%|          | 2/222 [01:12<2:12:21, 36.10s/it]                                                 {'loss': 0.6278, 'grad_norm': 0.24458809196949005, 'learning_rate': 0.00029993992606774825, 'rewards/chosen': 0.0374569408595562, 'rewards/rejected': -0.09453826397657394, 'rewards/accuracies': 0.96875, 'rewards/margins': 0.13199520111083984, 'logps/rejected': -92.77151489257812, 'logps/chosen': -68.62345123291016, 'logits/rejected': -1.3548469543457031, 'logits/chosen': -1.3859184980392456, 'epoch': 0.03}
  1%|          | 2/222 [01:12<2:12:21, 36.10s/it]  1%|â–         | 3/222 [01:48<2:10:55, 35.87s/it]                                                 {'loss': 0.5456, 'grad_norm': 0.34156540036201477, 'learning_rate': 0.00029986484493070223, 'rewards/chosen': 0.05085562542080879, 'rewards/rejected': -0.25626206398010254, 'rewards/accuracies': 0.96875, 'rewards/margins': 0.30711767077445984, 'logps/rejected': -98.42753601074219, 'logps/chosen': -68.11347961425781, 'logits/rejected': -1.3239493370056152, 'logits/chosen': -1.3585774898529053, 'epoch': 0.04}
  1%|â–         | 3/222 [01:48<2:10:55, 35.87s/it]  2%|â–         | 4/222 [02:23<2:09:42, 35.70s/it]                                                 {'loss': 0.4364, 'grad_norm': 0.4016122817993164, 'learning_rate': 0.00029975975238935744, 'rewards/chosen': 0.13750223815441132, 'rewards/rejected': -0.5184289813041687, 'rewards/accuracies': 0.984375, 'rewards/margins': 0.6559312343597412, 'logps/rejected': -98.59661865234375, 'logps/chosen': -68.26170349121094, 'logits/rejected': -1.3777289390563965, 'logits/chosen': -1.3543680906295776, 'epoch': 0.05}
  2%|â–         | 4/222 [02:23<2:09:42, 35.70s/it]  2%|â–         | 5/222 [02:59<2:09:05, 35.70s/it]                                                 {'loss': 0.3444, 'grad_norm': 0.3614455461502075, 'learning_rate': 0.00029962466948917494, 'rewards/chosen': 0.196015864610672, 'rewards/rejected': -0.8562293648719788, 'rewards/accuracies': 0.984375, 'rewards/margins': 1.0522452592849731, 'logps/rejected': -113.30293273925781, 'logps/chosen': -59.722412109375, 'logits/rejected': -1.3564534187316895, 'logits/chosen': -1.366742730140686, 'epoch': 0.07}
  2%|â–         | 5/222 [02:59<2:09:05, 35.70s/it]  3%|â–Ž         | 6/222 [03:34<2:08:33, 35.71s/it]                                                 {'loss': 0.2294, 'grad_norm': 0.2973364591598511, 'learning_rate': 0.00029945962328137895, 'rewards/chosen': 0.291511595249176, 'rewards/rejected': -1.2573777437210083, 'rewards/accuracies': 0.96875, 'rewards/margins': 1.548889398574829, 'logps/rejected': -128.1237335205078, 'logps/chosen': -65.53804779052734, 'logits/rejected': -1.408555507659912, 'logits/chosen': -1.3529794216156006, 'epoch': 0.08}
  3%|â–Ž         | 6/222 [03:34<2:08:33, 35.71s/it]  3%|â–Ž         | 7/222 [04:10<2:07:30, 35.58s/it]                                                 {'loss': 0.1777, 'grad_norm': 0.232200488448143, 'learning_rate': 0.0002992646468175399, 'rewards/chosen': 0.4881022572517395, 'rewards/rejected': -1.8977324962615967, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3858349323272705, 'logps/rejected': -118.19180297851562, 'logps/chosen': -58.74713897705078, 'logits/rejected': -1.3035709857940674, 'logits/chosen': -1.284123182296753, 'epoch': 0.09}
  3%|â–Ž         | 7/222 [04:10<2:07:30, 35.58s/it]  4%|â–Ž         | 8/222 [04:45<2:06:43, 35.53s/it]                                                 {'loss': 0.1315, 'grad_norm': 0.14607444405555725, 'learning_rate': 0.0002990397791429554, 'rewards/chosen': 0.49958890676498413, 'rewards/rejected': -2.6495509147644043, 'rewards/accuracies': 1.0, 'rewards/margins': 3.149139881134033, 'logps/rejected': -128.05880737304688, 'logps/chosen': -62.918312072753906, 'logits/rejected': -1.3347136974334717, 'logits/chosen': -1.350177526473999, 'epoch': 0.11}
  4%|â–Ž         | 8/222 [04:45<2:06:43, 35.53s/it]  4%|â–         | 9/222 [05:21<2:06:16, 35.57s/it]                                                 {'loss': 0.1047, 'grad_norm': 0.09315865486860275, 'learning_rate': 0.0002987850652888315, 'rewards/chosen': 0.35982733964920044, 'rewards/rejected': -3.0363850593566895, 'rewards/accuracies': 0.96875, 'rewards/margins': 3.396212577819824, 'logps/rejected': -130.7313995361328, 'logps/chosen': -67.49295043945312, 'logits/rejected': -1.3735172748565674, 'logits/chosen': -1.3312431573867798, 'epoch': 0.12}
  4%|â–         | 9/222 [05:21<2:06:16, 35.57s/it]  5%|â–         | 10/222 [05:56<2:05:33, 35.53s/it]                                                  {'loss': 0.0725, 'grad_norm': 0.06992455571889877, 'learning_rate': 0.0002985005562632645, 'rewards/chosen': 0.4540490508079529, 'rewards/rejected': -4.474279403686523, 'rewards/accuracies': 0.984375, 'rewards/margins': 4.928328514099121, 'logps/rejected': -149.9953155517578, 'logps/chosen': -67.3285140991211, 'logits/rejected': -1.39504873752594, 'logits/chosen': -1.3177284002304077, 'epoch': 0.13}
  5%|â–         | 10/222 [05:56<2:05:33, 35.53s/it]  5%|â–         | 11/222 [06:32<2:04:55, 35.53s/it]                                                  {'loss': 0.0548, 'grad_norm': 0.05794217437505722, 'learning_rate': 0.0002981863090410267, 'rewards/chosen': 0.418384850025177, 'rewards/rejected': -5.143019199371338, 'rewards/accuracies': 1.0, 'rewards/margins': 5.561403751373291, 'logps/rejected': -143.36842346191406, 'logps/chosen': -57.42694091796875, 'logits/rejected': -1.331423044204712, 'logits/chosen': -1.3651952743530273, 'epoch': 0.15}
  5%|â–         | 11/222 [06:32<2:04:55, 35.53s/it]  5%|â–Œ         | 12/222 [07:08<2:04:42, 35.63s/it]                                                  {'loss': 0.0499, 'grad_norm': 0.06783419102430344, 'learning_rate': 0.00029784238655215626, 'rewards/chosen': 0.5473803877830505, 'rewards/rejected': -6.139639854431152, 'rewards/accuracies': 1.0, 'rewards/margins': 6.687019348144531, 'logps/rejected': -157.7456512451172, 'logps/chosen': -47.8663444519043, 'logits/rejected': -1.38578200340271, 'logits/chosen': -1.3550260066986084, 'epoch': 0.16}
  5%|â–Œ         | 12/222 [07:08<2:04:42, 35.63s/it]  6%|â–Œ         | 13/222 [07:43<2:04:03, 35.62s/it]                                                  {'loss': 0.0422, 'grad_norm': 0.04937101528048515, 'learning_rate': 0.0002974688576693556, 'rewards/chosen': 0.4440790116786957, 'rewards/rejected': -8.264605522155762, 'rewards/accuracies': 1.0, 'rewards/margins': 8.708683967590332, 'logps/rejected': -182.56617736816406, 'logps/chosen': -67.9914321899414, 'logits/rejected': -1.3242270946502686, 'logits/chosen': -1.3321080207824707, 'epoch': 0.17}
  6%|â–Œ         | 13/222 [07:43<2:04:03, 35.62s/it]  6%|â–‹         | 14/222 [08:19<2:03:11, 35.54s/it]                                                  {'loss': 0.0367, 'grad_norm': 0.04609917476773262, 'learning_rate': 0.000297065797194199, 'rewards/chosen': 0.5171090364456177, 'rewards/rejected': -8.619576454162598, 'rewards/accuracies': 0.984375, 'rewards/margins': 9.136685371398926, 'logps/rejected': -185.01246643066406, 'logps/chosen': -59.50007629394531, 'logits/rejected': -1.3411625623703003, 'logits/chosen': -1.3392155170440674, 'epoch': 0.19}
  6%|â–‹         | 14/222 [08:19<2:03:11, 35.54s/it]  7%|â–‹         | 15/222 [08:54<2:02:25, 35.49s/it]                                                  {'loss': 0.0524, 'grad_norm': 0.10731028020381927, 'learning_rate': 0.00029663328584215293, 'rewards/chosen': 0.3705140948295593, 'rewards/rejected': -7.925765037536621, 'rewards/accuracies': 1.0, 'rewards/margins': 8.29627799987793, 'logps/rejected': -169.4701385498047, 'logps/chosen': -63.59200668334961, 'logits/rejected': -1.3410948514938354, 'logits/chosen': -1.3351497650146484, 'epoch': 0.2}
  7%|â–‹         | 15/222 [08:54<2:02:25, 35.49s/it]  7%|â–‹         | 16/222 [09:30<2:01:52, 35.50s/it]                                                  {'loss': 0.0317, 'grad_norm': 0.04338708519935608, 'learning_rate': 0.00029617141022641243, 'rewards/chosen': 0.5191649794578552, 'rewards/rejected': -9.855022430419922, 'rewards/accuracies': 1.0, 'rewards/margins': 10.374185562133789, 'logps/rejected': -184.57154846191406, 'logps/chosen': -62.01503372192383, 'logits/rejected': -1.3395276069641113, 'logits/chosen': -1.341306209564209, 'epoch': 0.21}
  7%|â–‹         | 16/222 [09:30<2:01:52, 35.50s/it]  8%|â–Š         | 17/222 [10:05<2:01:19, 35.51s/it]                                                  {'loss': 0.0272, 'grad_norm': 0.04474708437919617, 'learning_rate': 0.00029568026284055644, 'rewards/chosen': 0.5742111206054688, 'rewards/rejected': -10.655168533325195, 'rewards/accuracies': 1.0, 'rewards/margins': 11.229381561279297, 'logps/rejected': -209.49490356445312, 'logps/chosen': -70.46295166015625, 'logits/rejected': -1.3080861568450928, 'logits/chosen': -1.258143663406372, 'epoch': 0.23}
  8%|â–Š         | 17/222 [10:05<2:01:19, 35.51s/it]  8%|â–Š         | 18/222 [10:41<2:00:56, 35.57s/it]                                                  {'loss': 0.057, 'grad_norm': 0.11048643290996552, 'learning_rate': 0.00029515994204002484, 'rewards/chosen': 0.435858815908432, 'rewards/rejected': -10.825528144836426, 'rewards/accuracies': 0.984375, 'rewards/margins': 11.26138687133789, 'logps/rejected': -212.64015197753906, 'logps/chosen': -66.93959045410156, 'logits/rejected': -1.354022741317749, 'logits/chosen': -1.3267674446105957, 'epoch': 0.24}
  8%|â–Š         | 18/222 [10:41<2:00:56, 35.57s/it]  9%|â–Š         | 19/222 [11:16<2:00:06, 35.50s/it]                                                  {'loss': 0.0199, 'grad_norm': 0.04110682010650635, 'learning_rate': 0.00029461055202242256, 'rewards/chosen': 0.6069329977035522, 'rewards/rejected': -13.274688720703125, 'rewards/accuracies': 0.984375, 'rewards/margins': 13.881621360778809, 'logps/rejected': -242.4013214111328, 'logps/chosen': -60.11509704589844, 'logits/rejected': -1.283225178718567, 'logits/chosen': -1.2501643896102905, 'epoch': 0.25}
  9%|â–Š         | 19/222 [11:16<2:00:06, 35.50s/it]  9%|â–‰         | 20/222 [11:51<1:58:56, 35.33s/it]                                                  {'loss': 0.0132, 'grad_norm': 0.050674039870500565, 'learning_rate': 0.00029403220280665337, 'rewards/chosen': 0.3271063268184662, 'rewards/rejected': -11.235776901245117, 'rewards/accuracies': 1.0, 'rewards/margins': 11.562883377075195, 'logps/rejected': -204.92140197753906, 'logps/chosen': -65.38470458984375, 'logits/rejected': -1.2925118207931519, 'logits/chosen': -1.2851159572601318, 'epoch': 0.27}
  9%|â–‰         | 20/222 [11:51<1:58:56, 35.33s/it]  9%|â–‰         | 21/222 [12:26<1:58:17, 35.31s/it]                                                  {'loss': 0.0094, 'grad_norm': 0.019223036244511604, 'learning_rate': 0.0002934250102108876, 'rewards/chosen': 0.3706733286380768, 'rewards/rejected': -12.473604202270508, 'rewards/accuracies': 1.0, 'rewards/margins': 12.844277381896973, 'logps/rejected': -227.7111358642578, 'logps/chosen': -59.830711364746094, 'logits/rejected': -1.295791506767273, 'logits/chosen': -1.2948864698410034, 'epoch': 0.28}
  9%|â–‰         | 21/222 [12:26<1:58:17, 35.31s/it] 10%|â–‰         | 22/222 [13:02<1:57:47, 35.34s/it]                                                  {'loss': 0.016, 'grad_norm': 0.03114154003560543, 'learning_rate': 0.0002927890958293689, 'rewards/chosen': 0.6420468688011169, 'rewards/rejected': -11.924623489379883, 'rewards/accuracies': 1.0, 'rewards/margins': 12.566670417785645, 'logps/rejected': -215.01605224609375, 'logps/chosen': -54.23334503173828, 'logits/rejected': -1.3068957328796387, 'logits/chosen': -1.3253408670425415, 'epoch': 0.29}
 10%|â–‰         | 22/222 [13:02<1:57:47, 35.34s/it] 10%|â–ˆ         | 23/222 [13:37<1:57:23, 35.39s/it]                                                  {'loss': 0.0205, 'grad_norm': 0.040314141660928726, 'learning_rate': 0.00029212458700806444, 'rewards/chosen': 0.6098558902740479, 'rewards/rejected': -12.848189353942871, 'rewards/accuracies': 1.0, 'rewards/margins': 13.45804500579834, 'logps/rejected': -228.94192504882812, 'logps/chosen': -71.22616577148438, 'logits/rejected': -1.287977695465088, 'logits/chosen': -1.3304702043533325, 'epoch': 0.31}
 10%|â–ˆ         | 23/222 [13:37<1:57:23, 35.39s/it] 11%|â–ˆ         | 24/222 [14:13<1:56:49, 35.40s/it]                                                  {'loss': 0.008, 'grad_norm': 0.019358700141310692, 'learning_rate': 0.0002914316168191626, 'rewards/chosen': 0.5245234966278076, 'rewards/rejected': -14.288069725036621, 'rewards/accuracies': 0.984375, 'rewards/margins': 14.812592506408691, 'logps/rejected': -254.59625244140625, 'logps/chosen': -53.239540100097656, 'logits/rejected': -1.243822455406189, 'logits/chosen': -1.2427613735198975, 'epoch': 0.32}
 11%|â–ˆ         | 24/222 [14:13<1:56:49, 35.40s/it] 11%|â–ˆâ–        | 25/222 [14:49<1:56:54, 35.61s/it]                                                  {'loss': 0.0297, 'grad_norm': 0.057490456849336624, 'learning_rate': 0.00029071032403442485, 'rewards/chosen': 0.17641648650169373, 'rewards/rejected': -14.242307662963867, 'rewards/accuracies': 0.984375, 'rewards/margins': 14.418724060058594, 'logps/rejected': -243.48501586914062, 'logps/chosen': -57.822628021240234, 'logits/rejected': -1.2170053720474243, 'logits/chosen': -1.2534449100494385, 'epoch': 0.33}
 11%|â–ˆâ–        | 25/222 [14:49<1:56:54, 35.61s/it] 12%|â–ˆâ–        | 26/222 [15:24<1:56:05, 35.54s/it]                                                  {'loss': 0.007, 'grad_norm': 0.024402886629104614, 'learning_rate': 0.0002899608530973956, 'rewards/chosen': 0.7911660671234131, 'rewards/rejected': -13.815394401550293, 'rewards/accuracies': 1.0, 'rewards/margins': 14.606559753417969, 'logps/rejected': -240.21096801757812, 'logps/chosen': -67.31598663330078, 'logits/rejected': -1.2434818744659424, 'logits/chosen': -1.2535133361816406, 'epoch': 0.35}
 12%|â–ˆâ–        | 26/222 [15:24<1:56:05, 35.54s/it] 12%|â–ˆâ–        | 27/222 [15:59<1:55:18, 35.48s/it]                                                  {'loss': 0.0063, 'grad_norm': 0.027345461770892143, 'learning_rate': 0.0002891833540944764, 'rewards/chosen': 0.47846710681915283, 'rewards/rejected': -13.537869453430176, 'rewards/accuracies': 1.0, 'rewards/margins': 14.016337394714355, 'logps/rejected': -237.7632598876953, 'logps/chosen': -54.099205017089844, 'logits/rejected': -1.3093409538269043, 'logits/chosen': -1.2234876155853271, 'epoch': 0.36}
 12%|â–ˆâ–        | 27/222 [15:59<1:55:18, 35.48s/it] 13%|â–ˆâ–Ž        | 28/222 [16:35<1:54:56, 35.55s/it]                                                  {'loss': 0.0129, 'grad_norm': 0.026665594428777695, 'learning_rate': 0.00028837798272487026, 'rewards/chosen': 0.4751397967338562, 'rewards/rejected': -13.10611629486084, 'rewards/accuracies': 1.0, 'rewards/margins': 13.581256866455078, 'logps/rejected': -233.4886474609375, 'logps/chosen': -57.557891845703125, 'logits/rejected': -1.2872363328933716, 'logits/chosen': -1.2672256231307983, 'epoch': 0.37}
 13%|â–ˆâ–Ž        | 28/222 [16:35<1:54:56, 35.55s/it] 13%|â–ˆâ–Ž        | 29/222 [17:10<1:53:39, 35.34s/it]                                                  {'loss': 0.0182, 'grad_norm': 0.03337712585926056, 'learning_rate': 0.000287544900269402, 'rewards/chosen': 0.5292963981628418, 'rewards/rejected': -12.345516204833984, 'rewards/accuracies': 0.984375, 'rewards/margins': 12.874813079833984, 'logps/rejected': -224.91635131835938, 'logps/chosen': -65.68307495117188, 'logits/rejected': -1.2528016567230225, 'logits/chosen': -1.2930538654327393, 'epoch': 0.39}
 13%|â–ˆâ–Ž        | 29/222 [17:10<1:53:39, 35.34s/it] 14%|â–ˆâ–Ž        | 30/222 [17:45<1:53:14, 35.39s/it]                                                  {'loss': 0.0271, 'grad_norm': 0.056909456849098206, 'learning_rate': 0.00028668427355822034, 'rewards/chosen': 0.5793147683143616, 'rewards/rejected': -12.847809791564941, 'rewards/accuracies': 1.0, 'rewards/margins': 13.4271240234375, 'logps/rejected': -226.60765075683594, 'logps/chosen': -71.79932403564453, 'logits/rejected': -1.3050565719604492, 'logits/chosen': -1.3015798330307007, 'epoch': 0.4}
 14%|â–ˆâ–Ž        | 30/222 [17:46<1:53:14, 35.39s/it] 14%|â–ˆâ–        | 31/222 [18:21<1:52:44, 35.41s/it]                                                  {'loss': 0.0033, 'grad_norm': 0.01088609080761671, 'learning_rate': 0.0002857962749373895, 'rewards/chosen': 0.6164811253547668, 'rewards/rejected': -11.761594772338867, 'rewards/accuracies': 1.0, 'rewards/margins': 12.378074645996094, 'logps/rejected': -198.89727783203125, 'logps/chosen': -67.78480529785156, 'logits/rejected': -1.2903553247451782, 'logits/chosen': -1.298132061958313, 'epoch': 0.41}
 14%|â–ˆâ–        | 31/222 [18:21<1:52:44, 35.41s/it] 14%|â–ˆâ–        | 32/222 [18:56<1:52:03, 35.39s/it]                                                  {'loss': 0.0097, 'grad_norm': 0.024918289855122566, 'learning_rate': 0.0002848810822343755, 'rewards/chosen': 0.5561828017234802, 'rewards/rejected': -13.495112419128418, 'rewards/accuracies': 1.0, 'rewards/margins': 14.051294326782227, 'logps/rejected': -239.3335723876953, 'logps/chosen': -56.961429595947266, 'logits/rejected': -1.206235647201538, 'logits/chosen': -1.262169361114502, 'epoch': 0.43}
 14%|â–ˆâ–        | 32/222 [18:56<1:52:03, 35.39s/it] 15%|â–ˆâ–        | 33/222 [19:32<1:51:22, 35.36s/it]                                                  {'loss': 0.0053, 'grad_norm': 0.019019991159439087, 'learning_rate': 0.0002839388787224353, 'rewards/chosen': 0.6097928285598755, 'rewards/rejected': -12.96349048614502, 'rewards/accuracies': 1.0, 'rewards/margins': 13.573282241821289, 'logps/rejected': -243.6701202392578, 'logps/chosen': -54.15834045410156, 'logits/rejected': -1.2677199840545654, 'logits/chosen': -1.2823891639709473, 'epoch': 0.44}
 15%|â–ˆâ–        | 33/222 [19:32<1:51:22, 35.36s/it] 15%|â–ˆâ–Œ        | 34/222 [20:08<1:51:20, 35.53s/it]                                                  {'loss': 0.0028, 'grad_norm': 0.009612140245735645, 'learning_rate': 0.00028296985308391476, 'rewards/chosen': 0.5330877304077148, 'rewards/rejected': -12.988710403442383, 'rewards/accuracies': 1.0, 'rewards/margins': 13.521797180175781, 'logps/rejected': -227.24864196777344, 'logps/chosen': -75.31957244873047, 'logits/rejected': -1.2583954334259033, 'logits/chosen': -1.2643862962722778, 'epoch': 0.45}
 15%|â–ˆâ–Œ        | 34/222 [20:08<1:51:20, 35.53s/it] 16%|â–ˆâ–Œ        | 35/222 [20:43<1:50:25, 35.43s/it]                                                  {'loss': 0.0195, 'grad_norm': 0.04158661141991615, 'learning_rate': 0.0002819741993724644, 'rewards/chosen': 0.6703320741653442, 'rewards/rejected': -12.823196411132812, 'rewards/accuracies': 1.0, 'rewards/margins': 13.493528366088867, 'logps/rejected': -231.0370635986328, 'logps/chosen': -64.68635559082031, 'logits/rejected': -1.2204877138137817, 'logits/chosen': -1.2530145645141602, 'epoch': 0.47}
 16%|â–ˆâ–Œ        | 35/222 [20:43<1:50:25, 35.43s/it] 16%|â–ˆâ–Œ        | 36/222 [21:18<1:49:41, 35.39s/it]                                                  {'loss': 0.0027, 'grad_norm': 0.006356486119329929, 'learning_rate': 0.0002809521169741782, 'rewards/chosen': 0.6563458442687988, 'rewards/rejected': -13.393838882446289, 'rewards/accuracies': 1.0, 'rewards/margins': 14.050185203552246, 'logps/rejected': -239.98928833007812, 'logps/chosen': -69.95976257324219, 'logits/rejected': -1.2496740818023682, 'logits/chosen': -1.2085143327713013, 'epoch': 0.48}
 16%|â–ˆâ–Œ        | 36/222 [21:18<1:49:41, 35.39s/it] 17%|â–ˆâ–‹        | 37/222 [21:54<1:49:26, 35.50s/it]                                                  {'loss': 0.0042, 'grad_norm': 0.0097280815243721, 'learning_rate': 0.0002799038105676658, 'rewards/chosen': 0.5942726731300354, 'rewards/rejected': -13.540963172912598, 'rewards/accuracies': 1.0, 'rewards/margins': 14.135234832763672, 'logps/rejected': -238.177001953125, 'logps/chosen': -59.732845306396484, 'logits/rejected': -1.270168662071228, 'logits/chosen': -1.282189965248108, 'epoch': 0.49}
 17%|â–ˆâ–‹        | 37/222 [21:54<1:49:26, 35.50s/it] 17%|â–ˆâ–‹        | 38/222 [22:29<1:48:41, 35.45s/it]                                                  {'loss': 0.0031, 'grad_norm': 0.007319334428757429, 'learning_rate': 0.0002788294900830639, 'rewards/chosen': 0.6298949122428894, 'rewards/rejected': -12.038808822631836, 'rewards/accuracies': 1.0, 'rewards/margins': 12.668705940246582, 'logps/rejected': -215.46420288085938, 'logps/chosen': -60.26570129394531, 'logits/rejected': -1.2729934453964233, 'logits/chosen': -1.2379474639892578, 'epoch': 0.51}
 17%|â–ˆâ–‹        | 38/222 [22:29<1:48:41, 35.45s/it] 18%|â–ˆâ–Š        | 39/222 [23:04<1:48:02, 35.43s/it]                                                  {'loss': 0.0084, 'grad_norm': 0.02029063180088997, 'learning_rate': 0.00027772937065999667, 'rewards/chosen': 0.5875871181488037, 'rewards/rejected': -14.10132122039795, 'rewards/accuracies': 1.0, 'rewards/margins': 14.688909530639648, 'logps/rejected': -236.83016967773438, 'logps/chosen': -63.13749694824219, 'logits/rejected': -1.2637853622436523, 'logits/chosen': -1.2613883018493652, 'epoch': 0.52}
 18%|â–ˆâ–Š        | 39/222 [23:04<1:48:02, 35.43s/it] 18%|â–ˆâ–Š        | 40/222 [23:40<1:47:47, 35.54s/it]                                                  {'loss': 0.0021, 'grad_norm': 0.005343768745660782, 'learning_rate': 0.00027660367260449255, 'rewards/chosen': 0.29898566007614136, 'rewards/rejected': -14.532002449035645, 'rewards/accuracies': 1.0, 'rewards/margins': 14.830987930297852, 'logps/rejected': -251.561279296875, 'logps/chosen': -63.656951904296875, 'logits/rejected': -1.3143247365951538, 'logits/chosen': -1.2770334482192993, 'epoch': 0.53}
 18%|â–ˆâ–Š        | 40/222 [23:40<1:47:47, 35.54s/it] 18%|â–ˆâ–Š        | 41/222 [24:16<1:47:07, 35.51s/it]                                                  {'loss': 0.0017, 'grad_norm': 0.00944207888096571, 'learning_rate': 0.0002754526213448664, 'rewards/chosen': 0.3158858120441437, 'rewards/rejected': -14.230024337768555, 'rewards/accuracies': 1.0, 'rewards/margins': 14.545910835266113, 'logps/rejected': -249.68634033203125, 'logps/chosen': -69.02227783203125, 'logits/rejected': -1.2078453302383423, 'logits/chosen': -1.2521017789840698, 'epoch': 0.55}
 18%|â–ˆâ–Š        | 41/222 [24:16<1:47:07, 35.51s/it] 19%|â–ˆâ–‰        | 42/222 [24:51<1:46:24, 35.47s/it]                                                  {'loss': 0.0024, 'grad_norm': 0.004462800454348326, 'learning_rate': 0.0002742764473865763, 'rewards/chosen': 0.6490806937217712, 'rewards/rejected': -13.402091979980469, 'rewards/accuracies': 1.0, 'rewards/margins': 14.051172256469727, 'logps/rejected': -238.60191345214844, 'logps/chosen': -60.52643585205078, 'logits/rejected': -1.2985460758209229, 'logits/chosen': -1.250798225402832, 'epoch': 0.56}
 19%|â–ˆâ–‰        | 42/222 [24:51<1:46:24, 35.47s/it] 19%|â–ˆâ–‰        | 43/222 [25:26<1:45:42, 35.43s/it]                                                  {'loss': 0.0024, 'grad_norm': 0.003991718869656324, 'learning_rate': 0.0002730753862660631, 'rewards/chosen': 0.40707671642303467, 'rewards/rejected': -13.817584991455078, 'rewards/accuracies': 1.0, 'rewards/margins': 14.224660873413086, 'logps/rejected': -232.27847290039062, 'logps/chosen': -55.046714782714844, 'logits/rejected': -1.2814985513687134, 'logits/chosen': -1.2602267265319824, 'epoch': 0.57}
 19%|â–ˆâ–‰        | 43/222 [25:26<1:45:42, 35.43s/it] 20%|â–ˆâ–‰        | 44/222 [26:02<1:45:15, 35.48s/it]                                                  {'loss': 0.0024, 'grad_norm': 0.007995073683559895, 'learning_rate': 0.00027184967850358286, 'rewards/chosen': 0.4006922245025635, 'rewards/rejected': -14.653205871582031, 'rewards/accuracies': 1.0, 'rewards/margins': 15.053898811340332, 'logps/rejected': -259.0975341796875, 'logps/chosen': -66.66242218017578, 'logits/rejected': -1.2417652606964111, 'logits/chosen': -1.2544972896575928, 'epoch': 0.59}
 20%|â–ˆâ–‰        | 44/222 [26:02<1:45:15, 35.48s/it] 20%|â–ˆâ–ˆ        | 45/222 [26:37<1:44:19, 35.36s/it]                                                  {'loss': 0.0087, 'grad_norm': 0.013480761088430882, 'learning_rate': 0.0002705995695550411, 'rewards/chosen': 0.5938773155212402, 'rewards/rejected': -14.27949047088623, 'rewards/accuracies': 1.0, 'rewards/margins': 14.873367309570312, 'logps/rejected': -249.1453094482422, 'logps/chosen': -62.864707946777344, 'logits/rejected': -1.328181505203247, 'logits/chosen': -1.2910767793655396, 'epoch': 0.6}
 20%|â–ˆâ–ˆ        | 45/222 [26:37<1:44:19, 35.36s/it] 21%|â–ˆâ–ˆ        | 46/222 [27:13<1:43:53, 35.42s/it]                                                  {'loss': 0.0085, 'grad_norm': 0.018685966730117798, 'learning_rate': 0.0002693253097628385, 'rewards/chosen': 0.34131449460983276, 'rewards/rejected': -15.61109733581543, 'rewards/accuracies': 0.984375, 'rewards/margins': 15.952411651611328, 'logps/rejected': -262.0495300292969, 'logps/chosen': -55.403656005859375, 'logits/rejected': -1.2607450485229492, 'logits/chosen': -1.2464025020599365, 'epoch': 0.61}
 21%|â–ˆâ–ˆ        | 46/222 [27:13<1:43:53, 35.42s/it] 21%|â–ˆâ–ˆ        | 47/222 [27:48<1:43:17, 35.42s/it]                                                  {'loss': 0.0015, 'grad_norm': 0.0031319872941821814, 'learning_rate': 0.0002680271543057385, 'rewards/chosen': 0.6282100081443787, 'rewards/rejected': -13.036494255065918, 'rewards/accuracies': 1.0, 'rewards/margins': 13.664704322814941, 'logps/rejected': -227.80233764648438, 'logps/chosen': -73.69605255126953, 'logits/rejected': -1.291136384010315, 'logits/chosen': -1.2583491802215576, 'epoch': 0.63}
 21%|â–ˆâ–ˆ        | 47/222 [27:48<1:43:17, 35.42s/it] 22%|â–ˆâ–ˆâ–       | 48/222 [28:24<1:42:43, 35.42s/it]                                                  {'loss': 0.0039, 'grad_norm': 0.0054831295274198055, 'learning_rate': 0.00026670536314776593, 'rewards/chosen': 0.6156171560287476, 'rewards/rejected': -13.238361358642578, 'rewards/accuracies': 1.0, 'rewards/margins': 13.85397720336914, 'logps/rejected': -237.6641845703125, 'logps/chosen': -72.4474105834961, 'logits/rejected': -1.2582083940505981, 'logits/chosen': -1.2697687149047852, 'epoch': 0.64}
 22%|â–ˆâ–ˆâ–       | 48/222 [28:24<1:42:43, 35.42s/it] 22%|â–ˆâ–ˆâ–       | 49/222 [28:59<1:41:56, 35.36s/it]                                                  {'loss': 0.0037, 'grad_norm': 0.007783019449561834, 'learning_rate': 0.0002653602009861475, 'rewards/chosen': 0.5335320830345154, 'rewards/rejected': -14.915302276611328, 'rewards/accuracies': 1.0, 'rewards/margins': 15.448834419250488, 'logps/rejected': -241.1590118408203, 'logps/chosen': -56.30906677246094, 'logits/rejected': -1.2863757610321045, 'logits/chosen': -1.2696691751480103, 'epoch': 0.65}
 22%|â–ˆâ–ˆâ–       | 49/222 [28:59<1:41:56, 35.36s/it] 23%|â–ˆâ–ˆâ–Ž       | 50/222 [29:34<1:41:04, 35.26s/it]                                                  {'loss': 0.0064, 'grad_norm': 0.013171049766242504, 'learning_rate': 0.00026399193719830457, 'rewards/chosen': 0.5285082459449768, 'rewards/rejected': -14.635354995727539, 'rewards/accuracies': 1.0, 'rewards/margins': 15.163862228393555, 'logps/rejected': -241.3506317138672, 'logps/chosen': -63.95709228515625, 'logits/rejected': -1.2960180044174194, 'logits/chosen': -1.2321908473968506, 'epoch': 0.67}
 23%|â–ˆâ–ˆâ–Ž       | 50/222 [29:34<1:41:04, 35.26s/it] 23%|â–ˆâ–ˆâ–Ž       | 51/222 [30:09<1:40:34, 35.29s/it]                                                  {'loss': 0.0112, 'grad_norm': 0.030279871076345444, 'learning_rate': 0.0002626008457879086, 'rewards/chosen': 0.4479755163192749, 'rewards/rejected': -13.254738807678223, 'rewards/accuracies': 0.984375, 'rewards/margins': 13.702714920043945, 'logps/rejected': -242.91786193847656, 'logps/chosen': -64.27942657470703, 'logits/rejected': -1.2615340948104858, 'logits/chosen': -1.1978751420974731, 'epoch': 0.68}
 23%|â–ˆâ–ˆâ–Ž       | 51/222 [30:09<1:40:34, 35.29s/it] 23%|â–ˆâ–ˆâ–Ž       | 52/222 [30:45<1:40:22, 35.43s/it]                                                  {'loss': 0.0032, 'grad_norm': 0.006355287041515112, 'learning_rate': 0.00026118720533001, 'rewards/chosen': 0.49836716055870056, 'rewards/rejected': -14.952411651611328, 'rewards/accuracies': 1.0, 'rewards/margins': 15.450779914855957, 'logps/rejected': -253.63137817382812, 'logps/chosen': -62.43061065673828, 'logits/rejected': -1.2441374063491821, 'logits/chosen': -1.2741398811340332, 'epoch': 0.69}
 23%|â–ˆâ–ˆâ–Ž       | 52/222 [30:45<1:40:22, 35.43s/it] 24%|â–ˆâ–ˆâ–       | 53/222 [31:21<1:40:23, 35.64s/it]                                                  {'loss': 0.0039, 'grad_norm': 0.022563565522432327, 'learning_rate': 0.0002597512989152517, 'rewards/chosen': 0.30454325675964355, 'rewards/rejected': -14.87490177154541, 'rewards/accuracies': 1.0, 'rewards/margins': 15.179445266723633, 'logps/rejected': -242.63946533203125, 'logps/chosen': -71.731201171875, 'logits/rejected': -1.1780788898468018, 'logits/chosen': -1.2324535846710205, 'epoch': 0.71}
 24%|â–ˆâ–ˆâ–       | 53/222 [31:21<1:40:23, 35.64s/it] 24%|â–ˆâ–ˆâ–       | 54/222 [31:56<1:39:38, 35.59s/it]                                                  {'loss': 0.0116, 'grad_norm': 0.02991662733256817, 'learning_rate': 0.0002582934140931786, 'rewards/chosen': 0.5842143893241882, 'rewards/rejected': -15.174711227416992, 'rewards/accuracies': 1.0, 'rewards/margins': 15.75892448425293, 'logps/rejected': -257.4931945800781, 'logps/chosen': -63.57691955566406, 'logits/rejected': -1.2955920696258545, 'logits/chosen': -1.246317744255066, 'epoch': 0.72}
 24%|â–ˆâ–ˆâ–       | 54/222 [31:56<1:39:38, 35.59s/it] 25%|â–ˆâ–ˆâ–       | 55/222 [32:32<1:38:42, 35.46s/it]                                                  {'loss': 0.0183, 'grad_norm': 0.03712499886751175, 'learning_rate': 0.00025681384281465384, 'rewards/chosen': 0.3498450517654419, 'rewards/rejected': -15.614669799804688, 'rewards/accuracies': 1.0, 'rewards/margins': 15.964515686035156, 'logps/rejected': -252.67059326171875, 'logps/chosen': -54.99622344970703, 'logits/rejected': -1.2384228706359863, 'logits/chosen': -1.2056293487548828, 'epoch': 0.73}
 25%|â–ˆâ–ˆâ–       | 55/222 [32:32<1:38:42, 35.46s/it] 25%|â–ˆâ–ˆâ–Œ       | 56/222 [33:07<1:38:13, 35.50s/it]                                                  {'loss': 0.0011, 'grad_norm': 0.0026604123413562775, 'learning_rate': 0.0002553128813733934, 'rewards/chosen': 0.5298769474029541, 'rewards/rejected': -15.969535827636719, 'rewards/accuracies': 1.0, 'rewards/margins': 16.499412536621094, 'logps/rejected': -276.09710693359375, 'logps/chosen': -57.880489349365234, 'logits/rejected': -1.2659721374511719, 'logits/chosen': -1.2356675863265991, 'epoch': 0.75}
 25%|â–ˆâ–ˆâ–Œ       | 56/222 [33:07<1:38:13, 35.50s/it] 26%|â–ˆâ–ˆâ–Œ       | 57/222 [33:43<1:37:30, 35.46s/it]                                                  {'loss': 0.0011, 'grad_norm': 0.002044483320787549, 'learning_rate': 0.00025379083034663194, 'rewards/chosen': 0.42309150099754333, 'rewards/rejected': -15.128820419311523, 'rewards/accuracies': 1.0, 'rewards/margins': 15.551911354064941, 'logps/rejected': -257.6064758300781, 'logps/chosen': -61.5189323425293, 'logits/rejected': -1.2509716749191284, 'logits/chosen': -1.1927862167358398, 'epoch': 0.76}
 26%|â–ˆâ–ˆâ–Œ       | 57/222 [33:43<1:37:30, 35.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 58/222 [34:18<1:36:38, 35.36s/it]                                                  {'loss': 0.0057, 'grad_norm': 0.023174339905381203, 'learning_rate': 0.0002522479945349299, 'rewards/chosen': 0.6020421385765076, 'rewards/rejected': -14.30357551574707, 'rewards/accuracies': 1.0, 'rewards/margins': 14.905617713928223, 'logps/rejected': -234.94529724121094, 'logps/chosen': -67.15773010253906, 'logits/rejected': -1.2723591327667236, 'logits/chosen': -1.258191704750061, 'epoch': 0.77}
 26%|â–ˆâ–ˆâ–Œ       | 58/222 [34:18<1:36:38, 35.36s/it] 27%|â–ˆâ–ˆâ–‹       | 59/222 [34:53<1:36:05, 35.37s/it]                                                  {'loss': 0.0104, 'grad_norm': 0.029621591791510582, 'learning_rate': 0.0002506846829011354, 'rewards/chosen': 0.2547091841697693, 'rewards/rejected': -14.32177734375, 'rewards/accuracies': 1.0, 'rewards/margins': 14.576485633850098, 'logps/rejected': -235.2797088623047, 'logps/chosen': -63.69683837890625, 'logits/rejected': -1.2600367069244385, 'logits/chosen': -1.2249929904937744, 'epoch': 0.79}
 27%|â–ˆâ–ˆâ–‹       | 59/222 [34:53<1:36:05, 35.37s/it] 27%|â–ˆâ–ˆâ–‹       | 60/222 [35:29<1:35:35, 35.41s/it]                                                  {'loss': 0.0039, 'grad_norm': 0.008441627025604248, 'learning_rate': 0.00024910120850851216, 'rewards/chosen': 0.6830248832702637, 'rewards/rejected': -15.196722984313965, 'rewards/accuracies': 1.0, 'rewards/margins': 15.87974739074707, 'logps/rejected': -272.44000244140625, 'logps/chosen': -66.21630096435547, 'logits/rejected': -1.2954797744750977, 'logits/chosen': -1.192726492881775, 'epoch': 0.8}
 27%|â–ˆâ–ˆâ–‹       | 60/222 [35:29<1:35:35, 35.41s/it] 27%|â–ˆâ–ˆâ–‹       | 61/222 [36:04<1:35:09, 35.47s/it]                                                  {'loss': 0.0073, 'grad_norm': 0.019570134580135345, 'learning_rate': 0.000247497888458047, 'rewards/chosen': 0.5181385278701782, 'rewards/rejected': -14.440722465515137, 'rewards/accuracies': 1.0, 'rewards/margins': 14.958863258361816, 'logps/rejected': -239.58152770996094, 'logps/chosen': -52.53714370727539, 'logits/rejected': -1.314713478088379, 'logits/chosen': -1.277099847793579, 'epoch': 0.81}
 27%|â–ˆâ–ˆâ–‹       | 61/222 [36:04<1:35:09, 35.47s/it] 28%|â–ˆâ–ˆâ–Š       | 62/222 [36:40<1:34:47, 35.55s/it]                                                  {'loss': 0.0136, 'grad_norm': 0.025983896106481552, 'learning_rate': 0.00024587504382494774, 'rewards/chosen': 0.6032120585441589, 'rewards/rejected': -12.344621658325195, 'rewards/accuracies': 0.96875, 'rewards/margins': 12.947834014892578, 'logps/rejected': -208.53343200683594, 'logps/chosen': -69.85578155517578, 'logits/rejected': -1.258205533027649, 'logits/chosen': -1.275613784790039, 'epoch': 0.83}
 28%|â–ˆâ–ˆâ–Š       | 62/222 [36:40<1:34:47, 35.55s/it] 28%|â–ˆâ–ˆâ–Š       | 63/222 [37:15<1:34:05, 35.50s/it]                                                  {'loss': 0.0049, 'grad_norm': 0.02268766239285469, 'learning_rate': 0.00024423299959434636, 'rewards/chosen': 0.7654565572738647, 'rewards/rejected': -13.250617027282715, 'rewards/accuracies': 1.0, 'rewards/margins': 14.016073226928711, 'logps/rejected': -223.71029663085938, 'logps/chosen': -72.30068969726562, 'logits/rejected': -1.2423970699310303, 'logits/chosen': -1.3020386695861816, 'epoch': 0.84}
 28%|â–ˆâ–ˆâ–Š       | 63/222 [37:15<1:34:05, 35.50s/it] 29%|â–ˆâ–ˆâ–‰       | 64/222 [37:51<1:33:35, 35.54s/it]                                                  {'loss': 0.0059, 'grad_norm': 0.02148226462304592, 'learning_rate': 0.00024257208459621828, 'rewards/chosen': 0.594765305519104, 'rewards/rejected': -15.062894821166992, 'rewards/accuracies': 1.0, 'rewards/margins': 15.657660484313965, 'logps/rejected': -249.93600463867188, 'logps/chosen': -73.05765533447266, 'logits/rejected': -1.252733826637268, 'logits/chosen': -1.2785269021987915, 'epoch': 0.85}
 29%|â–ˆâ–ˆâ–‰       | 64/222 [37:51<1:33:35, 35.54s/it] 29%|â–ˆâ–ˆâ–‰       | 65/222 [38:27<1:33:20, 35.67s/it]                                                  {'loss': 0.0014, 'grad_norm': 0.0030582663603127003, 'learning_rate': 0.0002408926314395322, 'rewards/chosen': 0.5014303922653198, 'rewards/rejected': -13.933034896850586, 'rewards/accuracies': 1.0, 'rewards/margins': 14.434466361999512, 'logps/rejected': -220.51193237304688, 'logps/chosen': -70.84313201904297, 'logits/rejected': -1.230190634727478, 'logits/chosen': -1.2971861362457275, 'epoch': 0.87}
 29%|â–ˆâ–ˆâ–‰       | 65/222 [38:27<1:33:20, 35.67s/it] 30%|â–ˆâ–ˆâ–‰       | 66/222 [39:02<1:32:29, 35.57s/it]                                                  {'loss': 0.0018, 'grad_norm': 0.003878442570567131, 'learning_rate': 0.00023919497644564298, 'rewards/chosen': 0.36745935678482056, 'rewards/rejected': -15.657459259033203, 'rewards/accuracies': 1.0, 'rewards/margins': 16.024919509887695, 'logps/rejected': -257.3191223144531, 'logps/chosen': -60.925804138183594, 'logits/rejected': -1.3063642978668213, 'logits/chosen': -1.2724733352661133, 'epoch': 0.88}
 30%|â–ˆâ–ˆâ–‰       | 66/222 [39:02<1:32:29, 35.57s/it] 30%|â–ˆâ–ˆâ–ˆ       | 67/222 [39:38<1:31:55, 35.58s/it]                                                  {'loss': 0.0011, 'grad_norm': 0.0036151143722236156, 'learning_rate': 0.00023747945958094098, 'rewards/chosen': 0.8410292267799377, 'rewards/rejected': -14.47199821472168, 'rewards/accuracies': 1.0, 'rewards/margins': 15.31302547454834, 'logps/rejected': -250.07981872558594, 'logps/chosen': -60.90394973754883, 'logits/rejected': -1.2285284996032715, 'logits/chosen': -1.2794160842895508, 'epoch': 0.89}
 30%|â–ˆâ–ˆâ–ˆ       | 67/222 [39:38<1:31:55, 35.58s/it] 31%|â–ˆâ–ˆâ–ˆ       | 68/222 [40:13<1:31:19, 35.58s/it]                                                  {'loss': 0.0005, 'grad_norm': 0.0012068833457306027, 'learning_rate': 0.0002357464243887718, 'rewards/chosen': 0.832842230796814, 'rewards/rejected': -13.717377662658691, 'rewards/accuracies': 1.0, 'rewards/margins': 14.550219535827637, 'logps/rejected': -241.15362548828125, 'logps/chosen': -73.09141540527344, 'logits/rejected': -1.2992053031921387, 'logits/chosen': -1.2956324815750122, 'epoch': 0.91}
 31%|â–ˆâ–ˆâ–ˆ       | 68/222 [40:13<1:31:19, 35.58s/it] 31%|â–ˆâ–ˆâ–ˆ       | 69/222 [40:49<1:30:35, 35.53s/it]                                                  {'loss': 0.0049, 'grad_norm': 0.012394393794238567, 'learning_rate': 0.00023399621792063928, 'rewards/chosen': 0.3956947922706604, 'rewards/rejected': -13.640996932983398, 'rewards/accuracies': 0.984375, 'rewards/margins': 14.036689758300781, 'logps/rejected': -223.59628295898438, 'logps/chosen': -67.26265716552734, 'logits/rejected': -1.2706024646759033, 'logits/chosen': -1.26970374584198, 'epoch': 0.92}
 31%|â–ˆâ–ˆâ–ˆ       | 69/222 [40:49<1:30:35, 35.53s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 70/222 [41:24<1:29:55, 35.50s/it]                                                  {'loss': 0.0012, 'grad_norm': 0.0028294778894633055, 'learning_rate': 0.00023222919066670647, 'rewards/chosen': 0.5853002667427063, 'rewards/rejected': -15.015358924865723, 'rewards/accuracies': 1.0, 'rewards/margins': 15.60065746307373, 'logps/rejected': -246.87335205078125, 'logps/chosen': -61.09131622314453, 'logits/rejected': -1.2187846899032593, 'logits/chosen': -1.2515407800674438, 'epoch': 0.93}
 32%|â–ˆâ–ˆâ–ˆâ–      | 70/222 [41:24<1:29:55, 35.50s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 71/222 [42:00<1:29:19, 35.49s/it]                                                  {'loss': 0.0009, 'grad_norm': 0.004162383731454611, 'learning_rate': 0.00023044569648560733, 'rewards/chosen': 0.7088287472724915, 'rewards/rejected': -14.417278289794922, 'rewards/accuracies': 1.0, 'rewards/margins': 15.126107215881348, 'logps/rejected': -239.1703643798828, 'logps/chosen': -64.18359375, 'logits/rejected': -1.2894762754440308, 'logits/chosen': -1.2879977226257324, 'epoch': 0.95}
 32%|â–ˆâ–ˆâ–ˆâ–      | 71/222 [42:00<1:29:19, 35.49s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 72/222 [42:35<1:28:36, 35.44s/it]                                                  {'loss': 0.0044, 'grad_norm': 0.00779072055593133, 'learning_rate': 0.00022864609253358474, 'rewards/chosen': 0.6109966039657593, 'rewards/rejected': -14.489917755126953, 'rewards/accuracies': 1.0, 'rewards/margins': 15.100913047790527, 'logps/rejected': -246.37255859375, 'logps/chosen': -58.790138244628906, 'logits/rejected': -1.2790238857269287, 'logits/chosen': -1.2433255910873413, 'epoch': 0.96}
 32%|â–ˆâ–ˆâ–ˆâ–      | 72/222 [42:35<1:28:36, 35.44s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 73/222 [43:11<1:28:04, 35.47s/it]                                                  {'loss': 0.0026, 'grad_norm': 0.009998851455748081, 'learning_rate': 0.0002268307391929671, 'rewards/chosen': 0.6475644111633301, 'rewards/rejected': -15.525659561157227, 'rewards/accuracies': 1.0, 'rewards/margins': 16.1732234954834, 'logps/rejected': -265.1434020996094, 'logps/chosen': -48.259132385253906, 'logits/rejected': -1.3486244678497314, 'logits/chosen': -1.1780729293823242, 'epoch': 0.97}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 73/222 [43:11<1:28:04, 35.47s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 74/222 [43:46<1:27:32, 35.49s/it]                                                  {'loss': 0.0051, 'grad_norm': 0.015288867056369781, 'learning_rate': 0.000225, 'rewards/chosen': 0.3712136149406433, 'rewards/rejected': -15.976112365722656, 'rewards/accuracies': 1.0, 'rewards/margins': 16.347326278686523, 'logps/rejected': -263.3631591796875, 'logps/chosen': -54.43109130859375, 'logits/rejected': -1.2477933168411255, 'logits/chosen': -1.262360692024231, 'epoch': 0.99}
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 74/222 [43:46<1:27:32, 35.49s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 75/222 [44:22<1:26:52, 35.46s/it]                                                  {'loss': 0.0007, 'grad_norm': 0.0014242189936339855, 'learning_rate': 0.00022315424157204518, 'rewards/chosen': 0.8303490877151489, 'rewards/rejected': -15.543318748474121, 'rewards/accuracies': 1.0, 'rewards/margins': 16.373666763305664, 'logps/rejected': -258.1849365234375, 'logps/chosen': -59.919342041015625, 'logits/rejected': -1.3021963834762573, 'logits/chosen': -1.2996841669082642, 'epoch': 1.0}
 34%|â–ˆâ–ˆâ–ˆâ–      | 75/222 [44:22<1:26:52, 35.46s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 76/222 [44:57<1:26:16, 35.46s/it]                                                  {'loss': 0.0023, 'grad_norm': 0.004121685400605202, 'learning_rate': 0.00022129383353416347, 'rewards/chosen': 0.4252353608608246, 'rewards/rejected': -14.461699485778809, 'rewards/accuracies': 1.0, 'rewards/margins': 14.886934280395508, 'logps/rejected': -250.9639892578125, 'logps/chosen': -58.489898681640625, 'logits/rejected': -1.3306846618652344, 'logits/chosen': -1.254359483718872, 'epoch': 1.02}
 34%|â–ˆâ–ˆâ–ˆâ–      | 76/222 [44:57<1:26:16, 35.46s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 77/222 [45:33<1:25:46, 35.49s/it]                                                  {'loss': 0.0037, 'grad_norm': 0.018658192828297615, 'learning_rate': 0.00021941914844509483, 'rewards/chosen': 0.37050285935401917, 'rewards/rejected': -14.590474128723145, 'rewards/accuracies': 1.0, 'rewards/margins': 14.960975646972656, 'logps/rejected': -248.40505981445312, 'logps/chosen': -58.78943634033203, 'logits/rejected': -1.2736632823944092, 'logits/chosen': -1.226367473602295, 'epoch': 1.03}
 35%|â–ˆâ–ˆâ–ˆâ–      | 77/222 [45:33<1:25:46, 35.49s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 78/222 [46:08<1:25:25, 35.59s/it]                                                  {'loss': 0.0009, 'grad_norm': 0.0017501661786809564, 'learning_rate': 0.00021753056172265096, 'rewards/chosen': 0.48929059505462646, 'rewards/rejected': -15.719361305236816, 'rewards/accuracies': 1.0, 'rewards/margins': 16.20865249633789, 'logps/rejected': -260.0767517089844, 'logps/chosen': -57.59297180175781, 'logits/rejected': -1.2917485237121582, 'logits/chosen': -1.2503721714019775, 'epoch': 1.04}
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 78/222 [46:08<1:25:25, 35.59s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 79/222 [46:44<1:24:44, 35.56s/it]                                                  {'loss': 0.002, 'grad_norm': 0.0050097983330488205, 'learning_rate': 0.00021562845156853562, 'rewards/chosen': 0.2917596101760864, 'rewards/rejected': -15.041590690612793, 'rewards/accuracies': 1.0, 'rewards/margins': 15.33335018157959, 'logps/rejected': -243.678955078125, 'logps/chosen': -64.78612518310547, 'logits/rejected': -1.271329641342163, 'logits/chosen': -1.3143165111541748, 'epoch': 1.06}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 79/222 [46:44<1:24:44, 35.56s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 80/222 [47:19<1:24:02, 35.51s/it]                                                  {'loss': 0.0027, 'grad_norm': 0.010128658264875412, 'learning_rate': 0.00021371319889260717, 'rewards/chosen': 0.5160402655601501, 'rewards/rejected': -14.954914093017578, 'rewards/accuracies': 1.0, 'rewards/margins': 15.470955848693848, 'logps/rejected': -240.98623657226562, 'logps/chosen': -59.06755065917969, 'logits/rejected': -1.2663816213607788, 'logits/chosen': -1.2310938835144043, 'epoch': 1.07}
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 80/222 [47:19<1:24:02, 35.51s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 81/222 [47:55<1:23:22, 35.48s/it]                                                  {'loss': 0.0048, 'grad_norm': 0.0071485587395727634, 'learning_rate': 0.0002117851872365989, 'rewards/chosen': 0.5328807830810547, 'rewards/rejected': -13.799946784973145, 'rewards/accuracies': 0.984375, 'rewards/margins': 14.332826614379883, 'logps/rejected': -238.00582885742188, 'logps/chosen': -58.717552185058594, 'logits/rejected': -1.288069248199463, 'logits/chosen': -1.2301615476608276, 'epoch': 1.08}
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 81/222 [47:55<1:23:22, 35.48s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 82/222 [48:30<1:22:42, 35.44s/it]                                                  {'loss': 0.0021, 'grad_norm': 0.004803122486919165, 'learning_rate': 0.00020984480269731242, 'rewards/chosen': 0.6195048093795776, 'rewards/rejected': -15.169978141784668, 'rewards/accuracies': 1.0, 'rewards/margins': 15.789483070373535, 'logps/rejected': -265.8260498046875, 'logps/chosen': -80.74943542480469, 'logits/rejected': -1.28349769115448, 'logits/chosen': -1.2166486978530884, 'epoch': 1.1}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 82/222 [48:30<1:22:42, 35.44s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 83/222 [49:05<1:21:51, 35.33s/it]                                                  {'loss': 0.0009, 'grad_norm': 0.00160594389308244, 'learning_rate': 0.0002078924338492993, 'rewards/chosen': 0.4589599370956421, 'rewards/rejected': -15.674771308898926, 'rewards/accuracies': 1.0, 'rewards/margins': 16.133729934692383, 'logps/rejected': -249.66969299316406, 'logps/chosen': -63.40412521362305, 'logits/rejected': -1.2959158420562744, 'logits/chosen': -1.3200534582138062, 'epoch': 1.11}
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 83/222 [49:05<1:21:51, 35.33s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 84/222 [49:40<1:21:11, 35.30s/it]                                                  {'loss': 0.0015, 'grad_norm': 0.003353546839207411, 'learning_rate': 0.0002059284716670463, 'rewards/chosen': 0.5621006488800049, 'rewards/rejected': -16.146352767944336, 'rewards/accuracies': 1.0, 'rewards/margins': 16.708452224731445, 'logps/rejected': -267.7861022949219, 'logps/chosen': -54.00319290161133, 'logits/rejected': -1.2987773418426514, 'logits/chosen': -1.2479205131530762, 'epoch': 1.12}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 84/222 [49:40<1:21:11, 35.30s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 85/222 [50:16<1:20:50, 35.40s/it]                                                  {'loss': 0.0006, 'grad_norm': 0.001335246255621314, 'learning_rate': 0.00020395330944668037, 'rewards/chosen': 0.4849647581577301, 'rewards/rejected': -15.061241149902344, 'rewards/accuracies': 1.0, 'rewards/margins': 15.546205520629883, 'logps/rejected': -254.36105346679688, 'logps/chosen': -65.93959045410156, 'logits/rejected': -1.2865616083145142, 'logits/chosen': -1.2767053842544556, 'epoch': 1.14}
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 85/222 [50:16<1:20:50, 35.40s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 86/222 [50:51<1:19:47, 35.20s/it]                                                  {'loss': 0.0019, 'grad_norm': 0.005172009579837322, 'learning_rate': 0.00020196734272720854, 'rewards/chosen': 0.6509799957275391, 'rewards/rejected': -15.542336463928223, 'rewards/accuracies': 1.0, 'rewards/margins': 16.193317413330078, 'logps/rejected': -251.9949951171875, 'logps/chosen': -52.39426803588867, 'logits/rejected': -1.2958837747573853, 'logits/chosen': -1.2689441442489624, 'epoch': 1.15}
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 86/222 [50:51<1:19:47, 35.20s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 87/222 [51:26<1:19:28, 35.32s/it]                                                  {'loss': 0.0011, 'grad_norm': 0.00489295506849885, 'learning_rate': 0.00019997096921130862, 'rewards/chosen': 0.518303394317627, 'rewards/rejected': -16.305763244628906, 'rewards/accuracies': 1.0, 'rewards/margins': 16.824068069458008, 'logps/rejected': -257.9451599121094, 'logps/chosen': -57.848167419433594, 'logits/rejected': -1.3274561166763306, 'logits/chosen': -1.251174807548523, 'epoch': 1.16}
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 87/222 [51:26<1:19:28, 35.32s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 88/222 [52:02<1:18:59, 35.37s/it]                                                  {'loss': 0.0036, 'grad_norm': 0.016574271023273468, 'learning_rate': 0.00019796458868568678, 'rewards/chosen': 0.4479716122150421, 'rewards/rejected': -15.861263275146484, 'rewards/accuracies': 1.0, 'rewards/margins': 16.309234619140625, 'logps/rejected': -269.2653503417969, 'logps/chosen': -56.65322494506836, 'logits/rejected': -1.2517650127410889, 'logits/chosen': -1.2018284797668457, 'epoch': 1.18}
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 88/222 [52:02<1:18:59, 35.37s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 89/222 [52:39<1:19:28, 35.85s/it]                                                  {'loss': 0.0015, 'grad_norm': 0.0042558093555271626, 'learning_rate': 0.00019594860294101752, 'rewards/chosen': 0.46901410818099976, 'rewards/rejected': -15.285775184631348, 'rewards/accuracies': 1.0, 'rewards/margins': 15.754790306091309, 'logps/rejected': -259.1955261230469, 'logps/chosen': -58.44235610961914, 'logits/rejected': -1.2933036088943481, 'logits/chosen': -1.2012144327163696, 'epoch': 1.19}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 89/222 [52:39<1:19:28, 35.85s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 90/222 [53:14<1:18:15, 35.57s/it]                                                  {'loss': 0.0011, 'grad_norm': 0.003210546215996146, 'learning_rate': 0.00019392341569148252, 'rewards/chosen': 0.3251875042915344, 'rewards/rejected': -16.70903968811035, 'rewards/accuracies': 1.0, 'rewards/margins': 17.03422737121582, 'logps/rejected': -280.9901123046875, 'logps/chosen': -75.23185729980469, 'logits/rejected': -1.2911227941513062, 'logits/chosen': -1.328857421875, 'epoch': 1.2}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 90/222 [53:14<1:18:15, 35.57s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 91/222 [53:49<1:17:26, 35.47s/it]                                                  {'loss': 0.0009, 'grad_norm': 0.0027109195943921804, 'learning_rate': 0.0001918894324939245, 'rewards/chosen': 0.2828492224216461, 'rewards/rejected': -15.92607307434082, 'rewards/accuracies': 1.0, 'rewards/margins': 16.20892333984375, 'logps/rejected': -265.0639343261719, 'logps/chosen': -53.97810745239258, 'logits/rejected': -1.3484768867492676, 'logits/chosen': -1.3003168106079102, 'epoch': 1.22}
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 91/222 [53:49<1:17:26, 35.47s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 92/222 [54:24<1:16:24, 35.27s/it]                                                  {'loss': 0.0011, 'grad_norm': 0.0028413760010153055, 'learning_rate': 0.00018984706066663143, 'rewards/chosen': 0.44527944922447205, 'rewards/rejected': -17.14655303955078, 'rewards/accuracies': 1.0, 'rewards/margins': 17.59183120727539, 'logps/rejected': -278.5603942871094, 'logps/chosen': -77.81849670410156, 'logits/rejected': -1.2571995258331299, 'logits/chosen': -1.2746129035949707, 'epoch': 1.23}
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 92/222 [54:24<1:16:24, 35.27s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 93/222 [54:59<1:16:00, 35.35s/it]                                                  {'loss': 0.0008, 'grad_norm': 0.0022004807833582163, 'learning_rate': 0.00018779670920776877, 'rewards/chosen': 0.5140420198440552, 'rewards/rejected': -15.834707260131836, 'rewards/accuracies': 1.0, 'rewards/margins': 16.3487491607666, 'logps/rejected': -263.9977111816406, 'logps/chosen': -70.97215270996094, 'logits/rejected': -1.21793794631958, 'logits/chosen': -1.217179775238037, 'epoch': 1.24}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 93/222 [54:59<1:16:00, 35.35s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 94/222 [55:35<1:15:33, 35.41s/it]                                                  {'loss': 0.0026, 'grad_norm': 0.009786611422896385, 'learning_rate': 0.00018573878871347473, 'rewards/chosen': 0.6014276146888733, 'rewards/rejected': -16.492408752441406, 'rewards/accuracies': 1.0, 'rewards/margins': 17.093835830688477, 'logps/rejected': -261.2842712402344, 'logps/chosen': -69.28257751464844, 'logits/rejected': -1.2799464464187622, 'logits/chosen': -1.238463044166565, 'epoch': 1.26}
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 94/222 [55:35<1:15:33, 35.41s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 95/222 [56:10<1:14:42, 35.29s/it]                                                  {'loss': 0.0007, 'grad_norm': 0.002187752164900303, 'learning_rate': 0.00018367371129563586, 'rewards/chosen': 0.4883970618247986, 'rewards/rejected': -16.1197452545166, 'rewards/accuracies': 1.0, 'rewards/margins': 16.608142852783203, 'logps/rejected': -253.74359130859375, 'logps/chosen': -54.17692184448242, 'logits/rejected': -1.315673828125, 'logits/chosen': -1.2729179859161377, 'epoch': 1.27}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 95/222 [56:10<1:14:42, 35.29s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 96/222 [56:46<1:14:23, 35.43s/it]                                                  {'loss': 0.0014, 'grad_norm': 0.006249789614230394, 'learning_rate': 0.00018160189049935892, 'rewards/chosen': 0.26578256487846375, 'rewards/rejected': -16.03864860534668, 'rewards/accuracies': 1.0, 'rewards/margins': 16.304431915283203, 'logps/rejected': -249.15084838867188, 'logps/chosen': -53.526214599609375, 'logits/rejected': -1.3364243507385254, 'logits/chosen': -1.3086044788360596, 'epoch': 1.28}
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 96/222 [56:46<1:14:23, 35.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 97/222 [57:21<1:13:38, 35.35s/it]                                                  {'loss': 0.0022, 'grad_norm': 0.004497256595641375, 'learning_rate': 0.0001795237412201558, 'rewards/chosen': 0.4894380271434784, 'rewards/rejected': -16.062744140625, 'rewards/accuracies': 1.0, 'rewards/margins': 16.552181243896484, 'logps/rejected': -262.33349609375, 'logps/chosen': -55.22446060180664, 'logits/rejected': -1.3447438478469849, 'logits/chosen': -1.2343151569366455, 'epoch': 1.3}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 97/222 [57:21<1:13:38, 35.35s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 98/222 [57:56<1:13:03, 35.35s/it]                                                  {'loss': 0.001, 'grad_norm': 0.0033271375577896833, 'learning_rate': 0.00017743967962085798, 'rewards/chosen': 0.43887579441070557, 'rewards/rejected': -16.687179565429688, 'rewards/accuracies': 1.0, 'rewards/margins': 17.126054763793945, 'logps/rejected': -289.7488098144531, 'logps/chosen': -60.41659927368164, 'logits/rejected': -1.2529138326644897, 'logits/chosen': -1.2084593772888184, 'epoch': 1.31}
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 98/222 [57:56<1:13:03, 35.35s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 99/222 [58:32<1:12:38, 35.43s/it]                                                  {'loss': 0.0024, 'grad_norm': 0.014578012749552727, 'learning_rate': 0.00017535012304827736, 'rewards/chosen': 0.44147586822509766, 'rewards/rejected': -19.27496910095215, 'rewards/accuracies': 1.0, 'rewards/margins': 19.71644401550293, 'logps/rejected': -324.7601013183594, 'logps/chosen': -54.196964263916016, 'logits/rejected': -1.2711683511734009, 'logits/chosen': -1.2323657274246216, 'epoch': 1.32}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 99/222 [58:32<1:12:38, 35.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 100/222 [59:08<1:12:25, 35.62s/it]                                                   {'loss': 0.001, 'grad_norm': 0.0016946623800322413, 'learning_rate': 0.00017325548994962965, 'rewards/chosen': 0.7134270071983337, 'rewards/rejected': -16.636184692382812, 'rewards/accuracies': 1.0, 'rewards/margins': 17.349613189697266, 'logps/rejected': -252.75979614257812, 'logps/chosen': -69.40687561035156, 'logits/rejected': -1.2794933319091797, 'logits/chosen': -1.3007451295852661, 'epoch': 1.34}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 100/222 [59:08<1:12:25, 35.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 101/222 [59:43<1:11:47, 35.60s/it]                                                   {'loss': 0.0037, 'grad_norm': 0.006646290887147188, 'learning_rate': 0.00017115619978873788, 'rewards/chosen': 0.5928747057914734, 'rewards/rejected': -15.753077507019043, 'rewards/accuracies': 1.0, 'rewards/margins': 16.3459529876709, 'logps/rejected': -264.3302001953125, 'logps/chosen': -59.959259033203125, 'logits/rejected': -1.3191001415252686, 'logits/chosen': -1.2199311256408691, 'epoch': 1.35}
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 101/222 [59:43<1:11:47, 35.60s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 102/222 [1:00:19<1:11:22, 35.69s/it]                                                     {'loss': 0.0012, 'grad_norm': 0.00319258077070117, 'learning_rate': 0.0001690526729620318, 'rewards/chosen': 0.3381709158420563, 'rewards/rejected': -17.42218589782715, 'rewards/accuracies': 1.0, 'rewards/margins': 17.760356903076172, 'logps/rejected': -287.5788269042969, 'logps/chosen': -61.40020751953125, 'logits/rejected': -1.325649619102478, 'logits/chosen': -1.2047710418701172, 'epoch': 1.36}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 102/222 [1:00:19<1:11:22, 35.69s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 103/222 [1:00:55<1:11:05, 35.85s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.0020507017616182566, 'learning_rate': 0.00016694533071436092, 'rewards/chosen': 0.4278322458267212, 'rewards/rejected': -16.9957218170166, 'rewards/accuracies': 1.0, 'rewards/margins': 17.423553466796875, 'logps/rejected': -269.16552734375, 'logps/chosen': -59.22521209716797, 'logits/rejected': -1.3000431060791016, 'logits/chosen': -1.254610538482666, 'epoch': 1.38}
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 103/222 [1:00:55<1:11:05, 35.85s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 104/222 [1:01:30<1:10:01, 35.61s/it]                                                     {'loss': 0.0034, 'grad_norm': 0.01004568487405777, 'learning_rate': 0.00016483459505463747, 'rewards/chosen': 0.7276510000228882, 'rewards/rejected': -17.837188720703125, 'rewards/accuracies': 1.0, 'rewards/margins': 18.564838409423828, 'logps/rejected': -275.3447265625, 'logps/chosen': -49.86411666870117, 'logits/rejected': -1.2805256843566895, 'logits/chosen': -1.2689270973205566, 'epoch': 1.39}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 104/222 [1:01:30<1:10:01, 35.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 105/222 [1:02:06<1:09:21, 35.57s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.0008793913875706494, 'learning_rate': 0.00016272088867132637, 'rewards/chosen': 0.4454377293586731, 'rewards/rejected': -17.601598739624023, 'rewards/accuracies': 1.0, 'rewards/margins': 18.04703712463379, 'logps/rejected': -258.3473205566406, 'logps/chosen': -61.06492614746094, 'logits/rejected': -1.25102698802948, 'logits/chosen': -1.2920817136764526, 'epoch': 1.4}
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 105/222 [1:02:06<1:09:21, 35.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 106/222 [1:02:42<1:08:45, 35.57s/it]                                                     {'loss': 0.0008, 'grad_norm': 0.003545141778886318, 'learning_rate': 0.00016060463484779918, 'rewards/chosen': 0.3347415328025818, 'rewards/rejected': -16.182954788208008, 'rewards/accuracies': 1.0, 'rewards/margins': 16.51769256591797, 'logps/rejected': -253.55209350585938, 'logps/chosen': -66.26922607421875, 'logits/rejected': -1.2423017024993896, 'logits/chosen': -1.2445887327194214, 'epoch': 1.42}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 106/222 [1:02:42<1:08:45, 35.57s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 107/222 [1:03:17<1:08:10, 35.57s/it]                                                     {'loss': 0.0032, 'grad_norm': 0.005646257661283016, 'learning_rate': 0.00015848625737756886, 'rewards/chosen': 0.35426005721092224, 'rewards/rejected': -18.601688385009766, 'rewards/accuracies': 1.0, 'rewards/margins': 18.95594596862793, 'logps/rejected': -295.6007385253906, 'logps/chosen': -56.39006042480469, 'logits/rejected': -1.277343511581421, 'logits/chosen': -1.2013758420944214, 'epoch': 1.43}
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 107/222 [1:03:17<1:08:10, 35.57s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 108/222 [1:03:53<1:07:58, 35.77s/it]                                                     {'loss': 0.0009, 'grad_norm': 0.002193939406424761, 'learning_rate': 0.00015636618047942222, 'rewards/chosen': 0.430747389793396, 'rewards/rejected': -17.358448028564453, 'rewards/accuracies': 1.0, 'rewards/margins': 17.789194107055664, 'logps/rejected': -267.0965576171875, 'logps/chosen': -55.38279342651367, 'logits/rejected': -1.2840954065322876, 'logits/chosen': -1.2464128732681274, 'epoch': 1.44}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 108/222 [1:03:53<1:07:58, 35.77s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 109/222 [1:04:29<1:07:22, 35.77s/it]                                                     {'loss': 0.0019, 'grad_norm': 0.0048096319660544395, 'learning_rate': 0.00015424482871246773, 'rewards/chosen': 0.5325454473495483, 'rewards/rejected': -17.529884338378906, 'rewards/accuracies': 1.0, 'rewards/margins': 18.062427520751953, 'logps/rejected': -283.9765625, 'logps/chosen': -64.62454986572266, 'logits/rejected': -1.2866473197937012, 'logits/chosen': -1.3002173900604248, 'epoch': 1.46}
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 109/222 [1:04:29<1:07:22, 35.77s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 110/222 [1:05:05<1:06:50, 35.81s/it]                                                     {'loss': 0.0018, 'grad_norm': 0.006414702162146568, 'learning_rate': 0.00015212262689111433, 'rewards/chosen': 0.49429216980934143, 'rewards/rejected': -16.20535659790039, 'rewards/accuracies': 1.0, 'rewards/margins': 16.699649810791016, 'logps/rejected': -269.3929443359375, 'logps/chosen': -57.86503982543945, 'logits/rejected': -1.2485551834106445, 'logits/chosen': -1.1764432191848755, 'epoch': 1.47}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 110/222 [1:05:05<1:06:50, 35.81s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 111/222 [1:05:41<1:06:15, 35.81s/it]                                                     {'loss': 0.0034, 'grad_norm': 0.00597042590379715, 'learning_rate': 0.00015, 'rewards/chosen': 0.6459270715713501, 'rewards/rejected': -15.78515338897705, 'rewards/accuracies': 1.0, 'rewards/margins': 16.431079864501953, 'logps/rejected': -249.78472900390625, 'logps/chosen': -75.02664184570312, 'logits/rejected': -1.2482668161392212, 'logits/chosen': -1.2883950471878052, 'epoch': 1.48}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 111/222 [1:05:41<1:06:15, 35.81s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 112/222 [1:06:18<1:06:19, 36.17s/it]                                                     {'loss': 0.0029, 'grad_norm': 0.006224710028618574, 'learning_rate': 0.0001478773731088857, 'rewards/chosen': 0.45622390508651733, 'rewards/rejected': -18.393522262573242, 'rewards/accuracies': 1.0, 'rewards/margins': 18.849746704101562, 'logps/rejected': -286.2903747558594, 'logps/chosen': -59.87939453125, 'logits/rejected': -1.3220250606536865, 'logits/chosen': -1.2321282625198364, 'epoch': 1.5}
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 112/222 [1:06:18<1:06:19, 36.17s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 113/222 [1:06:53<1:05:17, 35.94s/it]                                                     {'loss': 0.0014, 'grad_norm': 0.004002653062343597, 'learning_rate': 0.00014575517128753227, 'rewards/chosen': 0.5999374389648438, 'rewards/rejected': -18.005578994750977, 'rewards/accuracies': 1.0, 'rewards/margins': 18.60551643371582, 'logps/rejected': -290.7713623046875, 'logps/chosen': -61.18126678466797, 'logits/rejected': -1.3198693990707397, 'logits/chosen': -1.2571784257888794, 'epoch': 1.51}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 113/222 [1:06:53<1:05:17, 35.94s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 114/222 [1:07:29<1:04:20, 35.74s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.0011165996547788382, 'learning_rate': 0.00014363381952057778, 'rewards/chosen': 1.0516611337661743, 'rewards/rejected': -16.807754516601562, 'rewards/accuracies': 1.0, 'rewards/margins': 17.85941505432129, 'logps/rejected': -274.9407958984375, 'logps/chosen': -58.471282958984375, 'logits/rejected': -1.292527198791504, 'logits/chosen': -1.2519636154174805, 'epoch': 1.52}
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 114/222 [1:07:29<1:04:20, 35.74s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 115/222 [1:08:05<1:04:07, 35.96s/it]                                                     {'loss': 0.0011, 'grad_norm': 0.0033460103441029787, 'learning_rate': 0.00014151374262243112, 'rewards/chosen': 0.670278787612915, 'rewards/rejected': -17.28520393371582, 'rewards/accuracies': 1.0, 'rewards/margins': 17.955482482910156, 'logps/rejected': -276.1820983886719, 'logps/chosen': -71.48666381835938, 'logits/rejected': -1.3662551641464233, 'logits/chosen': -1.3112376928329468, 'epoch': 1.54}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 115/222 [1:08:05<1:04:07, 35.96s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 116/222 [1:08:40<1:03:16, 35.82s/it]                                                     {'loss': 0.0012, 'grad_norm': 0.004063531756401062, 'learning_rate': 0.0001393953651522008, 'rewards/chosen': 0.5670101046562195, 'rewards/rejected': -16.710119247436523, 'rewards/accuracies': 1.0, 'rewards/margins': 17.277130126953125, 'logps/rejected': -270.114501953125, 'logps/chosen': -68.82916259765625, 'logits/rejected': -1.3355863094329834, 'logits/chosen': -1.310744047164917, 'epoch': 1.55}
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 116/222 [1:08:40<1:03:16, 35.82s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 117/222 [1:09:16<1:02:39, 35.80s/it]                                                     {'loss': 0.0009, 'grad_norm': 0.00328259589150548, 'learning_rate': 0.00013727911132867365, 'rewards/chosen': 0.8418036699295044, 'rewards/rejected': -16.273216247558594, 'rewards/accuracies': 1.0, 'rewards/margins': 17.115022659301758, 'logps/rejected': -257.3507080078125, 'logps/chosen': -71.65863037109375, 'logits/rejected': -1.2343817949295044, 'logits/chosen': -1.2271589040756226, 'epoch': 1.56}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 117/222 [1:09:16<1:02:39, 35.80s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 118/222 [1:09:52<1:01:48, 35.66s/it]                                                     {'loss': 0.0013, 'grad_norm': 0.004858415573835373, 'learning_rate': 0.00013516540494536253, 'rewards/chosen': 0.6055611371994019, 'rewards/rejected': -16.447288513183594, 'rewards/accuracies': 1.0, 'rewards/margins': 17.05284881591797, 'logps/rejected': -260.6920471191406, 'logps/chosen': -56.87680435180664, 'logits/rejected': -1.2887463569641113, 'logits/chosen': -1.2181367874145508, 'epoch': 1.58}
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 118/222 [1:09:52<1:01:48, 35.66s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 119/222 [1:10:28<1:01:33, 35.86s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.0013135862536728382, 'learning_rate': 0.00013305466928563908, 'rewards/chosen': 0.6536718606948853, 'rewards/rejected': -17.72489356994629, 'rewards/accuracies': 1.0, 'rewards/margins': 18.37856674194336, 'logps/rejected': -272.285888671875, 'logps/chosen': -57.44248962402344, 'logits/rejected': -1.2624115943908691, 'logits/chosen': -1.2713005542755127, 'epoch': 1.59}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 119/222 [1:10:28<1:01:33, 35.86s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 120/222 [1:11:03<1:00:46, 35.75s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.0011805581161752343, 'learning_rate': 0.00013094732703796818, 'rewards/chosen': 0.6370400190353394, 'rewards/rejected': -17.468713760375977, 'rewards/accuracies': 1.0, 'rewards/margins': 18.105754852294922, 'logps/rejected': -274.5043029785156, 'logps/chosen': -70.15916442871094, 'logits/rejected': -1.2804605960845947, 'logits/chosen': -1.2253384590148926, 'epoch': 1.6}
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 120/222 [1:11:03<1:00:46, 35.75s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 121/222 [1:11:38<59:43, 35.48s/it]                                                     {'loss': 0.0026, 'grad_norm': 0.005448781419545412, 'learning_rate': 0.00012884380021126212, 'rewards/chosen': 0.709047794342041, 'rewards/rejected': -17.818437576293945, 'rewards/accuracies': 1.0, 'rewards/margins': 18.527484893798828, 'logps/rejected': -273.91729736328125, 'logps/chosen': -61.84339141845703, 'logits/rejected': -1.330977439880371, 'logits/chosen': -1.273823857307434, 'epoch': 1.62}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 121/222 [1:11:38<59:43, 35.48s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 122/222 [1:12:14<59:08, 35.49s/it]                                                   {'loss': 0.0027, 'grad_norm': 0.006185678765177727, 'learning_rate': 0.0001267445100503703, 'rewards/chosen': 0.4607919156551361, 'rewards/rejected': -17.20888328552246, 'rewards/accuracies': 1.0, 'rewards/margins': 17.669675827026367, 'logps/rejected': -261.09051513671875, 'logps/chosen': -62.57331466674805, 'logits/rejected': -1.2634564638137817, 'logits/chosen': -1.2505321502685547, 'epoch': 1.63}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 122/222 [1:12:14<59:08, 35.49s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 123/222 [1:12:49<58:30, 35.46s/it]                                                   {'loss': 0.0006, 'grad_norm': 0.00155309506226331, 'learning_rate': 0.00012464987695172264, 'rewards/chosen': 0.3684421479701996, 'rewards/rejected': -19.030967712402344, 'rewards/accuracies': 1.0, 'rewards/margins': 19.399410247802734, 'logps/rejected': -291.02587890625, 'logps/chosen': -54.70635223388672, 'logits/rejected': -1.3139158487319946, 'logits/chosen': -1.2183958292007446, 'epoch': 1.64}
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 123/222 [1:12:49<58:30, 35.46s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 124/222 [1:13:25<57:55, 35.47s/it]                                                   {'loss': 0.0029, 'grad_norm': 0.007978135719895363, 'learning_rate': 0.000122560320379142, 'rewards/chosen': 0.5417106747627258, 'rewards/rejected': -16.983604431152344, 'rewards/accuracies': 1.0, 'rewards/margins': 17.52531623840332, 'logps/rejected': -275.9549560546875, 'logps/chosen': -75.07006072998047, 'logits/rejected': -1.3119187355041504, 'logits/chosen': -1.2875064611434937, 'epoch': 1.66}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 124/222 [1:13:25<57:55, 35.47s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 125/222 [1:14:00<57:16, 35.43s/it]                                                   {'loss': 0.0009, 'grad_norm': 0.003390395315364003, 'learning_rate': 0.00012047625877984418, 'rewards/chosen': 0.5232585072517395, 'rewards/rejected': -17.974069595336914, 'rewards/accuracies': 1.0, 'rewards/margins': 18.49732780456543, 'logps/rejected': -271.7110900878906, 'logps/chosen': -71.62164306640625, 'logits/rejected': -1.2217862606048584, 'logits/chosen': -1.2791744470596313, 'epoch': 1.67}
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 125/222 [1:14:00<57:16, 35.43s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 126/222 [1:14:35<56:42, 35.44s/it]                                                   {'loss': 0.0024, 'grad_norm': 0.006093898788094521, 'learning_rate': 0.00011839810950064109, 'rewards/chosen': 0.5300067663192749, 'rewards/rejected': -18.364301681518555, 'rewards/accuracies': 1.0, 'rewards/margins': 18.89430809020996, 'logps/rejected': -281.9561462402344, 'logps/chosen': -57.81473159790039, 'logits/rejected': -1.3224546909332275, 'logits/chosen': -1.1936039924621582, 'epoch': 1.68}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 126/222 [1:14:35<56:42, 35.44s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 127/222 [1:15:11<56:17, 35.55s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.0017471864121034741, 'learning_rate': 0.0001163262887043641, 'rewards/chosen': 1.0112007856369019, 'rewards/rejected': -16.410606384277344, 'rewards/accuracies': 1.0, 'rewards/margins': 17.42180824279785, 'logps/rejected': -251.88888549804688, 'logps/chosen': -58.37273025512695, 'logits/rejected': -1.252419352531433, 'logits/chosen': -1.2743843793869019, 'epoch': 1.7}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 127/222 [1:15:11<56:17, 35.55s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 128/222 [1:15:47<55:38, 35.51s/it]                                                   {'loss': 0.0011, 'grad_norm': 0.0026293254923075438, 'learning_rate': 0.00011426121128652526, 'rewards/chosen': 0.4691668748855591, 'rewards/rejected': -16.604076385498047, 'rewards/accuracies': 1.0, 'rewards/margins': 17.073244094848633, 'logps/rejected': -253.04722595214844, 'logps/chosen': -69.73807525634766, 'logits/rejected': -1.2211012840270996, 'logits/chosen': -1.2504993677139282, 'epoch': 1.71}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 128/222 [1:15:47<55:38, 35.51s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 129/222 [1:16:22<55:04, 35.53s/it]                                                   {'loss': 0.0036, 'grad_norm': 0.0079782260581851, 'learning_rate': 0.00011220329079223123, 'rewards/chosen': 0.7064588069915771, 'rewards/rejected': -18.678312301635742, 'rewards/accuracies': 1.0, 'rewards/margins': 19.3847713470459, 'logps/rejected': -291.150390625, 'logps/chosen': -59.942718505859375, 'logits/rejected': -1.2431583404541016, 'logits/chosen': -1.245939016342163, 'epoch': 1.72}
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 129/222 [1:16:22<55:04, 35.53s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 130/222 [1:16:57<54:17, 35.40s/it]                                                   {'loss': 0.0007, 'grad_norm': 0.001921801595017314, 'learning_rate': 0.00011015293933336857, 'rewards/chosen': 0.45356136560440063, 'rewards/rejected': -17.35018539428711, 'rewards/accuracies': 1.0, 'rewards/margins': 17.80374526977539, 'logps/rejected': -267.3450927734375, 'logps/chosen': -60.461341857910156, 'logits/rejected': -1.2952847480773926, 'logits/chosen': -1.2443376779556274, 'epoch': 1.74}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 130/222 [1:16:57<54:17, 35.40s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 131/222 [1:17:33<53:38, 35.37s/it]                                                   {'loss': 0.0007, 'grad_norm': 0.0016576612833887339, 'learning_rate': 0.00010811056750607549, 'rewards/chosen': 0.5044529438018799, 'rewards/rejected': -17.76372528076172, 'rewards/accuracies': 1.0, 'rewards/margins': 18.268177032470703, 'logps/rejected': -279.91864013671875, 'logps/chosen': -50.06349563598633, 'logits/rejected': -1.2894402742385864, 'logits/chosen': -1.1955227851867676, 'epoch': 1.75}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 131/222 [1:17:33<53:38, 35.37s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 132/222 [1:18:08<53:04, 35.39s/it]                                                   {'loss': 0.0022, 'grad_norm': 0.005712238140404224, 'learning_rate': 0.00010607658430851744, 'rewards/chosen': 0.7492535710334778, 'rewards/rejected': -17.285446166992188, 'rewards/accuracies': 1.0, 'rewards/margins': 18.034700393676758, 'logps/rejected': -284.85369873046875, 'logps/chosen': -61.99318313598633, 'logits/rejected': -1.2571568489074707, 'logits/chosen': -1.2622300386428833, 'epoch': 1.76}
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 132/222 [1:18:08<53:04, 35.39s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 133/222 [1:18:43<52:21, 35.30s/it]                                                   {'loss': 0.0033, 'grad_norm': 0.007115793880075216, 'learning_rate': 0.00010405139705898249, 'rewards/chosen': 0.3692995309829712, 'rewards/rejected': -17.269744873046875, 'rewards/accuracies': 1.0, 'rewards/margins': 17.63904571533203, 'logps/rejected': -275.1270751953125, 'logps/chosen': -57.00882339477539, 'logits/rejected': -1.24845552444458, 'logits/chosen': -1.1953811645507812, 'epoch': 1.78}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 133/222 [1:18:43<52:21, 35.30s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 134/222 [1:19:19<51:52, 35.36s/it]                                                   {'loss': 0.0006, 'grad_norm': 0.0019278385443612933, 'learning_rate': 0.0001020354113143132, 'rewards/chosen': 0.3477039337158203, 'rewards/rejected': -20.015241622924805, 'rewards/accuracies': 1.0, 'rewards/margins': 20.362947463989258, 'logps/rejected': -308.2232666015625, 'logps/chosen': -64.11665344238281, 'logits/rejected': -1.2553445100784302, 'logits/chosen': -1.2516794204711914, 'epoch': 1.79}
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 134/222 [1:19:19<51:52, 35.36s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 135/222 [1:19:54<51:22, 35.43s/it]                                                   {'loss': 0.0056, 'grad_norm': 0.015016177669167519, 'learning_rate': 0.00010002903078869135, 'rewards/chosen': 0.44828155636787415, 'rewards/rejected': -19.276479721069336, 'rewards/accuracies': 1.0, 'rewards/margins': 19.724761962890625, 'logps/rejected': -292.2929992675781, 'logps/chosen': -57.19260025024414, 'logits/rejected': -1.2531675100326538, 'logits/chosen': -1.2259840965270996, 'epoch': 1.8}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 135/222 [1:19:54<51:22, 35.43s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 136/222 [1:20:30<50:53, 35.50s/it]                                                   {'loss': 0.001, 'grad_norm': 0.0023424976971000433, 'learning_rate': 9.803265727279149e-05, 'rewards/chosen': 0.5545825958251953, 'rewards/rejected': -16.804279327392578, 'rewards/accuracies': 1.0, 'rewards/margins': 17.358863830566406, 'logps/rejected': -262.8597717285156, 'logps/chosen': -78.5423812866211, 'logits/rejected': -1.3414580821990967, 'logits/chosen': -1.23746657371521, 'epoch': 1.82}
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 136/222 [1:20:30<50:53, 35.50s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 137/222 [1:21:05<50:14, 35.46s/it]                                                   {'loss': 0.0004, 'grad_norm': 0.0015885847387835383, 'learning_rate': 9.604669055331963e-05, 'rewards/chosen': 0.49278751015663147, 'rewards/rejected': -16.161888122558594, 'rewards/accuracies': 1.0, 'rewards/margins': 16.654674530029297, 'logps/rejected': -246.10702514648438, 'logps/chosen': -64.52500915527344, 'logits/rejected': -1.313828945159912, 'logits/chosen': -1.311983585357666, 'epoch': 1.83}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 137/222 [1:21:05<50:14, 35.46s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 138/222 [1:21:41<49:36, 35.44s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.002017402555793524, 'learning_rate': 9.407152833295372e-05, 'rewards/chosen': 0.5840561389923096, 'rewards/rejected': -19.42637062072754, 'rewards/accuracies': 1.0, 'rewards/margins': 20.01042938232422, 'logps/rejected': -291.9632568359375, 'logps/chosen': -64.8446273803711, 'logits/rejected': -1.2608425617218018, 'logits/chosen': -1.2973575592041016, 'epoch': 1.84}
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 138/222 [1:21:41<49:36, 35.44s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 139/222 [1:22:16<49:05, 35.49s/it]                                                   {'loss': 0.0041, 'grad_norm': 0.014840221032500267, 'learning_rate': 9.210756615070065e-05, 'rewards/chosen': 0.34623152017593384, 'rewards/rejected': -16.895526885986328, 'rewards/accuracies': 1.0, 'rewards/margins': 17.241758346557617, 'logps/rejected': -264.84228515625, 'logps/chosen': -66.55873107910156, 'logits/rejected': -1.3032537698745728, 'logits/chosen': -1.2818028926849365, 'epoch': 1.86}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 139/222 [1:22:16<49:05, 35.49s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 140/222 [1:22:52<48:33, 35.53s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.0009387698373757303, 'learning_rate': 9.015519730268754e-05, 'rewards/chosen': 0.33454787731170654, 'rewards/rejected': -19.52338409423828, 'rewards/accuracies': 1.0, 'rewards/margins': 19.85793113708496, 'logps/rejected': -307.6835632324219, 'logps/chosen': -57.104515075683594, 'logits/rejected': -1.2840609550476074, 'logits/chosen': -1.213627576828003, 'epoch': 1.87}
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 140/222 [1:22:52<48:33, 35.53s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 141/222 [1:23:27<47:48, 35.41s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.0009288506698794663, 'learning_rate': 8.821481276340112e-05, 'rewards/chosen': 0.5792145729064941, 'rewards/rejected': -18.009586334228516, 'rewards/accuracies': 1.0, 'rewards/margins': 18.588802337646484, 'logps/rejected': -291.9131164550781, 'logps/chosen': -66.24674224853516, 'logits/rejected': -1.2739531993865967, 'logits/chosen': -1.258432149887085, 'epoch': 1.88}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 141/222 [1:23:27<47:48, 35.41s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 142/222 [1:24:03<47:14, 35.43s/it]                                                   {'loss': 0.0034, 'grad_norm': 0.013766700401902199, 'learning_rate': 8.62868011073928e-05, 'rewards/chosen': 0.3514094352722168, 'rewards/rejected': -18.371028900146484, 'rewards/accuracies': 1.0, 'rewards/margins': 18.72243881225586, 'logps/rejected': -277.1500244140625, 'logps/chosen': -67.3144760131836, 'logits/rejected': -1.2083461284637451, 'logits/chosen': -1.2635772228240967, 'epoch': 1.9}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 142/222 [1:24:03<47:14, 35.43s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 143/222 [1:24:39<46:52, 35.60s/it]                                                   {'loss': 0.0023, 'grad_norm': 0.009886455722153187, 'learning_rate': 8.437154843146441e-05, 'rewards/chosen': 0.5467904210090637, 'rewards/rejected': -17.862796783447266, 'rewards/accuracies': 1.0, 'rewards/margins': 18.40958595275879, 'logps/rejected': -283.4307861328125, 'logps/chosen': -82.92930603027344, 'logits/rejected': -1.2289612293243408, 'logits/chosen': -1.2613974809646606, 'epoch': 1.91}
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 143/222 [1:24:39<46:52, 35.60s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 144/222 [1:25:14<46:14, 35.57s/it]                                                   {'loss': 0.0014, 'grad_norm': 0.00346467737108469, 'learning_rate': 8.246943827734897e-05, 'rewards/chosen': 0.3355754315853119, 'rewards/rejected': -19.099987030029297, 'rewards/accuracies': 1.0, 'rewards/margins': 19.43556022644043, 'logps/rejected': -273.53668212890625, 'logps/chosen': -55.94605255126953, 'logits/rejected': -1.28135085105896, 'logits/chosen': -1.2962157726287842, 'epoch': 1.92}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 144/222 [1:25:14<46:14, 35.57s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 145/222 [1:25:49<45:36, 35.54s/it]                                                   {'loss': 0.0006, 'grad_norm': 0.002366832224652171, 'learning_rate': 8.058085155490518e-05, 'rewards/chosen': 0.5262181758880615, 'rewards/rejected': -19.296730041503906, 'rewards/accuracies': 1.0, 'rewards/margins': 19.822948455810547, 'logps/rejected': -302.41943359375, 'logps/chosen': -73.12506103515625, 'logits/rejected': -1.296574592590332, 'logits/chosen': -1.2165422439575195, 'epoch': 1.94}
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 145/222 [1:25:50<45:36, 35.54s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 146/222 [1:26:25<44:49, 35.39s/it]                                                   {'loss': 0.0007, 'grad_norm': 0.0013907060492783785, 'learning_rate': 7.870616646583648e-05, 'rewards/chosen': 0.466422438621521, 'rewards/rejected': -18.225250244140625, 'rewards/accuracies': 1.0, 'rewards/margins': 18.69167137145996, 'logps/rejected': -272.9405517578125, 'logps/chosen': -72.18628692626953, 'logits/rejected': -1.315398097038269, 'logits/chosen': -1.3251184225082397, 'epoch': 1.95}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 146/222 [1:26:25<44:49, 35.39s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 147/222 [1:27:00<44:13, 35.38s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.0009509490337222815, 'learning_rate': 7.684575842795485e-05, 'rewards/chosen': 0.5181828737258911, 'rewards/rejected': -18.658098220825195, 'rewards/accuracies': 1.0, 'rewards/margins': 19.176279067993164, 'logps/rejected': -300.1765441894531, 'logps/chosen': -68.08263397216797, 'logits/rejected': -1.2836666107177734, 'logits/chosen': -1.269264817237854, 'epoch': 1.96}
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 147/222 [1:27:00<44:13, 35.38s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 148/222 [1:27:35<43:36, 35.35s/it]                                                   {'loss': 0.0038, 'grad_norm': 0.007500604726374149, 'learning_rate': 7.500000000000002e-05, 'rewards/chosen': 0.6942915320396423, 'rewards/rejected': -18.01593780517578, 'rewards/accuracies': 1.0, 'rewards/margins': 18.710227966308594, 'logps/rejected': -287.7427062988281, 'logps/chosen': -58.04265594482422, 'logits/rejected': -1.3202519416809082, 'logits/chosen': -1.2502086162567139, 'epoch': 1.98}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 148/222 [1:27:35<43:36, 35.35s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 149/222 [1:28:11<43:01, 35.37s/it]                                                   {'loss': 0.0024, 'grad_norm': 0.004262105096131563, 'learning_rate': 7.316926080703287e-05, 'rewards/chosen': 0.5113682150840759, 'rewards/rejected': -17.638673782348633, 'rewards/accuracies': 1.0, 'rewards/margins': 18.150043487548828, 'logps/rejected': -256.22735595703125, 'logps/chosen': -60.60089111328125, 'logits/rejected': -1.2387332916259766, 'logits/chosen': -1.218135118484497, 'epoch': 1.99}
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 149/222 [1:28:11<43:01, 35.37s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 150/222 [1:28:46<42:31, 35.44s/it]                                                   {'loss': 0.0004, 'grad_norm': 0.0011123634176328778, 'learning_rate': 7.135390746641526e-05, 'rewards/chosen': 0.6308343410491943, 'rewards/rejected': -17.989225387573242, 'rewards/accuracies': 1.0, 'rewards/margins': 18.620058059692383, 'logps/rejected': -272.6824035644531, 'logps/chosen': -63.88936996459961, 'logits/rejected': -1.3273757696151733, 'logits/chosen': -1.264634370803833, 'epoch': 2.0}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 150/222 [1:28:46<42:31, 35.44s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 151/222 [1:29:21<41:46, 35.30s/it]                                                   {'loss': 0.0011, 'grad_norm': 0.004255386535078287, 'learning_rate': 6.955430351439263e-05, 'rewards/chosen': 0.5511664152145386, 'rewards/rejected': -18.101118087768555, 'rewards/accuracies': 1.0, 'rewards/margins': 18.652284622192383, 'logps/rejected': -274.1068420410156, 'logps/chosen': -47.89936828613281, 'logits/rejected': -1.3092924356460571, 'logits/chosen': -1.2153295278549194, 'epoch': 2.02}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 151/222 [1:29:21<41:46, 35.30s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 152/222 [1:29:56<41:09, 35.28s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.0007814408163540065, 'learning_rate': 6.777080933329354e-05, 'rewards/chosen': 0.553679883480072, 'rewards/rejected': -18.342897415161133, 'rewards/accuracies': 1.0, 'rewards/margins': 18.896575927734375, 'logps/rejected': -277.9855651855469, 'logps/chosen': -65.90499114990234, 'logits/rejected': -1.2709534168243408, 'logits/chosen': -1.2411305904388428, 'epoch': 2.03}
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 152/222 [1:29:56<41:09, 35.28s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 153/222 [1:30:32<40:38, 35.34s/it]                                                   {'loss': 0.0004, 'grad_norm': 0.00127777352463454, 'learning_rate': 6.600378207936069e-05, 'rewards/chosen': 0.481277734041214, 'rewards/rejected': -16.227401733398438, 'rewards/accuracies': 1.0, 'rewards/margins': 16.70867919921875, 'logps/rejected': -239.97418212890625, 'logps/chosen': -66.75711822509766, 'logits/rejected': -1.2646183967590332, 'logits/chosen': -1.284387230873108, 'epoch': 2.04}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 153/222 [1:30:32<40:38, 35.34s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 154/222 [1:31:07<40:02, 35.34s/it]                                                   {'loss': 0.0018, 'grad_norm': 0.004792413674294949, 'learning_rate': 6.425357561122819e-05, 'rewards/chosen': 0.4786617159843445, 'rewards/rejected': -18.453250885009766, 'rewards/accuracies': 1.0, 'rewards/margins': 18.93191146850586, 'logps/rejected': -286.06610107421875, 'logps/chosen': -78.5443115234375, 'logits/rejected': -1.2976751327514648, 'logits/chosen': -1.2559764385223389, 'epoch': 2.06}
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 154/222 [1:31:07<40:02, 35.34s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 155/222 [1:31:42<39:22, 35.27s/it]                                                   {'loss': 0.0013, 'grad_norm': 0.0035843178629875183, 'learning_rate': 6.2520540419059e-05, 'rewards/chosen': 0.7196546792984009, 'rewards/rejected': -18.053913116455078, 'rewards/accuracies': 1.0, 'rewards/margins': 18.773571014404297, 'logps/rejected': -277.9478454589844, 'logps/chosen': -60.481021881103516, 'logits/rejected': -1.3268924951553345, 'logits/chosen': -1.2652831077575684, 'epoch': 2.07}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 155/222 [1:31:42<39:22, 35.27s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 156/222 [1:32:18<38:52, 35.34s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.0014894907362759113, 'learning_rate': 6.080502355435701e-05, 'rewards/chosen': 0.2721576988697052, 'rewards/rejected': -20.64626121520996, 'rewards/accuracies': 1.0, 'rewards/margins': 20.918418884277344, 'logps/rejected': -302.5972900390625, 'logps/chosen': -57.45089340209961, 'logits/rejected': -1.236269474029541, 'logits/chosen': -1.2131102085113525, 'epoch': 2.08}
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 156/222 [1:32:18<38:52, 35.34s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 157/222 [1:32:53<38:15, 35.32s/it]                                                   {'loss': 0.0006, 'grad_norm': 0.0016260214615613222, 'learning_rate': 5.910736856046777e-05, 'rewards/chosen': 0.38810887932777405, 'rewards/rejected': -17.28297996520996, 'rewards/accuracies': 1.0, 'rewards/margins': 17.67108917236328, 'logps/rejected': -263.0232849121094, 'logps/chosen': -55.84623718261719, 'logits/rejected': -1.2803230285644531, 'logits/chosen': -1.2793309688568115, 'epoch': 2.1}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 157/222 [1:32:53<38:15, 35.32s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 158/222 [1:33:28<37:35, 35.24s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.0014932769117876887, 'learning_rate': 5.742791540378175e-05, 'rewards/chosen': 0.4195769429206848, 'rewards/rejected': -19.469497680664062, 'rewards/accuracies': 1.0, 'rewards/margins': 19.889076232910156, 'logps/rejected': -288.7603759765625, 'logps/chosen': -64.92636108398438, 'logits/rejected': -1.281531810760498, 'logits/chosen': -1.260676383972168, 'epoch': 2.11}
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 158/222 [1:33:28<37:35, 35.24s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 159/222 [1:34:04<37:07, 35.35s/it]                                                   {'loss': 0.0008, 'grad_norm': 0.0031459613237529993, 'learning_rate': 5.5767000405653636e-05, 'rewards/chosen': 0.47143685817718506, 'rewards/rejected': -17.268985748291016, 'rewards/accuracies': 1.0, 'rewards/margins': 17.74042320251465, 'logps/rejected': -260.0992126464844, 'logps/chosen': -62.2411003112793, 'logits/rejected': -1.2751655578613281, 'logits/chosen': -1.212235450744629, 'epoch': 2.12}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 159/222 [1:34:04<37:07, 35.35s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 160/222 [1:34:39<36:34, 35.40s/it]                                                   {'loss': 0.0008, 'grad_norm': 0.001564200734719634, 'learning_rate': 5.4124956175052295e-05, 'rewards/chosen': 0.3840603828430176, 'rewards/rejected': -19.82301902770996, 'rewards/accuracies': 1.0, 'rewards/margins': 20.207080841064453, 'logps/rejected': -308.09588623046875, 'logps/chosen': -51.245479583740234, 'logits/rejected': -1.2622076272964478, 'logits/chosen': -1.2185500860214233, 'epoch': 2.14}
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 160/222 [1:34:39<36:34, 35.40s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 161/222 [1:35:15<35:59, 35.40s/it]                                                   {'loss': 0.0015, 'grad_norm': 0.0029342209454625845, 'learning_rate': 5.250211154195298e-05, 'rewards/chosen': 0.517474889755249, 'rewards/rejected': -18.531740188598633, 'rewards/accuracies': 1.0, 'rewards/margins': 19.049217224121094, 'logps/rejected': -281.6805114746094, 'logps/chosen': -63.84607696533203, 'logits/rejected': -1.3272407054901123, 'logits/chosen': -1.2789286375045776, 'epoch': 2.15}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 161/222 [1:35:15<35:59, 35.40s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 162/222 [1:35:50<35:29, 35.49s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.0026736718136817217, 'learning_rate': 5.089879149148781e-05, 'rewards/chosen': 0.33168452978134155, 'rewards/rejected': -21.745084762573242, 'rewards/accuracies': 1.0, 'rewards/margins': 22.076770782470703, 'logps/rejected': -329.99176025390625, 'logps/chosen': -59.14874267578125, 'logits/rejected': -1.2894304990768433, 'logits/chosen': -1.2496181726455688, 'epoch': 2.16}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 162/222 [1:35:50<35:29, 35.49s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 163/222 [1:36:26<34:51, 35.46s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.0004318016581237316, 'learning_rate': 4.931531709886456e-05, 'rewards/chosen': 0.24632227420806885, 'rewards/rejected': -19.73467254638672, 'rewards/accuracies': 1.0, 'rewards/margins': 19.980993270874023, 'logps/rejected': -311.0997314453125, 'logps/chosen': -70.86653900146484, 'logits/rejected': -1.2938895225524902, 'logits/chosen': -1.2397315502166748, 'epoch': 2.18}
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 163/222 [1:36:26<34:51, 35.46s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 164/222 [1:37:01<34:21, 35.54s/it]                                                   {'loss': 0.0011, 'grad_norm': 0.0043416740372776985, 'learning_rate': 4.7752005465070094e-05, 'rewards/chosen': 0.6885795593261719, 'rewards/rejected': -18.492006301879883, 'rewards/accuracies': 1.0, 'rewards/margins': 19.180587768554688, 'logps/rejected': -282.452392578125, 'logps/chosen': -64.28630065917969, 'logits/rejected': -1.2502129077911377, 'logits/chosen': -1.2853407859802246, 'epoch': 2.19}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 164/222 [1:37:01<34:21, 35.54s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 165/222 [1:37:37<33:43, 35.50s/it]                                                   {'loss': 0.0007, 'grad_norm': 0.0021783229894936085, 'learning_rate': 4.6209169653368086e-05, 'rewards/chosen': 0.350395530462265, 'rewards/rejected': -19.666950225830078, 'rewards/accuracies': 1.0, 'rewards/margins': 20.01734733581543, 'logps/rejected': -297.7077941894531, 'logps/chosen': -64.0865478515625, 'logits/rejected': -1.3294143676757812, 'logits/chosen': -1.2546223402023315, 'epoch': 2.2}
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 165/222 [1:37:37<33:43, 35.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 166/222 [1:38:12<33:05, 35.45s/it]                                                   {'loss': 0.0032, 'grad_norm': 0.01245854515582323, 'learning_rate': 4.468711862660662e-05, 'rewards/chosen': 0.6990192532539368, 'rewards/rejected': -19.148765563964844, 'rewards/accuracies': 1.0, 'rewards/margins': 19.84778594970703, 'logps/rejected': -283.5901184082031, 'logps/chosen': -62.21072006225586, 'logits/rejected': -1.2690250873565674, 'logits/chosen': -1.2960132360458374, 'epoch': 2.22}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 166/222 [1:38:12<33:05, 35.45s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 167/222 [1:38:48<32:35, 35.55s/it]                                                   {'loss': 0.0012, 'grad_norm': 0.00363901793025434, 'learning_rate': 4.318615718534618e-05, 'rewards/chosen': 0.33375847339630127, 'rewards/rejected': -20.386669158935547, 'rewards/accuracies': 1.0, 'rewards/margins': 20.72042465209961, 'logps/rejected': -305.5983581542969, 'logps/chosen': -61.12098693847656, 'logits/rejected': -1.3129332065582275, 'logits/chosen': -1.2037068605422974, 'epoch': 2.23}
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 167/222 [1:38:48<32:35, 35.55s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 168/222 [1:39:23<31:58, 35.53s/it]                                                   {'loss': 0.0034, 'grad_norm': 0.006210186518728733, 'learning_rate': 4.1706585906821334e-05, 'rewards/chosen': 0.5623079538345337, 'rewards/rejected': -18.036827087402344, 'rewards/accuracies': 0.984375, 'rewards/margins': 18.599132537841797, 'logps/rejected': -275.83660888671875, 'logps/chosen': -78.73445129394531, 'logits/rejected': -1.2837984561920166, 'logits/chosen': -1.2946051359176636, 'epoch': 2.24}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 168/222 [1:39:23<31:58, 35.53s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 169/222 [1:39:59<31:20, 35.49s/it]                                                   {'loss': 0.001, 'grad_norm': 0.0026536935474723577, 'learning_rate': 4.024870108474825e-05, 'rewards/chosen': 0.8158388137817383, 'rewards/rejected': -19.03591537475586, 'rewards/accuracies': 1.0, 'rewards/margins': 19.85175323486328, 'logps/rejected': -289.22015380859375, 'logps/chosen': -70.04779052734375, 'logits/rejected': -1.2738827466964722, 'logits/chosen': -1.2828681468963623, 'epoch': 2.26}
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 169/222 [1:39:59<31:20, 35.49s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 170/222 [1:40:34<30:45, 35.50s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.0017354200826957822, 'learning_rate': 3.881279466999001e-05, 'rewards/chosen': 0.38175085186958313, 'rewards/rejected': -18.216943740844727, 'rewards/accuracies': 1.0, 'rewards/margins': 18.598691940307617, 'logps/rejected': -275.110595703125, 'logps/chosen': -64.61896514892578, 'logits/rejected': -1.2700170278549194, 'logits/chosen': -1.191876769065857, 'epoch': 2.27}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 170/222 [1:40:34<30:45, 35.50s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 171/222 [1:41:10<30:11, 35.52s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.0005955276428721845, 'learning_rate': 3.739915421209133e-05, 'rewards/chosen': 0.32898929715156555, 'rewards/rejected': -18.311246871948242, 'rewards/accuracies': 1.0, 'rewards/margins': 18.640235900878906, 'logps/rejected': -280.13787841796875, 'logps/chosen': -59.095584869384766, 'logits/rejected': -1.281995415687561, 'logits/chosen': -1.1799170970916748, 'epoch': 2.28}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 171/222 [1:41:10<30:11, 35.52s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 172/222 [1:41:46<29:38, 35.57s/it]                                                   {'loss': 0.0023, 'grad_norm': 0.005863195285201073, 'learning_rate': 3.600806280169541e-05, 'rewards/chosen': 0.4458495080471039, 'rewards/rejected': -20.58091163635254, 'rewards/accuracies': 1.0, 'rewards/margins': 21.026762008666992, 'logps/rejected': -312.5713195800781, 'logps/chosen': -68.73242950439453, 'logits/rejected': -1.3091990947723389, 'logits/chosen': -1.2611161470413208, 'epoch': 2.3}
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 172/222 [1:41:46<29:38, 35.57s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 173/222 [1:42:21<29:02, 35.57s/it]                                                   {'loss': 0.0029, 'grad_norm': 0.005403770133852959, 'learning_rate': 3.463979901385247e-05, 'rewards/chosen': 0.5332253575325012, 'rewards/rejected': -17.03293228149414, 'rewards/accuracies': 1.0, 'rewards/margins': 17.5661563873291, 'logps/rejected': -258.35919189453125, 'logps/chosen': -66.77356719970703, 'logits/rejected': -1.2530182600021362, 'logits/chosen': -1.3002395629882812, 'epoch': 2.31}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 173/222 [1:42:21<29:02, 35.57s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 174/222 [1:42:57<28:23, 35.48s/it]                                                   {'loss': 0.0008, 'grad_norm': 0.0031949265394359827, 'learning_rate': 3.3294636852234105e-05, 'rewards/chosen': 0.5125150680541992, 'rewards/rejected': -18.840726852416992, 'rewards/accuracies': 1.0, 'rewards/margins': 19.353242874145508, 'logps/rejected': -294.56463623046875, 'logps/chosen': -62.622802734375, 'logits/rejected': -1.266115665435791, 'logits/chosen': -1.271746039390564, 'epoch': 2.32}
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 174/222 [1:42:57<28:23, 35.48s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 175/222 [1:43:32<27:51, 35.55s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.0013364398619160056, 'learning_rate': 3.197284569426147e-05, 'rewards/chosen': 0.5813338160514832, 'rewards/rejected': -17.809465408325195, 'rewards/accuracies': 1.0, 'rewards/margins': 18.390796661376953, 'logps/rejected': -266.5994567871094, 'logps/chosen': -64.68946075439453, 'logits/rejected': -1.2680690288543701, 'logits/chosen': -1.2740052938461304, 'epoch': 2.34}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 175/222 [1:43:32<27:51, 35.55s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 176/222 [1:44:07<27:07, 35.38s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.0022296207025647163, 'learning_rate': 3.067469023716154e-05, 'rewards/chosen': 0.5305495262145996, 'rewards/rejected': -20.106407165527344, 'rewards/accuracies': 1.0, 'rewards/margins': 20.6369571685791, 'logps/rejected': -301.18170166015625, 'logps/chosen': -55.200294494628906, 'logits/rejected': -1.316359519958496, 'logits/chosen': -1.2621597051620483, 'epoch': 2.35}
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 176/222 [1:44:07<27:07, 35.38s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 177/222 [1:44:43<26:32, 35.38s/it]                                                   {'loss': 0.0037, 'grad_norm': 0.00956817902624607, 'learning_rate': 2.9400430444958932e-05, 'rewards/chosen': 0.8570091128349304, 'rewards/rejected': -16.70206642150879, 'rewards/accuracies': 1.0, 'rewards/margins': 17.55907440185547, 'logps/rejected': -254.59576416015625, 'logps/chosen': -68.57386779785156, 'logits/rejected': -1.2708953619003296, 'logits/chosen': -1.2832999229431152, 'epoch': 2.36}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 177/222 [1:44:43<26:32, 35.38s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 178/222 [1:45:18<25:57, 35.41s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.001056912005878985, 'learning_rate': 2.8150321496417135e-05, 'rewards/chosen': 0.7266871333122253, 'rewards/rejected': -20.435287475585938, 'rewards/accuracies': 1.0, 'rewards/margins': 21.16197395324707, 'logps/rejected': -299.10308837890625, 'logps/chosen': -63.61531448364258, 'logits/rejected': -1.29094398021698, 'logits/chosen': -1.2526986598968506, 'epoch': 2.38}
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 178/222 [1:45:18<25:57, 35.41s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 179/222 [1:45:53<25:20, 35.35s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.0007845390937291086, 'learning_rate': 2.692461373393688e-05, 'rewards/chosen': 0.4956713616847992, 'rewards/rejected': -19.508512496948242, 'rewards/accuracies': 1.0, 'rewards/margins': 20.004182815551758, 'logps/rejected': -293.6392822265625, 'logps/chosen': -61.61576843261719, 'logits/rejected': -1.3387835025787354, 'logits/chosen': -1.2169965505599976, 'epoch': 2.39}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 179/222 [1:45:53<25:20, 35.35s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 180/222 [1:46:29<24:44, 35.34s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.0007384247146546841, 'learning_rate': 2.5723552613423687e-05, 'rewards/chosen': 0.29211899638175964, 'rewards/rejected': -18.486127853393555, 'rewards/accuracies': 1.0, 'rewards/margins': 18.778247833251953, 'logps/rejected': -279.194580078125, 'logps/chosen': -70.99018859863281, 'logits/rejected': -1.282973289489746, 'logits/chosen': -1.264662265777588, 'epoch': 2.4}
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 180/222 [1:46:29<24:44, 35.34s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 181/222 [1:47:04<24:13, 35.45s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.0005610487423837185, 'learning_rate': 2.4547378655133586e-05, 'rewards/chosen': 0.5193157196044922, 'rewards/rejected': -18.390979766845703, 'rewards/accuracies': 1.0, 'rewards/margins': 18.910297393798828, 'logps/rejected': -287.5804748535156, 'logps/chosen': -73.23202514648438, 'logits/rejected': -1.3148691654205322, 'logits/chosen': -1.243405818939209, 'epoch': 2.42}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 181/222 [1:47:04<24:13, 35.45s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 182/222 [1:47:40<23:35, 35.39s/it]                                                   {'loss': 0.0025, 'grad_norm': 0.0060616484843194485, 'learning_rate': 2.3396327395507448e-05, 'rewards/chosen': 0.4937279522418976, 'rewards/rejected': -19.99183464050293, 'rewards/accuracies': 1.0, 'rewards/margins': 20.48556137084961, 'logps/rejected': -310.11322021484375, 'logps/chosen': -62.965213775634766, 'logits/rejected': -1.240464687347412, 'logits/chosen': -1.2483752965927124, 'epoch': 2.43}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 182/222 [1:47:40<23:35, 35.39s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 183/222 [1:48:15<23:02, 35.44s/it]                                                   {'loss': 0.0004, 'grad_norm': 0.0012867104960605502, 'learning_rate': 2.2270629340003303e-05, 'rewards/chosen': 0.5674214363098145, 'rewards/rejected': -18.513671875, 'rewards/accuracies': 1.0, 'rewards/margins': 19.081092834472656, 'logps/rejected': -282.5898742675781, 'logps/chosen': -64.90855407714844, 'logits/rejected': -1.2038096189498901, 'logits/chosen': -1.2515056133270264, 'epoch': 2.44}
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 183/222 [1:48:15<23:02, 35.44s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 184/222 [1:48:51<22:28, 35.49s/it]                                                   {'loss': 0.001, 'grad_norm': 0.0038493676111102104, 'learning_rate': 2.117050991693609e-05, 'rewards/chosen': 0.3300665616989136, 'rewards/rejected': -19.790992736816406, 'rewards/accuracies': 1.0, 'rewards/margins': 20.12105941772461, 'logps/rejected': -299.2138366699219, 'logps/chosen': -55.90544128417969, 'logits/rejected': -1.2750203609466553, 'logits/chosen': -1.2665209770202637, 'epoch': 2.46}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 184/222 [1:48:51<22:28, 35.49s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 185/222 [1:49:26<21:52, 35.48s/it]                                                   {'loss': 0.0009, 'grad_norm': 0.0023147277534008026, 'learning_rate': 2.009618943233419e-05, 'rewards/chosen': 0.5576645731925964, 'rewards/rejected': -18.959579467773438, 'rewards/accuracies': 1.0, 'rewards/margins': 19.517244338989258, 'logps/rejected': -291.34661865234375, 'logps/chosen': -55.1597785949707, 'logits/rejected': -1.250842809677124, 'logits/chosen': -1.2269432544708252, 'epoch': 2.47}
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 185/222 [1:49:26<21:52, 35.48s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 186/222 [1:50:02<21:16, 35.45s/it]                                                   {'loss': 0.0007, 'grad_norm': 0.0017422343371436, 'learning_rate': 1.9047883025821774e-05, 'rewards/chosen': 0.41066521406173706, 'rewards/rejected': -19.55337142944336, 'rewards/accuracies': 1.0, 'rewards/margins': 19.964035034179688, 'logps/rejected': -301.4932861328125, 'logps/chosen': -55.19405746459961, 'logits/rejected': -1.3395581245422363, 'logits/chosen': -1.2566323280334473, 'epoch': 2.48}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 186/222 [1:50:02<21:16, 35.45s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 187/222 [1:50:37<20:43, 35.54s/it]                                                   {'loss': 0.0009, 'grad_norm': 0.0026105802971869707, 'learning_rate': 1.8025800627535614e-05, 'rewards/chosen': 0.2732992172241211, 'rewards/rejected': -19.44594955444336, 'rewards/accuracies': 1.0, 'rewards/margins': 19.719249725341797, 'logps/rejected': -304.48284912109375, 'logps/chosen': -62.07026672363281, 'logits/rejected': -1.279402494430542, 'logits/chosen': -1.1989428997039795, 'epoch': 2.5}
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 187/222 [1:50:37<20:43, 35.54s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 188/222 [1:51:13<20:07, 35.51s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.0004692913207691163, 'learning_rate': 1.7030146916085185e-05, 'rewards/chosen': 0.5158698558807373, 'rewards/rejected': -18.747840881347656, 'rewards/accuracies': 1.0, 'rewards/margins': 19.263708114624023, 'logps/rejected': -275.0948791503906, 'logps/chosen': -59.41424560546875, 'logits/rejected': -1.2855569124221802, 'logits/chosen': -1.2655104398727417, 'epoch': 2.51}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 188/222 [1:51:13<20:07, 35.51s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 189/222 [1:51:48<19:32, 35.54s/it]                                                   {'loss': 0.0006, 'grad_norm': 0.0017859898507595062, 'learning_rate': 1.6061121277564743e-05, 'rewards/chosen': 0.2788396179676056, 'rewards/rejected': -17.973485946655273, 'rewards/accuracies': 1.0, 'rewards/margins': 18.25232696533203, 'logps/rejected': -274.1277160644531, 'logps/chosen': -63.27330017089844, 'logits/rejected': -1.2578020095825195, 'logits/chosen': -1.2476880550384521, 'epoch': 2.52}
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 189/222 [1:51:48<19:32, 35.54s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 190/222 [1:52:24<18:54, 35.46s/it]                                                   {'loss': 0.0028, 'grad_norm': 0.007316045928746462, 'learning_rate': 1.5118917765624467e-05, 'rewards/chosen': 0.5062756538391113, 'rewards/rejected': -20.45062828063965, 'rewards/accuracies': 1.0, 'rewards/margins': 20.9569034576416, 'logps/rejected': -308.40380859375, 'logps/chosen': -57.90354537963867, 'logits/rejected': -1.2972643375396729, 'logits/chosen': -1.241255521774292, 'epoch': 2.54}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 190/222 [1:52:24<18:54, 35.46s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 191/222 [1:52:59<18:20, 35.50s/it]                                                   {'loss': 0.0006, 'grad_norm': 0.0013045254163444042, 'learning_rate': 1.4203725062610505e-05, 'rewards/chosen': 0.38609856367111206, 'rewards/rejected': -18.2868595123291, 'rewards/accuracies': 1.0, 'rewards/margins': 18.672956466674805, 'logps/rejected': -287.80706787109375, 'logps/chosen': -50.84180450439453, 'logits/rejected': -1.305246353149414, 'logits/chosen': -1.2118216753005981, 'epoch': 2.55}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 191/222 [1:52:59<18:20, 35.50s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 192/222 [1:53:34<17:43, 35.44s/it]                                                   {'loss': 0.0006, 'grad_norm': 0.0018264082027599216, 'learning_rate': 1.3315726441779629e-05, 'rewards/chosen': 0.43834248185157776, 'rewards/rejected': -20.036169052124023, 'rewards/accuracies': 1.0, 'rewards/margins': 20.474512100219727, 'logps/rejected': -311.58349609375, 'logps/chosen': -58.573753356933594, 'logits/rejected': -1.2818816900253296, 'logits/chosen': -1.2153311967849731, 'epoch': 2.56}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 192/222 [1:53:35<17:43, 35.44s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 193/222 [1:54:10<17:08, 35.47s/it]                                                   {'loss': 0.0008, 'grad_norm': 0.002533611375838518, 'learning_rate': 1.2455099730598005e-05, 'rewards/chosen': 0.5515769124031067, 'rewards/rejected': -19.46769142150879, 'rewards/accuracies': 1.0, 'rewards/margins': 20.019268035888672, 'logps/rejected': -288.0530700683594, 'logps/chosen': -69.42964935302734, 'logits/rejected': -1.2824466228485107, 'logits/chosen': -1.2046204805374146, 'epoch': 2.58}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 193/222 [1:54:10<17:08, 35.47s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 194/222 [1:54:46<16:33, 35.48s/it]                                                   {'loss': 0.0004, 'grad_norm': 0.0012859177077189088, 'learning_rate': 1.1622017275129708e-05, 'rewards/chosen': 0.5467998385429382, 'rewards/rejected': -19.05699920654297, 'rewards/accuracies': 1.0, 'rewards/margins': 19.60379981994629, 'logps/rejected': -305.96478271484375, 'logps/chosen': -61.69261932373047, 'logits/rejected': -1.2793411016464233, 'logits/chosen': -1.207069993019104, 'epoch': 2.59}
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 194/222 [1:54:46<16:33, 35.48s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 195/222 [1:55:21<15:56, 35.43s/it]                                                   {'loss': 0.0026, 'grad_norm': 0.005238017067313194, 'learning_rate': 1.0816645905523597e-05, 'rewards/chosen': 0.43447738885879517, 'rewards/rejected': -19.266067504882812, 'rewards/accuracies': 1.0, 'rewards/margins': 19.700544357299805, 'logps/rejected': -279.7586975097656, 'logps/chosen': -59.99468994140625, 'logits/rejected': -1.3064873218536377, 'logits/chosen': -1.2376644611358643, 'epoch': 2.6}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 195/222 [1:55:21<15:56, 35.43s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 196/222 [1:55:56<15:22, 35.47s/it]                                                   {'loss': 0.0028, 'grad_norm': 0.006151611916720867, 'learning_rate': 1.00391469026044e-05, 'rewards/chosen': 0.48235735297203064, 'rewards/rejected': -20.498334884643555, 'rewards/accuracies': 1.0, 'rewards/margins': 20.98069190979004, 'logps/rejected': -305.06317138671875, 'logps/chosen': -60.47684860229492, 'logits/rejected': -1.2978498935699463, 'logits/chosen': -1.2525155544281006, 'epoch': 2.62}
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 196/222 [1:55:56<15:22, 35.47s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 197/222 [1:56:32<14:48, 35.55s/it]                                                   {'loss': 0.0012, 'grad_norm': 0.0034269492607563734, 'learning_rate': 9.289675965575117e-06, 'rewards/chosen': 0.35674044489860535, 'rewards/rejected': -22.533552169799805, 'rewards/accuracies': 1.0, 'rewards/margins': 22.89029312133789, 'logps/rejected': -328.78619384765625, 'logps/chosen': -54.89773941040039, 'logits/rejected': -1.2592718601226807, 'logits/chosen': -1.2072457075119019, 'epoch': 2.63}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 197/222 [1:56:32<14:48, 35.55s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 198/222 [1:57:08<14:14, 35.59s/it]                                                   {'loss': 0.0004, 'grad_norm': 0.0018343073315918446, 'learning_rate': 8.568383180837368e-06, 'rewards/chosen': 0.5250213742256165, 'rewards/rejected': -19.25613021850586, 'rewards/accuracies': 1.0, 'rewards/margins': 19.781150817871094, 'logps/rejected': -297.7981262207031, 'logps/chosen': -60.59965515136719, 'logits/rejected': -1.2635366916656494, 'logits/chosen': -1.2069334983825684, 'epoch': 2.64}
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 198/222 [1:57:08<14:14, 35.59s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 199/222 [1:57:43<13:33, 35.36s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.0022160655353218317, 'learning_rate': 7.875412991935548e-06, 'rewards/chosen': 0.21111750602722168, 'rewards/rejected': -21.08309555053711, 'rewards/accuracies': 1.0, 'rewards/margins': 21.294212341308594, 'logps/rejected': -318.39288330078125, 'logps/chosen': -53.3408203125, 'logits/rejected': -1.3038729429244995, 'logits/chosen': -1.197522521018982, 'epoch': 2.66}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 199/222 [1:57:43<13:33, 35.36s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 200/222 [1:58:18<12:58, 35.39s/it]                                                   {'loss': 0.0006, 'grad_norm': 0.001515597221441567, 'learning_rate': 7.210904170631021e-06, 'rewards/chosen': 0.5049329400062561, 'rewards/rejected': -18.135974884033203, 'rewards/accuracies': 1.0, 'rewards/margins': 18.64090919494629, 'logps/rejected': -278.51019287109375, 'logps/chosen': -61.71760177612305, 'logits/rejected': -1.3019076585769653, 'logits/chosen': -1.3014028072357178, 'epoch': 2.67}
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 200/222 [1:58:18<12:58, 35.39s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 201/222 [1:58:54<12:24, 35.44s/it]                                                   {'loss': 0.0019, 'grad_norm': 0.0045970408245921135, 'learning_rate': 6.574989789112372e-06, 'rewards/chosen': 0.2851705253124237, 'rewards/rejected': -17.895891189575195, 'rewards/accuracies': 1.0, 'rewards/margins': 18.181062698364258, 'logps/rejected': -277.48406982421875, 'logps/chosen': -74.0704116821289, 'logits/rejected': -1.268296718597412, 'logits/chosen': -1.1869239807128906, 'epoch': 2.68}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 201/222 [1:58:54<12:24, 35.44s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 202/222 [1:59:29<11:49, 35.48s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.0004796322318725288, 'learning_rate': 5.967797193346574e-06, 'rewards/chosen': 0.482504665851593, 'rewards/rejected': -18.727745056152344, 'rewards/accuracies': 1.0, 'rewards/margins': 19.210250854492188, 'logps/rejected': -282.29180908203125, 'logps/chosen': -64.35041046142578, 'logits/rejected': -1.247595191001892, 'logits/chosen': -1.223820686340332, 'epoch': 2.7}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 202/222 [1:59:29<11:49, 35.48s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 203/222 [2:00:05<11:14, 35.47s/it]                                                   {'loss': 0.0018, 'grad_norm': 0.003930302802473307, 'learning_rate': 5.389447977577416e-06, 'rewards/chosen': 0.15730899572372437, 'rewards/rejected': -19.141050338745117, 'rewards/accuracies': 1.0, 'rewards/margins': 19.298358917236328, 'logps/rejected': -283.2182312011719, 'logps/chosen': -58.69325256347656, 'logits/rejected': -1.2921302318572998, 'logits/chosen': -1.2904167175292969, 'epoch': 2.71}
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 203/222 [2:00:05<11:14, 35.47s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 204/222 [2:00:40<10:37, 35.44s/it]                                                   {'loss': 0.0015, 'grad_norm': 0.004460285883396864, 'learning_rate': 4.840057959975169e-06, 'rewards/chosen': 0.35609230399131775, 'rewards/rejected': -20.017528533935547, 'rewards/accuracies': 1.0, 'rewards/margins': 20.373619079589844, 'logps/rejected': -281.017578125, 'logps/chosen': -56.05704879760742, 'logits/rejected': -1.3310809135437012, 'logits/chosen': -1.2891943454742432, 'epoch': 2.72}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 204/222 [2:00:40<10:37, 35.44s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 205/222 [2:01:16<10:03, 35.51s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.0011791038559749722, 'learning_rate': 4.31973715944357e-06, 'rewards/chosen': 0.5167474746704102, 'rewards/rejected': -16.850664138793945, 'rewards/accuracies': 1.0, 'rewards/margins': 17.36741065979004, 'logps/rejected': -266.76287841796875, 'logps/chosen': -74.70448303222656, 'logits/rejected': -1.3108000755310059, 'logits/chosen': -1.2813150882720947, 'epoch': 2.74}
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 205/222 [2:01:16<10:03, 35.51s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 206/222 [2:01:51<09:29, 35.57s/it]                                                   {'loss': 0.0012, 'grad_norm': 0.004044769797474146, 'learning_rate': 3.828589773587515e-06, 'rewards/chosen': 0.2537688612937927, 'rewards/rejected': -18.409290313720703, 'rewards/accuracies': 1.0, 'rewards/margins': 18.66305923461914, 'logps/rejected': -278.5644226074219, 'logps/chosen': -58.73876953125, 'logits/rejected': -1.3265098333358765, 'logits/chosen': -1.237889289855957, 'epoch': 2.75}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 206/222 [2:01:51<09:29, 35.57s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 207/222 [2:02:27<08:53, 35.58s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.0007687720935791731, 'learning_rate': 3.366714157847078e-06, 'rewards/chosen': 0.4858195185661316, 'rewards/rejected': -18.454267501831055, 'rewards/accuracies': 1.0, 'rewards/margins': 18.940088272094727, 'logps/rejected': -276.58380126953125, 'logps/chosen': -61.41865921020508, 'logits/rejected': -1.2306309938430786, 'logits/chosen': -1.2077491283416748, 'epoch': 2.76}
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 207/222 [2:02:27<08:53, 35.58s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 208/222 [2:03:02<08:14, 35.33s/it]                                                   {'loss': 0.0016, 'grad_norm': 0.0036024681758135557, 'learning_rate': 2.934202805800989e-06, 'rewards/chosen': 0.7573328614234924, 'rewards/rejected': -19.866140365600586, 'rewards/accuracies': 1.0, 'rewards/margins': 20.62347412109375, 'logps/rejected': -307.0595703125, 'logps/chosen': -54.44709396362305, 'logits/rejected': -1.2919279336929321, 'logits/chosen': -1.2563817501068115, 'epoch': 2.78}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 208/222 [2:03:02<08:14, 35.33s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 209/222 [2:03:38<07:40, 35.45s/it]                                                   {'loss': 0.0008, 'grad_norm': 0.003942291252315044, 'learning_rate': 2.5311423306443645e-06, 'rewards/chosen': 0.2841992676258087, 'rewards/rejected': -18.94479751586914, 'rewards/accuracies': 1.0, 'rewards/margins': 19.22899627685547, 'logps/rejected': -285.7711181640625, 'logps/chosen': -64.96326446533203, 'logits/rejected': -1.3146319389343262, 'logits/chosen': -1.2315905094146729, 'epoch': 2.79}
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 209/222 [2:03:38<07:40, 35.45s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 210/222 [2:04:13<07:04, 35.40s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.0007971920422278345, 'learning_rate': 2.1576134478437313e-06, 'rewards/chosen': 0.6164081692695618, 'rewards/rejected': -18.747325897216797, 'rewards/accuracies': 1.0, 'rewards/margins': 19.363733291625977, 'logps/rejected': -297.4022216796875, 'logps/chosen': -73.07101440429688, 'logits/rejected': -1.2585200071334839, 'logits/chosen': -1.1594740152359009, 'epoch': 2.8}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 210/222 [2:04:13<07:04, 35.40s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 211/222 [2:04:48<06:29, 35.42s/it]                                                   {'loss': 0.0023, 'grad_norm': 0.005887804087251425, 'learning_rate': 1.8136909589733073e-06, 'rewards/chosen': 0.5991932153701782, 'rewards/rejected': -19.391515731811523, 'rewards/accuracies': 1.0, 'rewards/margins': 19.990711212158203, 'logps/rejected': -293.0881652832031, 'logps/chosen': -70.81377410888672, 'logits/rejected': -1.2970139980316162, 'logits/chosen': -1.3039573431015015, 'epoch': 2.82}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 211/222 [2:04:48<06:29, 35.42s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 212/222 [2:05:24<05:55, 35.55s/it]                                                   {'loss': 0.001, 'grad_norm': 0.006057354621589184, 'learning_rate': 1.4994437367354339e-06, 'rewards/chosen': 0.16286669671535492, 'rewards/rejected': -21.02889060974121, 'rewards/accuracies': 1.0, 'rewards/margins': 21.191757202148438, 'logps/rejected': -317.1720886230469, 'logps/chosen': -57.080841064453125, 'logits/rejected': -1.2680522203445435, 'logits/chosen': -1.2135417461395264, 'epoch': 2.83}
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 212/222 [2:05:24<05:55, 35.55s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 213/222 [2:05:59<05:19, 35.47s/it]                                                   {'loss': 0.0021, 'grad_norm': 0.003733804216608405, 'learning_rate': 1.2149347111684749e-06, 'rewards/chosen': 0.5964863300323486, 'rewards/rejected': -18.575775146484375, 'rewards/accuracies': 1.0, 'rewards/margins': 19.172258377075195, 'logps/rejected': -293.6719970703125, 'logps/chosen': -65.86489868164062, 'logits/rejected': -1.2938209772109985, 'logits/chosen': -1.282212257385254, 'epoch': 2.84}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 213/222 [2:05:59<05:19, 35.47s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 214/222 [2:06:35<04:43, 35.42s/it]                                                   {'loss': 0.0006, 'grad_norm': 0.0015097965952008963, 'learning_rate': 9.602208570445636e-07, 'rewards/chosen': 0.46871253848075867, 'rewards/rejected': -17.80752944946289, 'rewards/accuracies': 1.0, 'rewards/margins': 18.276243209838867, 'logps/rejected': -291.87567138671875, 'logps/chosen': -59.928462982177734, 'logits/rejected': -1.2304835319519043, 'logits/chosen': -1.252313256263733, 'epoch': 2.86}
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 214/222 [2:06:35<04:43, 35.42s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 215/222 [2:07:10<04:07, 35.31s/it]                                                   {'loss': 0.0021, 'grad_norm': 0.005359427072107792, 'learning_rate': 7.353531824600966e-07, 'rewards/chosen': 0.46048110723495483, 'rewards/rejected': -19.64163589477539, 'rewards/accuracies': 1.0, 'rewards/margins': 20.102115631103516, 'logps/rejected': -299.1166687011719, 'logps/chosen': -72.65308380126953, 'logits/rejected': -1.2510533332824707, 'logits/chosen': -1.277635097503662, 'epoch': 2.87}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 215/222 [2:07:10<04:07, 35.31s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 216/222 [2:07:45<03:31, 35.32s/it]                                                   {'loss': 0.003, 'grad_norm': 0.006139028817415237, 'learning_rate': 5.403767186210218e-07, 'rewards/chosen': 0.5182565450668335, 'rewards/rejected': -20.387205123901367, 'rewards/accuracies': 1.0, 'rewards/margins': 20.905460357666016, 'logps/rejected': -298.01934814453125, 'logps/chosen': -81.4466552734375, 'logits/rejected': -1.25681471824646, 'logits/chosen': -1.2762603759765625, 'epoch': 2.88}
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 216/222 [2:07:45<03:31, 35.32s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 217/222 [2:08:21<02:57, 35.42s/it]                                                   {'loss': 0.0009, 'grad_norm': 0.003949145786464214, 'learning_rate': 3.753305108250504e-07, 'rewards/chosen': 0.542380154132843, 'rewards/rejected': -18.156816482543945, 'rewards/accuracies': 1.0, 'rewards/margins': 18.69919776916504, 'logps/rejected': -275.5682067871094, 'logps/chosen': -60.5659294128418, 'logits/rejected': -1.277969241142273, 'logits/chosen': -1.2728818655014038, 'epoch': 2.9}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 217/222 [2:08:21<02:57, 35.42s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 218/222 [2:08:56<02:21, 35.42s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.0006955528515391052, 'learning_rate': 2.402476106425466e-07, 'rewards/chosen': 0.2671510875225067, 'rewards/rejected': -19.806739807128906, 'rewards/accuracies': 1.0, 'rewards/margins': 20.073890686035156, 'logps/rejected': -303.1613464355469, 'logps/chosen': -58.06520462036133, 'logits/rejected': -1.2473604679107666, 'logits/chosen': -1.226616382598877, 'epoch': 2.91}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 218/222 [2:08:56<02:21, 35.42s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 219/222 [2:09:31<01:45, 35.33s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.0009139365865848958, 'learning_rate': 1.3515506929778762e-07, 'rewards/chosen': 0.606879472732544, 'rewards/rejected': -21.914649963378906, 'rewards/accuracies': 1.0, 'rewards/margins': 22.52153205871582, 'logps/rejected': -316.71142578125, 'logps/chosen': -61.53041458129883, 'logits/rejected': -1.2572044134140015, 'logits/chosen': -1.2896353006362915, 'epoch': 2.92}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 219/222 [2:09:31<01:45, 35.33s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 220/222 [2:10:07<01:10, 35.41s/it]                                                   {'loss': 0.0019, 'grad_norm': 0.0045102303847670555, 'learning_rate': 6.007393225176404e-08, 'rewards/chosen': 0.5632749795913696, 'rewards/rejected': -18.099424362182617, 'rewards/accuracies': 1.0, 'rewards/margins': 18.66269874572754, 'logps/rejected': -277.6796875, 'logps/chosen': -60.45097351074219, 'logits/rejected': -1.3015284538269043, 'logits/chosen': -1.2491884231567383, 'epoch': 2.94}
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 220/222 [2:10:07<01:10, 35.41s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 221/222 [2:10:42<00:35, 35.40s/it]                                                   {'loss': 0.0036, 'grad_norm': 0.006246407050639391, 'learning_rate': 1.501923498766766e-08, 'rewards/chosen': 0.33123576641082764, 'rewards/rejected': -18.923900604248047, 'rewards/accuracies': 1.0, 'rewards/margins': 19.25513458251953, 'logps/rejected': -285.4656677246094, 'logps/chosen': -54.737308502197266, 'logits/rejected': -1.2802977561950684, 'logits/chosen': -1.2520471811294556, 'epoch': 2.95}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 221/222 [2:10:42<00:35, 35.40s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [2:11:18<00:00, 35.40s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.00047299251309596, 'learning_rate': 0.0, 'rewards/chosen': 0.468610554933548, 'rewards/rejected': -18.649503707885742, 'rewards/accuracies': 1.0, 'rewards/margins': 19.118112564086914, 'logps/rejected': -274.6195983886719, 'logps/chosen': -71.79456329345703, 'logits/rejected': -1.270556926727295, 'logits/chosen': -1.3192490339279175, 'epoch': 2.96}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [2:11:18<00:00, 35.40s/it]                                                   {'train_runtime': 7880.7988, 'train_samples_per_second': 7.293, 'train_steps_per_second': 0.028, 'train_loss': 0.0195680142889352, 'epoch': 2.96}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [2:11:18<00:00, 35.40s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 222/222 [2:11:18<00:00, 35.49s/it]
wandb: - 0.030 MB of 0.030 MB uploadedwandb: \ 0.030 MB of 0.030 MB uploadedwandb: | 0.030 MB of 0.030 MB uploadedwandb: / 0.030 MB of 0.030 MB uploadedwandb: - 0.030 MB of 0.030 MB uploadedwandb: \ 0.030 MB of 0.030 MB uploadedwandb: | 0.067 MB of 0.115 MB uploaded (0.031 MB deduped)wandb: / 0.115 MB of 0.115 MB uploaded (0.031 MB deduped)wandb: 
wandb: Run history:
wandb:              train/epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:        train/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:          train/grad_norm â–‡â–ˆâ–ƒâ–„â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:      train/learning_rate â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:      train/logits/chosen â–â–‚â–‚â–ƒâ–…â–„â–…â–„â–…â–„â–…â–„â–„â–…â–†â–…â–„â–ƒâ–‡â–…â–…â–†â–‡â–…â–†â–…â–…â–…â–…â–„â–‡â–…â–…â–…â–†â–‡â–„â–ˆâ–„â–ƒ
wandb:    train/logits/rejected â–ƒâ–â–‚â–ƒâ–‡â–…â–†â–„â–†â–‡â–†â–†â–…â–‡â–†â–…â–†â–„â–„â–…â–…â–…â–„â–…â–ƒâ–ˆâ–„â–…â–…â–‡â–†â–„â–‡â–…â–…â–†â–„â–†â–†â–†
wandb:       train/logps/chosen â–„â–„â–ˆâ–„â–‡â–ƒâ–‚â–…â–†â–…â–„â–ƒâ–ƒâ–‡â–†â–‡â–‚â–‡â–…â–†â–†â–ƒâ–†â–…â–‚â–„â–†â–‚â–„â–…â–…â–†â–…â–†â–†â–…â–†â–ƒâ–â–ƒ
wandb:     train/logps/rejected â–ˆâ–‡â–†â–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–â–‚
wandb:               train/loss â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: train/rewards/accuracies â–â–â–ˆâ–…â–…â–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:     train/rewards/chosen â–â–ƒâ–…â–„â–„â–…â–„â–ƒâ–ƒâ–„â–…â–…â–†â–ƒâ–„â–…â–„â–ƒâ–ƒâ–„â–ˆâ–…â–„â–„â–…â–ƒâ–†â–„â–„â–…â–ƒâ–„â–„â–„â–„â–„â–ƒâ–…â–„â–„
wandb:    train/rewards/margins â–â–â–ƒâ–…â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:   train/rewards/rejected â–ˆâ–ˆâ–†â–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–â–â–‚â–â–‚
wandb: 
wandb: Run summary:
wandb:               total_flos 0.0
wandb:              train/epoch 2.96494
wandb:        train/global_step 222
wandb:          train/grad_norm 0.00047
wandb:      train/learning_rate 0.0
wandb:      train/logits/chosen -1.31925
wandb:    train/logits/rejected -1.27056
wandb:       train/logps/chosen -71.79456
wandb:     train/logps/rejected -274.6196
wandb:               train/loss 0.0001
wandb: train/rewards/accuracies 1.0
wandb:     train/rewards/chosen 0.46861
wandb:    train/rewards/margins 19.11811
wandb:   train/rewards/rejected -18.6495
wandb:               train_loss 0.01957
wandb:            train_runtime 7880.7988
wandb: train_samples_per_second 7.293
wandb:   train_steps_per_second 0.028
wandb: 
wandb: ðŸš€ View run models/llama-7b_SpclSpclSpcl_None_2024-06-02-00-00-00_dpo_NaiveCompletion_2024-08-15-02-26-16 at: https://wandb.ai/sizhe-chen/huggingface/runs/w0h7hpoa
wandb: â­ï¸ View project at: https://wandb.ai/sizhe-chen/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240815_022806-w0h7hpoa/logs
